{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MF+DO_Final.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMfn3Dod9yn6b7guk27Iiya",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/christina-ohjoo/Machine-Learning/blob/main/MF%2BDO_Final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j-p0C30K5vbH"
      },
      "source": [
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from matplotlib import pyplot as plt\n",
        "plt.style.use('dark_background')\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Flatten, Activation, Dropout\n",
        "from keras.utils import normalize, to_categorical\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import scipy.special\n",
        "import time\n",
        "import datetime\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.utils import plot_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mYTXzA-FF9qK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7b755bc-5f49-49ed-c381-ed9a8cb18a89"
      },
      "source": [
        "print(keras.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.4.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WKi5KwVd-RvX",
        "outputId": "9ac581e7-f9be-40c7-cfff-7977eda08cc5"
      },
      "source": [
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.4.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-nQ4YijK5zhQ"
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E7eSj2oc52Sm",
        "outputId": "bc56425d-bd73-4e9d-fa6b-b7df0e414324"
      },
      "source": [
        "print('축의 개수 : ', x_train.ndim)\n",
        "print('배열의 크기 : ', x_train.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "축의 개수 :  3\n",
            "배열의 크기 :  (60000, 28, 28)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UTYVApkf539e"
      },
      "source": [
        "x_train = normalize(x_train, axis=1)\n",
        "x_test = normalize(x_test, axis=1)\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_xmj2N2A57Wa",
        "outputId": "bbdef66d-c061-472f-f9b5-1efdb271a6e5"
      },
      "source": [
        "#without dropout\n",
        "model = Sequential()\n",
        "model.add(Flatten(input_shape=(28, 28)))\n",
        "model.add(Dense(128))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(128))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(10))\n",
        "model.add(Activation('softmax'))\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_1 (Flatten)          (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 128)               100480    \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 10)                1290      \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 118,282\n",
            "Trainable params: 118,282\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 865
        },
        "id": "YYTymm2igLyk",
        "outputId": "085e3a0e-3761-4299-dc04-68e2c3309f28"
      },
      "source": [
        "plot_model(model, to_file='model.png')\n",
        "plot_model(model, to_file='model_shapes.png', show_shapes=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAdcAAANQCAYAAAB6riWIAAAABmJLR0QA/wD/AP+gvaeTAAAgAElEQVR4nOzde1RTZ9Y/8G+AQAATLioX8QZBVBTrWHl/QsvgpWNVRlGBitVerK2orYi3KuCtiCjVIguVcUTLmldtFdSCY6XOaIc6jNZlRxmVvrV4BxURud8EYf/+cJIaEzGBAwlxf9ZirfY5zznPPuck2ebkPGeLiIjAGGOMMaGkm+g7AsYYY8zYcHJljDHGBMbJlTHGGBMYJ1fGGGNMYGbPNpw5cwYJCQn6iIUxxhjrdNLT09Xa1L65FhQU4ODBgx0SEGOs9X788Uf8+OOP+g6jUyksLOTPNyaYll5Pat9cFTRlYsaY4QgJCQHA71VdpKWlYdq0aXzMmCAUrydN+DdXxhhjTGCcXBljjDGBcXJljDHGBMbJlTHGGBMYJ1fGGGNMYJxcGXvJHTt2DDY2NvjrX/+q71AM0ty5cyESiZR/M2fOVOtz4sQJREZG4tChQ3Bzc1P2feedd9T6jh07FlKpFKamphg0aBDOnz/fEbvRajExMfD09IRMJoOFhQXc3d3x6aeforq6Wq3vV199BW9vb0ilUvTp0wezZs1CUVGR3sc9cuQI4uPj0dTUpLJeRkaGyrnt1q1bq2LViJ5x4MAB0tDMGDMwwcHBFBwc3ObtHD16lGQyGR05ckSAqAxbaz7fwsLCyN7enrKysujKlStUX1+vsnz16tU0ceJEqqysVLbJ5XLq2rUrAaCjR4+qbTMrK4sCAwNbtxMdzN/fn7Zv304PHz6kyspKOnDgAInFYho3bpxKv/379xMAio+Pp/Lycrpw4QK5ubnR0KFDqbGxUe/jJiYmkr+/P5WVlSnbmpubqbCwkE6dOkUTJkygrl276hRjC6+nNE6ujHVSQiVXQ1JbW0s+Pj7ttv3WJlcXFxeNyzZs2EAeHh5UV1en0i6Xy2nfvn1kYmJCLi4uVF5errK8MyXXgIAAevz4sUrbW2+9RQDo9u3byrZRo0ZRjx49qLm5Wdm2bds2AkA5OTkGMW54eDj5+PhoTPYLFy4UNLnyZWHGmMHYvXs3iouL9R2GVq5evYpVq1bhs88+g0QiUVvu6+uLiIgI3LlzB0uXLtVDhMI4evQoTE1NVdoUl09ra2uVbQUFBXB2doZIJFK29erVCwBw69Ytgxh37dq1yM3NRWJios7x6IqTK2MvsZycHPTu3RsikQjbtm0DACQnJ8Pa2hpWVlbIzMzE+PHjIZPJ0LNnT3z99dfKdZOSkiCRSODg4IC5c+fC2dkZEokEvr6+OHv2rLJfeHg4zM3N4eTkpGz7+OOPYW1tDZFIhJKSEgBAREQElixZgmvXrkEkEsHd3R0A8N1330Emk2H9+vUdcUi0lpSUBCLCpEmTntsnNjYWHh4e2LVrF06cONHi9ogICQkJGDhwICwsLGBnZ4fJkyfjl19+UfbR9twAQFNTE1avXo3evXvD0tISQ4YMwYEDB9q20/91584dWFpawtXVVdnm5uam9g8jxe+ebm5uBjGunZ0d/P39kZiYCCISJKbn0uFrLmPMgAh1WbigoIAA0NatW5Vt0dHRBIBOnjxJFRUVVFxcTH5+fmRtbU0NDQ3KfmFhYWRtbU0///wz1dfXU15eHnl7e5NUKlW5dDdjxgxydHRUGXfTpk0EgB48eKBsCwoKIrlcrtLv6NGjJJVKKSYmps37KuRlYTc3N/L09NS4jlwupxs3bhAR0enTp8nExIT69u1L1dXVRKT5svDq1avJ3Nyc9uzZQ+Xl5XTx4kUaNmwYdevWjYqKipT9tD03S5cuJQsLCzp48CCVlZVRVFQUmZiY0Llz53Ta/2fV1NSQVCql8PBwlfbs7GwSi8WUlJRElZWVdPnyZRo4cCC9+eabbRpP6HEjIyMJAF24cEGlnS8LM8Y6jK+vL2QyGbp3747Q0FDU1NTg9u3bKn3MzMyU37Y8PT2RnJyMqqoqpKamChJDQEAAKisrsWrVKkG2J4SamhrcuHEDcrn8hX19fHywaNEi3Lx5EytWrNDYp66uDgkJCZg6dSpmzpwJGxsbeHl5YceOHSgpKcHOnTvV1mnp3NTX1yM5ORlTpkxBUFAQbG1tsXLlSojF4jafl7i4ODg7OyM2Nlal3d/fH8uXL0d4eDhkMhkGDx6Mqqoq7Nq1q03jCT1uv379AACXLl0SJK7n4eTKGNOKubk5AKCxsbHFfsOHD4eVlZXK5UxjU1xcDCKClZWVVv1jY2PRv39/bN++HTk5OWrL8/LyUF1djeHDh6u0e3t7w9zcXOUyuybPnpsrV66gtrYWgwcPVvaxtLSEk5NTm87L4cOHkZaWhuPHj0Mqlaosi46Oxs6dO3Hy5ElUV1fj+vXr8PX1hY+PDwoKClo9ptDjKs7Z/fv32xTTi3ByZYwJzsLCAg8ePNB3GO2mvr4ewJP91IZEIkFqaipEIhE++OAD1NXVqSwvLy8HAHTp0kVtXVtbW1RVVekUX01NDQBg5cqVKvM4b926pXIzkC7279+PjRs3Ijs7G3379lVZdu/ePcTHx2POnDkYPXo0rK2t4erqipSUFNy9exebNm1q1ZjtMa6lpSWA385he+HkyhgTVGNjI8rLy9GzZ099h9JuFB/Qzz6UoCU+Pj5YvHgx8vPzsW7dOpVltra2AKAxibbmWHbv3h0AsGXLFhCRyt+ZM2d02hYAbN26FXv37sX333+PHj16qC3Pz89HU1OT2jKZTAZ7e3vk5eXpPGZ7jdvQ0ADgt3PYXp5bz5UxxlojOzsbRIQRI0Yo28zMzF54ObkzcXBwgEgkQkVFhU7rrVu3DkePHsWFCxfQu3dvZfvgwYPRpUsX/PTTTyr9z549i4aGBrz66qs6jdOrVy9IJBLk5ubqtN6ziAgrVqxAWVkZMjIyYGamOWUokv+9e/dU2quqqlBaWqqcGmMI4yrOmaOjo04x6Yq/uTLG2qS5uRllZWV4/PgxLl68iIiICPTu3Rvvv/++so+7uztKS0uRkZGBxsZGPHjwQOPcR3t7e9y9exc3b95EVVUVGhsbkZWVZXBTcaysrODm5obCwkKd1lNcHn52/qZEIsGSJUtw+PBh7N27F5WVlbh06RLmzZsHZ2dnhIWF6TzOrFmz8PXXXyM5ORmVlZVoampCYWGhMhGFhobC0dGxxccv/vzzz/j888+RkpICsViscolZJBJh8+bNAABXV1eMGjUKKSkpOHXqFOrq6lBQUKCMe/bs2cpt6mtcBcU58/Ly0uWQ6oyTK2MvsW3btsHb2xsAsHz5cgQGBiI5ORlbtmwBAAwZMgTXr19HSkoKlixZAgAYN24c8vPzlduor6+Hl5cXLC0t4efnBw8PD/zjH/9Q+T1y/vz5GDVqFKZPn47+/ftj3bp1ystyT994Mm/ePDg4OMDT0xMTJkxAaWlphxyH1ggICEBeXp7K76fffPMN3N3dce3aNXh7e2PBggVq640YMQKLFy9Wa1+zZg3i4uIQExODbt26wd/fH3379kV2djasra0BQKdzk5iYiEWLFiE+Ph5du3aFs7MzIiIiUFZWBuDJ5dHi4mJkZmY+dx9Jy7mgIpEI6enpCA0NxezZs2FnZwdPT0/cvn0bhw4dgp+fn7KvvsZVOHfuHFxcXDBkyBCtxmg1HebtMMYMiCE8/lDx3N3OQsh5rvn5+WRmZkZ79uwRKrwO1dTURH5+frR79+6XYlwiopKSEpJIJLR582a1ZTzPlTFmUHS5qaezqqurw/Hjx5Gfn6+8Icbd3R0xMTGIiYnRWKnFkDU1NSEjIwNVVVUIDQ01+nEV1q5di6FDhyI8PBzAk2/Id+/eRU5ODq5evSroWJxcGWPsBUpLSzFu3Dh4eHjggw8+ULZHRkYiJCQEoaGhOt/cpE/Z2dk4dOgQsrKytJ6r25nHBYCEhATk5ubi2LFjEIvFAIDMzEy4uLjAz88P3377raDjCZZcHz16hIULF8LJyQlWVlZ44403lHfU7dixQ6hh9K65uRlbtmyBr69vm7ZjDDU0f/zxRwwcOBAmJiYQiURwdHRUe3qKvj1bX9PJyUljPU6mu6ioKKSmpqKiogKurq44ePCgvkNqFzt27FCZyrJ3716V5evXr0d4eDg2bNigpwh1N2bMGOzbt0/lec/GPG5mZiYePXqE7Oxs2NnZKdsnT56scm4Vz7kWgmBTcb744gt89913+OWXX5CWlgZ7e3sMHTpU+agpY5Cfn49Zs2bhX//6F1555ZU2bYva+6HRHWDEiBH4v//7P4wbNw7Hjx/HlStXlPP1DEVQUBCCgoLg7u6OkpKSVhduZuri4uIQFxen7zAMwtixYzF27Fh9h8GeIzAwEIGBgR06pmDfXDMyMjB8+HDY2tpizpw5CA4ObtV26urq1L4VamrraP/5z3+wYsUKzJs3D0OHDm3z9gICAlBRUYGJEycKEF3bGMLxFYox7QtjrPMSLLkWFhYqr2O3haZ6joZQ4/GVV17BoUOHMGPGDK0fedZZGMLxFYox7QtjrPNqc3L9+9//Dnd3d9y7dw9/+ctfIBKJND4fU+Gf//wnPD09YWNjA4lEAi8vLxw/fhyA5nqOz6vx2FKtQl1qHuqDsdfQNLR90VVLr9EPP/xQ+futXC7HhQsXAACzZs2ClZUVbGxscOTIEQAtv0Y///xzWFlZQSqVori4GEuWLIGLiwuuXLnSqpgZYwZGh3k7LXJ0dKT33ntPpS0/P58A0J/+9CdlW3p6Oq1du5ZKS0vp4cOHNGLECJW5RZrqOWpqe1GtQm1rHrbG//t//49eeeWVNm3DmGpovvnmmwSAysrKDHJfiJ7U17SxsXnhvhBp9xo1NTWlO3fuqKz39ttv05EjR5T/r+1rdOHChbR161aaOnUq/d///Z9WMRIZxjzXzobn8TMhGdQ81+DgYKxZswZ2dnawt7fHpEmT8PDhQ50qaOhSq1CbepSGxphqaBrCvujqRa/RefPmoampSSW+yspKnDt3DhMmTACg22t048aN+OSTT3Do0CEMGDCg43aUMdZu9P7gfsXvtLpMRG9trUJt61EaEmOqodlZ9+XZ1+jo0aPh4eGBL7/8ElFRURCJRNi/fz9CQ0OVz4xtr3qazzp48CBEIpFg23tZ8DFj7a3Dk+u3336LTZs2IS8vD5WVla1KdE/XKly5cqXKMmdnZ0Hi7IyMqYamPvflRa9RkUiEuXPnYvHixTh58iTeeOMN/O///i/27dun7NNRr9ERI0Zg0aJFgm3P2J05cwaJiYnK374ZawvF60mTDk2ut2/fxpQpUzB16lR8+eWX6NGjB7Zu3YpPP/1Up+08XaswIiKiPULtdIyphmZH78upU6fw73//G4sWLdL6Nfr+++8jKioKu3btQq9evSCTydCnTx/l8o56jfbs2RNvvfVWu23fGCUmJvIxY4IxiOR66dIlNDY2Yv78+XBzcwPQusszQtUqNCbGVEOzo/fl3//+t7LqiLavUTs7O0ybNg379++HVCrFRx99pLKcX6OMvdw69IYmRXHgEydOoL6+Hvn5+SpTLgDN9RyfbTM1NX1hrUJjZ0w1NNt7X56nsbER9+/fVynppc1rVGHevHl49OgRjh49qvYwEG3qaTLGjJgOtxZrdPPmTfrd735HAMjMzIyGDRtGBw8epC+++IIcHR0JAFlbW9PUqVOJiGj58uVkb29Ptra2FBISQtu2bSMAJJfL6fbt23T+/Hnq06cPWVpa0uuvv05FRUUa2x49ekTLly+n3r17k5mZGXXv3p2CgoIoLy+Ptm/fTlZWVgSA+vXrR9euXaOdO3eSTCYjANSnTx/69ddfdbrl+syZM/Taa6+Rs7MzASAA5OTkRL6+vvTDDz/otK2tW7eSk5MTASArKyuaNGmSTjGHhYWRWCwmFxcXMjMzI5lMRpMnT6Zr166pjPPw4UMaNWoUSSQScnV1pQULFtCyZcsIALm7uyunumg6vseOHSOpVEqxsbHP3Y8ff/yRBg0aRCYmJsrjsX79eoPalz/96U8kl8uV5+x5f4cPH1aO9aLX6NN+97vfUWRkpMbj09JrND4+niwtLQkA9erVq1Vly3gqju54Kg4TUktTcUREqg+5TUtLw7Rp04zi2bfGau7cuUhPT8fDhw/1HUqbdfZ9CQgIwLZt2+Dq6trhY4eEhAAA0tPTO3zszoo/35iQWng9pXPJuU7KmGpodqZ9efoy88WLFyGRSPSSWBljhu2lTa6//PKL8jF2Lf1pW9BX6O0xw7R8+XLk5+fj119/xaxZs7Bu3Tp9h8Ta2dy5c1Xew5pKFp44cQKRkZFqJQ7feecdtb5jx46FVCqFqakpBg0ahPPnz3fEbrRaTEwMPD09IZPJYGFhAXd3d3z66acaC8R/9dVX8Pb2hlQqRZ8+fTBr1qxWV6ISctwjR44gPj5e7R/yGRkZKue2W7durYpVIx2uITMDEBkZSebm5gSA+vbtS+np6foOqdU6475ER0eTiYkJ9erVS+VRh/rAv7nqrjWfb2FhYWRvb09ZWVl05coVqq+vV1m+evVqmjhxIlVWVirb5HI5de3alQDQ0aNH1baZlZVFgYGBrduJDubv70/bt2+nhw8fUmVlJR04cIDEYjGNGzdOpd/+/fsJAMXHx1N5eTlduHCB3NzcaOjQodTY2Kj3cRMTE8nf31/lMa3Nzc1UWFhIp06dogkTJqg85lQbLf3mysmVsU7KEJJrbW0t+fj4dJoxWptcXVxcNC7bsGEDeXh4UF1dnUq7XC6nffv2kYmJCbm4uFB5ebnK8s6UXAMCAujx48cqbW+99RYBULnBb9SoUdSjRw9qbm5WtiluBszJyTGIccPDw8nHx0djsl+4cKGgyfWlvSzMGGu7jijxZ6hlBK9evYpVq1bhs88+g0QiUVvu6+uLiIgI3LlzB0uXLtVDhMI4evSo8rGeCorLp7W1tcq2goICODs7q8wL79WrFwBonDanj3HXrl2L3Nzc5z74QUicXBl7iRAREhISlIUS7OzsMHnyZJXnHbelxF9nKIkolKSkJBARJk2a9Nw+sbGx8PDwwK5du3DixIkWt6fNudGlnGZLJQ/b6s6dO7C0tFS5mc/NzU3tH0GK3z0VD2TR97h2dnbw9/dHYmJi+98xrsPXXMaYAWnNZeHVq1eTubk57dmzh8rLy+nixYs0bNgw6tatGxUVFSn7taXEn6GVRHyakJeF3dzcyNPTU+M6crmcbty4QUREp0+fJhMTE+rbty9VV1cTkebLwtqeG23LOb6o5GFr1dTUkFQqpfDwcJX27OxsEovFlJSURJWVlXT58mUaOHAgvfnmm20aT+hxIyMjCQBduHBBpZ0vCzPGWqWurg4JCQmYOnUqZs6cCRsbG3h5eWHHjh0oKSnBzp07BRurs5REbK2amhrcuHEDcrn8hX19fHywaNEi3Lx5EytWrNDYpzXnpqVyjrqUPNRVXFwcnJ2dERsbq9Lu7++P5cuXIzw8HDKZDIMHD0ZVVRV27drVpvGEHrdfv34AnjzqtD1xcmXsJZGXl4fq6moMHz5cpd3b2xvm5ubPfcyjEAytjGBbFRcXg4hgZWWlVf/Y2Fj0798f27dvR05Ojtrytp6bZ8s5tlfJw8OHDyMtLQ3Hjx+HVCpVWRYdHY2dO3fi5MmTqK6uxvXr1+Hr6wsfHx8UFBS0ekyhx1Wcs/v377cpphfh5MrYS6K8vBwA0KVLF7Vltra2qKqqatfxjakkYn19PYAn+6QNiUSC1NRUiEQifPDBB6irq1NZLvS5ebrk4dPzOG/duqVyM5Au9u/fj40bNyI7Oxt9+/ZVWXbv3j3Ex8djzpw5GD16NKytreHq6oqUlBTcvXsXmzZtatWY7TGupaUlgN/OYXvh5MrYS8LW1hYANH5Qt3eJP2MqiQj89gGty9PFfHx8sHjxYuTn56s9fEToc/N0yUMiUvk7c+aMTtsCgK1bt2Lv3r34/vvv0aNHD7Xl+fn5aGpqUlsmk8lgb2+PvLw8ncdsr3EbGhoA/HYO20uHF0tnjOnH4MGD0aVLF/z0008q7WfPnkVDQwNeffVVZZvQJf6MqSQiADg4OEAkEqGiokKn9datW4ejR4/iwoULygpMgG7nRhtClTwkIqxYsQJlZWXIyMiAmZnmlKFI/s9WfKqqqkJpaalyaowhjKs4Z46OjjrFpCv+5srYS0IikWDJkiU4fPgw9u7di8rKSly6dAnz5s2Ds7MzwsLClH3bWuLPmEoiamJlZQU3NzcUFhbqtJ7i8vCz8zd1OTfajvOikoehoaFwdHRs8fGLP//8Mz7//HOkpKRALBarPc518+bNAABXV1eMGjUKKSkpOHXqFOrq6lBQUKCMe/bs2cpt6mtcBcU58/Ly0uWQ6oyTK2MvkTVr1iAuLg4xMTHo1q0b/P390bdvX5WatgAwf/58jBo1CtOnT0f//v2xbt065WW0p28UmTdvHhwcHODp6YkJEyagtLQUwJPfs7y8vGBpaQk/Pz94eHjgH//4h8pvlG0dQ98CAgKQl5en8vvpN998A3d3d1y7dg3e3t5YsGCB2nojRozA4sWL1dq1OTfJycnYsmULAGDIkCG4fv06UlJSsGTJEgDAuHHjkJ+fDwBITEzEokWLEB8fj65du8LZ2RkREREoKysD8OTyaHFxMTIzM5+7j6TlXFCRSIT09HSEhoZi9uzZsLOzg6enJ27fvo1Dhw7Bz89P2Vdf4yqcO3cOLi4uGDJkiFZjtJoO83YYYwbEEB5/qIniWbyGSMh5rvn5+WRmZtaqWryGoKmpifz8/Gj37t0vxbhERCUlJSSRSGjz5s1qy3ieK2PM4HWmMoLaqKurw/Hjx5Gfn6+8Icbd3R0xMTGIiYnRWKnFkDU1NSEjIwNVVVUdWqlLX+MqrF27FkOHDkV4eDiAJ9+Q7969i5ycHFy9elXQsTi5MsbYC5SWlmLcuHHw8PDABx98oGyPjIxESEgIQkNDdb65SZ+ys7Nx6NAhZGVlaT1XtzOPCwAJCQnIzc3FsWPHIBaLAQCZmZlwcXGBn58fvv32W0HH4+TKGBNMVFQUUlNTUVFRAVdXVxw8eFDfIbXZjh07VKay7N27V2X5+vXrER4ejg0bNugpQt2NGTMG+/btU3m2szGPm5mZiUePHiE7Oxt2dnbK9smTJ6ucW8UzrYXAU3EYY4KJi4tDXFycvsPocGPHjsXYsWP1HQZ7jsDAQAQGBnbomPzNlTHGGBMYJ1fGGGNMYJxcGWOMMYFxcmWMMcYE9twbmtLS0joyDsaYjhSPceP3qvYUD63nY8aE0FIRBBGR6nOm0tLSMG3atHYPijHGGDMGpP64xnS15MoYMzyKf/Ty25WxTiGdf3NljDHGBMbJlTHGGBMYJ1fGGGNMYJxcGWOMMYFxcmWMMcYExsmVMcYYExgnV8YYY0xgnFwZY4wxgXFyZYwxxgTGyZUxxhgTGCdXxhhjTGCcXBljjDGBcXJljDHGBMbJlTHGGBMYJ1fGGGNMYJxcGWOMMYFxcmWMMcYExsmVMcYYExgnV8YYY0xgnFwZY4wxgXFyZYwxxgTGyZUxxhgTGCdXxhhjTGCcXBljjDGBcXJljDHGBMbJlTHGGBMYJ1fGGGNMYJxcGWOMMYFxcmWMMcYExsmVMcYYExgnV8YYY0xgnFwZY4wxgXFyZYwxxgRmpu8AGGOqCgsL8d5776GpqUnZVlZWBqlUipEjR6r07d+/P/785z93cISMsRfh5MqYgenZsydu3bqFa9euqS374YcfVP7/97//fUeFxRjTAV8WZswAvfvuuxCLxS/sFxoa2gHRMMZ0xcmVMQM0Y8YMPH78uMU+gwYNgqenZwdFxBjTBSdXxgyQXC7HkCFDIBKJNC4Xi8V47733Ojgqxpi2OLkyZqDeffddmJqaalz2+PFjhISEdHBEjDFtcXJlzEBNnz4dzc3Nau0mJiYYMWIE+vbt2/FBMca0wsmVMQPl7OyM1157DSYmqm9TExMTvPvuu3qKijGmDU6ujBmwd955R62NiDB16lQ9RMMY0xYnV8YMWHBwsMrvrqampnjjjTfg4OCgx6gYYy/CyZUxA2ZnZ4c//OEPygRLRJg5c6aeo2KMvQgnV8YM3MyZM5U3NonFYkyePFnPETHGXoSTK2MGbtKkSbCwsAAATJw4EV26dNFzRIyxF+HkypiBs7a2Vn5b5UvCjHUOIiIifQchpLS0NEybNk3fYTDGGNOSkaUhAEg32qo4Bw4c0HcIzMhs2bIFALBo0aIOH7upqQkHDhzA22+/3eFjt8WZM2eQmJjI70emkeL1YYyMNrm+9dZb+g6BGZn09HQA+nttTZkyBRKJRC9jt0ViYiK/H9lzGWty5d9cGeskOmNiZexlxcmVMcYYExgnV8YYY0xgnFwZY4wxgXFyZYwxxgTGyZWxDnbs2DHY2Njgr3/9q75DMXgnTpxAZGQkDh06BDc3N4hEIohEIo3VgsaOHQupVApTU1MMGjQI58+f10PE2ouJiYGnpydkMhksLCzg7u6OTz/9FNXV1Wp9v/rqK3h7e0MqlaJPnz6YNWsWioqK9D7ukSNHEB8fj6amplbFYsw4uTLWwYxwwny7WLNmDZKSkhAVFYWgoCBcv34dcrkcXbt2xd69e/Htt9+q9P/b3/6G9PR0TJw4EXl5eRg2bJieItfO999/j08++QQ3b95ESUkJ4uLikJiYiJCQEJV+Bw4cwIwZMxASEoLCwkJkZmbi1KlTGD9+PB4/fqzXcSdNmgSJRIIxY8agvLy89QfDGJGROXDgABnhbjEDEBwcTMHBwfoOQ1C1tbXk4+PTbttv7ftxw4YN5OHhQXV1dSrtcrmc9u3bRyYmJuTi4kLl5eUqy7OysigwMLBNMXeUgIAAevz4sUrbW2+9RQDo9u3byrZRo0ZRjx49qLm5Wdm2bds2AkA5OTkGMW54eDj5+PhQY2OjTrEY8ed1Gn9zZewltnv3bhQXF+s7DBVXr17FqlWr8Nlnn2mc2xNVxmcAACAASURBVOvr64uIiAjcuXMHS5cu1UOEwjh69KhKrV4A6NatGwCgtrZW2VZQUABnZ2eIRCJlW69evQAAt27dMohx165di9zcXKN9IERrcHJlrAPl5OSgd+/eEIlE2LZtGwAgOTkZ1tbWsLKyQmZmJsaPHw+ZTIaePXvi66+/Vq6blJQEiUQCBwcHzJ07F87OzpBIJPD19cXZs2eV/cLDw2Fubg4nJydl28cffwxra2uIRCKUlJQAACIiIrBkyRJcu3YNIpEI7u7uAIDvvvsOMpkM69ev74hDoiYpKQlEhEmTJj23T2xsLDw8PLBr1y6cOHGixe0RERISEjBw4EBYWFjAzs4OkydPxi+//KLso+05AJ48inL16tXo3bs3LC0tMWTIEMEe73jnzh1YWlrC1dVV2ebm5qb2DyDF755ubm4GMa6dnR38/f2RmJjIP3so6Pmrs+CM+DID0zOhLgsXFBQQANq6dauyLTo6mgDQyZMnqaKigoqLi8nPz4+sra2poaFB2S8sLIysra3p559/pvr6esrLyyNvb2+SSqUql/RmzJhBjo6OKuNu2rSJANCDBw+UbUFBQSSXy1X6HT16lKRSKcXExLR5X1vzfnRzcyNPT0+Ny+RyOd24cYOIiE6fPk0mJibUt29fqq6uJiLNl4VXr15N5ubmtGfPHiovL6eLFy/SsGHDqFu3blRUVKTsp+05WLp0KVlYWNDBgweprKyMoqKiyMTEhM6dO6fTfj6rpqaGpFIphYeHq7RnZ2eTWCympKQkqqyspMuXL9PAgQPpzTffbNN4Qo8bGRlJAOjChQtaj23En9d8WZgxQ+Lr6wuZTIbu3bsjNDQUNTU1uH37tkofMzMz5bcwT09PJCcno6qqCqmpqYLEEBAQgMrKSqxatUqQ7emipqYGN27cgFwuf2FfHx8fLFq0CDdv3sSKFSs09qmrq0NCQgKmTp2KmTNnwsbGBl5eXtixYwdKSkqwc+dOtXVaOgf19fVITk7GlClTEBQUBFtbW6xcuRJisbjNxz8uLg7Ozs6IjY1Vaff398fy5csRHh4OmUyGwYMHo6qqCrt27WrTeEKP269fPwDApUuXBImrs+PkypiBMjc3BwA0Nja22G/48OGwsrJSuczZWRUXF4OIYGVlpVX/2NhY9O/fH9u3b0dOTo7a8ry8PFRXV2P48OEq7d7e3jA3N1e5nK7Js+fgypUrqK2txeDBg5V9LC0t4eTk1Kbjf/jwYaSlpeH48eOQSqUqy6Kjo7Fz506cPHkS1dXVuH79Onx9feHj44OCgoJWjyn0uIpzdv/+/TbFZCw4uTJmBCwsLPDgwQN9h9Fm9fX1AJ7sjzYkEglSU1MhEonwwQcfoK6uTmW5YnpIly5d1Na1tbVFVVWVTvHV1NQAAFauXKmccysSiXDr1i2Vm4F0sX//fmzcuBHZ2dno27evyrJ79+4hPj4ec+bMwejRo2FtbQ1XV1ekpKTg7t272LRpU6vGbI9xLS0tAfx2Dl92nFwZ6+QaGxtRXl6Onj176juUNlN8QOvyUAIfHx8sXrwY+fn5WLduncoyW1tbANCYRFtzzLp37w7gSW1fIlL5O3PmjE7bAoCtW7di7969+P7779GjRw+15fn5+WhqalJbJpPJYG9vj7y8PJ3HbK9xGxoaAPx2Dl92RlvPlbGXRXZ2NogII0aMULaZmZm98HKyIXJwcIBIJEJFRYVO661btw5Hjx7FhQsX0Lt3b2X74MGD0aVLF/z0008q/c+ePYuGhga8+uqrOo3Tq1cvSCQS5Obm6rTes4gIK1asQFlZGTIyMmBmpvmjWJH87927p9JeVVWF0tJS5dQYQxhXcc4cHR11islY8TdXxjqZ5uZmlJWV4fHjx7h48SIiIiLQu3dvvP/++8o+7u7uKC0tRUZGBhobG/HgwQONcyLt7e1x9+5d3Lx5E1VVVWhsbERWVpbepuJYWVnBzc0NhYWFOq2nuDz87PxNiUSCJUuW4PDhw9i7dy8qKytx6dIlzJs3D87OzggLC9N5nFmzZuHrr79GcnIyKisr0dTUhMLCQmUiCg0NhaOjY4uPX/z555/x+eefIyUlBWKxWOUSs0gkwubNmwEArq6uGDVqFFJSUnDq1CnU1dWhoKBAGffs2bOV29TXuAqKc+bl5aXLITVanFwZ60Dbtm2Dt7c3AGD58uUIDAxEcnIytmzZAgAYMmQIrl+/jpSUFCxZsgQAMG7cOOTn5yu3UV9fDy8vL1haWsLPzw8eHh74xz/+ofI75fz58zFq1ChMnz4d/fv3x7p165SX656+IWXevHlwcHCAp6cnJkyYgNLS0g45Di0JCAhAXl6eyu+n33zzDdzd3XHt2jV4e3tjwYIFauuNGDECixcvVmtfs2YN4uLiEBMTg27dusHf3x99+/ZFdnY2rK2tAUCnc5CYmIhFixYhPj4eXbt2hbOzMyIiIlBWVgbgyeXR4uJiZGZmPncfScu5oCKRCOnp6QgNDcXs2bNhZ2cHT09P3L59G4cOHYKfn5+yr77GVTh37hxcXFwwZMgQrcYwevqaBNRejHjeFNMzQ3j8YVhYGNnb2+s1Bl205v2Yn59PZmZmtGfPnnaKqn01NTWRn58f7d69+6UYl4iopKSEJBIJbd68Waf1jPjzmue5MtbZGHsFEnd3d8TExCAmJkZjpRZD1tTUhIyMDFRVVSE0NNTox1VYu3Ythg4divDw8A4f21Bxcv2vR48eYeHChXBycoKVlRXeeOMN5c0VO3bs0Hd4gmlubsaWLVvg6+vb6m08W/5L05/i1v7Nmzcb5XFk7SsyMhIhISEIDQ3V+eYmfcrOzsahQ4eQlZWl9VzdzjwuACQkJCA3NxfHjh2DWCzu0LENGSfX//riiy/w3Xff4ZdffkFiYiLmzp2L06dP6zssQeXn5+P3v/89Fi9e3Oo5eQBUyn/Z2NgopyI8fvwYtbW1uH//vvINvnTpUqM7jvoSFRWF1NRUVFRUwNXVFQcPHtR3SO1q/fr1CA8Px4YNG/QditbGjBmDffv2qTzX2ZjHzczMxKNHj5CdnQ07O7sOHdvQcXL9r4yMDAwfPhy2traYM2cOgoODW7Wduro6tW+Fmto62n/+8x+sWLEC8+bNw9ChQ9tlDFNTU1haWsLBwQEeHh5t2pahHkd9iouLw6NHj0BEuHHjRqtfo53J2LFjsXHjRn2HwZ4jMDAQkZGRandpM06uSoWFhYJc0tBUwssQynq98sorOHToEGbMmKH102/aIiMjo03rG+pxZIwxbbz0yfXvf/873N3dce/ePfzlL3+BSCTS+Kg0hX/+85/w9PSEjY0NJBIJvLy8cPz4cQCaS3g9r6xXS2WrdCl/JbSOKjdm7MeRMfZye+mT6x/+8AdcvXoVjo6OeO+990BELd6heP/+fUybNg03b97E3bt30aVLF8yYMQPAk/lvEydOhFwuBxHh6tWrGtsAYMWKFfj888+xZcsW3Lt3DxMnTsTbb7+Nn376CfPnz8eiRYtQV1cHqVSKAwcO4Nq1a3Bzc8NHH33Urk/eUdyJ2tzc3Kr1v//+e+VE9JYY+3FkjL3cXvrkqqvg4GCsWbMGdnZ2sLe3x6RJk/Dw4UOdHpquS9kqbUqQCUnXcmMVFRUqdwmPGTNGq/WM/Tgyxl5u/GzhNlL8TqvL3MPWlq3StgRZR7KxsVFWHgGeTAl49jmu2ugsx7GwsBBpaWk6r/eyUjzMno8Z06Q1xQ46C06uOvr222+xadMm5OXlobKyslUf0E+XrVq5cqXKMmdnZ0Hi1JeRI0di5MiRL+zXWY/jjz/+iGnTprXLto0ZHzP2suHLwjq4ffs2pkyZAicnJ5w9exYVFRWIj4/XeTtCl63qbDrzcQwODlYbi/+e/6e4uUzfcfCfYf4pXh/GiL+56uDSpUtobGzE/Pnz4ebmBuDJA651JVTZqs6KjyNjzNjxN1cdKOpEnjhxAvX19cjPz8fZs2dV+mgq4fVsm6mp6QvLVulLR5QbexmOI2PsJUdGRtcqCzdv3qTf/e53BIDMzMxo2LBhdPDgQfriiy/I0dGRAJC1tTVNnTqViIiWL19O9vb2ZGtrSyEhIbRt2zYCQHK5nG7fvk3nz5+nPn36kKWlJb3++utUVFSkse3Ro0e0fPly6t27N5mZmVH37t0pKCiI8vLyaPv27WRlZUUAqF+/fnTt2jXauXMnyWQyAkB9+vShX3/9VafjcubMGXrttdfI2dmZABAAcnJyIl9fX/rhhx+U/Y4dO0ZSqZRiY2Ofu61//etf5OHhobKdMWPGaOxrTMfREKridDZGXPWECcCIXx9pIiLSrsBfJ5GWloZp06bByHaLGYCQkBAAQHp6up4j6Tz4/chaYsSvj3S+LMwYY4wJjJNrJ/XLL7+0WPJN8aeP2o6MMfay4+TaSQ0YMECrW93379+v71AZa3cnTpxAZGSkWq3hd955R63v2LFjIZVKYWpqikGDBuH8+fN6iFh7I0eOfO4/np99DvpXX30Fb29vSKVS9OnTB7NmzUJRUVGL26+vr8eAAQNU5oofOXIE8fHxOj3Uhani5MoY69TWrFmDpKQkREVFqdQa7tq1K/bu3Ytvv/1Wpf/f/vY3pKenY+LEicjLy8OwYcP0FHnbvf7668r/PnDgAGbMmIGQkBAUFhYiMzMTp06dwvjx4/H48ePnbiM6OhpXrlxRaZs0aRIkEgnGjBmj8gQ2pj1Orox1Ih1R07Yz1c3duHEj9u/fj7S0NEilUpVlSUlJMDExQVhYGCoqKvQUYdtJJBJUVlaqXZUKCwvDp59+quz35z//GT169MCyZctgY2ODoUOHYvHixcjNzVWb6qZw+vRpXL58WeOyhQsX4pVXXsGECRNaTM5MM06ujHUiHVHTtrPUzb169SpWrVqFzz77DBKJRG25r68vIiIicOfOHSxdulQPEQrju+++U/uHQ0FBAS5fvozRo0ertDk7O6s8kKVXr14AgFu3bqltt66uDsuWLUNiYuJzx167di1yc3Nb7MM04+TKWDsiIiQkJGDgwIGwsLCAnZ0dJk+erFJYIDw8HObm5nByclK2ffzxx7C2toZIJEJJSQkAzXVuk5KSIJFI4ODggLlz58LZ2RkSiQS+vr4q31baMgbQcXV+dZGUlAQiwqRJk57bJzY2Fh4eHti1axdOnDjR4va0OVe61AhuqdZwW23cuBELFy5UaXNzc1P7R5Hi91bFk9CeFh0djY8//lj5GFFN7Ozs4O/vj8TERGOcLtO+OnJWbUcw4knJTM9a8xCJ1atXk7m5Oe3Zs4fKy8vp4sWLNGzYMOrWrRsVFRUp+82YMYMcHR1V1t20aRMBoAcPHijbgoKCSC6Xq/QLCwsja2tr+vnnn6m+vp7y8vLI29ubpFIp3b59W5Axjh49SlKplGJiYnTa//Z8P7q5uZGnp6fGZXK5nG7cuEFERKdPnyYTExPq27cvVVdXExFRVlYWBQYGqqyj7bmKjo4mAHTy5EmqqKig4uJi8vPzI2tra2poaFD2W7p0KVlYWNDBgweprKyMoqKiyMTEhM6dO9em/S4sLCRPT09qampSac/OziaxWExJSUlUWVlJly9fpoEDB9Kbb76pto2cnByaNGkSERE9ePCAAFB0dLTG8SIjIwkAXbhwoU1xa2LEn9dp/M2VsXZSV1eHhIQETJ06FTNnzoSNjQ28vLywY8cOlJSUYOfOnYKNZWZmpvzG5enpieTkZFRVVanVtW0tXev8treamhrcuHEDcrn8hX19fHywaNEi3Lx5EytWrNDYpzXnqqUawbrUGtbVxo0bsWDBApiYqH58+/v7Y/ny5QgPD4dMJsPgwYNRVVWFXbt2qe1rREQEkpOTtRqvX79+AJ48E5xpj5MrY+0kLy8P1dXVGD58uEq7t7c3zM3Nn3uTiRCGDx8OKyurFuvadmbFxcUgIlhZWWnVPzY2Fv3798f27duRk5Ojtryt5+rZGsGtrTX8Infv3sWRI0fw/vvvqy2Ljo7Gzp07cfLkSVRXV+P69evw9fWFj48PCgoKlP2ioqIwZ84cuLi4aDWm4hjfv3+/1XG/jDi5MtZOFFMYnp2LCAC2traoqqpq1/EtLCzw4MGDdh1DX+rr6wE82UdtSCQSpKamQiQS4YMPPkBdXZ3KcqHP1dO1hp+el3rr1i3U1tbqtK2nxcfH46OPPlK7gevevXuIj4/HnDlzMHr0aFhbW8PV1RUpKSm4e/cuNm3aBADIycnBpUuX8OGHH2o9pqWlJYDfjjnTDidXxtqJra0tAGj8YC4vL0fPnj3bbezGxsZ2H0OfFB/4ujzkwMfHB4sXL0Z+fj7WrVunskzoc9UetYaLiorw1VdfYf78+WrL8vPz0dTUhB49eqi0y2Qy2NvbIy8vD8CTO8FPnjwJExMTZcJXxLp+/XqIRCL89NNPKttoaGgA8NsxZ9rh5MpYOxk8eDC6dOmi9mF19uxZNDQ04NVXX1W2mZmZKS8pCiE7OxtEhBEjRrTbGPrk4OAAkUik8/zVdevWYcCAAbhw4YJKuy7nShvtUWs4Pj4eM2fOhL29vdoyRfJ/ttRiVVUVSktLlVNyUlNT1ZK94upGdHQ0iEjt0rjiGDs6Ogq2Ly8DTq6MtROJRIIlS5bg8OHD2Lt3LyorK3Hp0iXMmzcPzs7OCAsLU/Z1d3dHaWkpMjIy0NjYiAcPHmicm6ipzi0ANDc3o6ysDI8fP8bFixcRERGB3r17q/w215YxOqLOry6srKzg5uaGwsJCndZTXB42NTVVa9f2XGk7zotqDYeGhsLR0VGrxy/ev38fX375JRYtWqRxuaurK0aNGoWUlBScOnUKdXV1KCgoUMY9e/ZsneJ/muIYe3l5tXobLyU93abcboz41m6mZ62ZitPc3EybNm2ifv36kVgsJjs7O5oyZQpduXJFpd/Dhw9p1KhRJJFIyNXVlRYsWEDLli0jAOTu7q6cUqOppm1YWBiJxWJycXEhMzMzkslkNHnyZLp27ZpgY2hT51eT9nw/hoeHk1gsptraWmXb4cOHSS6XEwDq1q0bffLJJxrXXbZsmdpUHG3OlS41gluqNUxENGXKFAJAq1evfuG+Ll68mGbOnNlin5KSEoqIiCB3d3eysLCgLl260GuvvUbffPNNi+u9aCpOQEAAubi4UHNz8wvj1JURf16nGd1eGfHJYnpmqMXSw8LCyN7eXt9haNSe78f8/HwyMzOjPXv2tMv221tTUxP5+fnR7t279R3Kc5WUlJBEIqHNmze3y/aN+POa57kyZgxexuol7u7uiImJQUxMDKqrq/Udjk6ampqQkZGBqqoqgy4LuXbtWgwdOhTh4eH6DqXT4eTKGOu0IiMjERISgtDQ0E71cP7s7GwcOnQIWVlZWs/V7WgJCQnIzc3FsWPHIBaL9R1Op8PJlbFOLCoqCqmpqaioqICrqysOHjyo75A63Pr16xEeHo4NGzboOxStjRkzBvv27VN51rMhyczMxKNHj5CdnQ07Ozt9h9Mpmek7AMZY68XFxSEuLk7fYejd2LFjMXbsWH2HYTQCAwMRGBio7zA6Nf7myhhjjAmMkytjjDEmME6ujDHGmMA4uTLGGGMCM9obmkJCQvQdAjMyP/74IwB+belC8eg8PmZME10fX9mZiIiI9B2EkM6cOYOEhAR9h8GYoIqKinDhwgWMHz9e36EwJrj09HR9hyC0dKNLrowZo7S0NEybNg38dmWsU0jn31wZY4wxgXFyZYwxxgTGyZUxxhgTGCdXxhhjTGCcXBljjDGBcXJljDHGBMbJlTHGGBMYJ1fGGGNMYJxcGWOMMYFxcmWMMcYExsmVMcYYExgnV8YYY0xgnFwZY4wxgXFyZYwxxgTGyZUxxhgTGCdXxhhjTGCcXBljjDGBcXJljDHGBMbJlTHGGBMYJ1fGGGNMYJxcGWOMMYFxcmWMMcYExsmVMcYYExgnV8YYY0xgnFwZY4wxgXFyZYwxxgTGyZUxxhgTGCdXxhhjTGCcXBljjDGBcXJljDHGBMbJlTHGGBMYJ1fGGGNMYGb6DoAxpqqxsRHV1dUqbTU1NQCAsrIylXaRSARbW9sOi40xph1OrowZmNLSUri4uKCpqUltmb29vcr/jxo1Ct9//31HhcYY0xJfFmbMwDg6OuL3v/89TExafnuKRCJMnz69g6JijOmCkytjBuidd955YR9TU1NMnTq1A6JhjOmKkytjBigoKAhmZs//1cbU1BTjxo1D165dOzAqxpi2OLkyZoBkMhnGjx//3ARLRJg5c2YHR8UY0xYnV8YM1MyZMzXe1AQA5ubm+OMf/9jBETHGtMXJlTED9cc//hFWVlZq7WKxGFOmTIG1tbUeomKMaYOTK2MGSiKRYOrUqRCLxSrtjY2NmDFjhp6iYoxpg5MrYwbs7bffRmNjo0qbTCbDH/7wBz1FxBjTBidXxgzYG2+8ofLgCLFYjOnTp8Pc3FyPUTHGXoSTK2MGzMzMDNOnT1deGm5sbMTbb7+t56gYYy/CyZUxAzd9+nTlpWFHR0e8/vrreo6IMfYinFwZM3C+vr5wcXEBALz77rsvfCwiY0z/+MH9/1VYWIjTp0/rOwzGNPL29sadO3fQtWtXpKWl6TscxjR666239B2CwRAREek7CEOQlpaGadOm6TsMxhjrtDidKKXzN9dn8IuD6SokJAQAkJ6e3q7jHDx4EMHBwe06RkdR/GOW32/Ggb+cqOMfbxjrJIwlsTL2MuDkyhhjjAmMkytjjDEmME6ujDHGmMA4uTLGGGMC4+TKGGOMCYyTK2MG4tixY7CxscFf//pXfYdi8E6cOIHIyEgcOnQIbm5uEIlEEIlEeOedd9T6jh07FlKpFKamphg0aBDOnz+vh4i1N3LkSOX+PPvXpUsXlb5fffUVvL29IZVK0adPH8yaNQtFRUUtbr++vh4DBgzAypUrlW1HjhxBfHw8mpqa2mWfXkacXBkzEDznUztr1qxBUlISoqKiEBQUhOvXr0Mul6Nr167Yu3cvvv32W5X+f/vb35Ceno6JEyciLy8Pw4YN01Pkbff0c6UPHDiAGTNmICQkBIWFhcjMzMSpU6cwfvx4PH78+LnbiI6OxpUrV1TaJk2aBIlEgjFjxqC8vLzd4n+ZcHJlzEAEBASgoqICEydO1HcoqKurg6+vr77DULNx40bs378faWlpkEqlKsuSkpJgYmKCsLAwVFRU6CnCtpNIJKisrAQRqfyFhYXh008/Vfb785//jB49emDZsmWwsbHB0KFDsXjxYuTm5uLs2bMat3369GlcvnxZ47KFCxfilVdewYQJE1pMzkw7nFwZY2p2796N4uJifYeh4urVq1i1ahU+++wzSCQSteW+vr6IiIjAnTt3sHTpUj1EKIzvvvtO7R8OBQUFuHz5MkaPHq3S5uzsDJFIpGzr1asXAODWrVtq262rq8OyZcuQmJj43LHXrl2L3NzcFvsw7XByZcwA5OTkoHfv3hCJRNi2bRsAIDk5GdbW1rCyskJmZibGjx8PmUyGnj174uuvv1aum5SUBIlEAgcHB8ydOxfOzs6QSCTw9fVV+QYTHh4Oc3NzODk5Kds+/vhjWFtbQyQSoaSkBAAQERGBJUuW4Nq1axCJRHB3dwfw5ENfJpNh/fr1HXFI1CQlJYGIMGnSpOf2iY2NhYeHB3bt2oUTJ060uD0iQkJCAgYOHAgLCwvY2dlh8uTJ+OWXX5R9tD0HANDU1ITVq1ejd+/esLS0xJAhQ3DgwIG27fR/bdy4EQsXLlRpc3NzU/sHkOL3Vjc3N7VtREdH4+OPP0b37t2fO46dnR38/f2RmJjIP1O0FTEiIjpw4ADx4WCtERwcTMHBwW3eTkFBAQGgrVu3Ktuio6MJAJ08eZIqKiqouLiY/Pz8yNramhoaGpT9wsLCyNramn7++Weqr6+nvLw88vb2JqlUSrdv31b2mzFjBjk6OqqMu2nTJgJADx48ULYFBQWRXC5X6Xf06FGSSqUUExPT5n1tzfvNzc2NPD09NS6Ty+V048YNIiI6ffo0mZiYUN++fam6upqIiLKysigwMFBlndWrV5O5uTnt2bOHysvL6eLFizRs2DDq1q0bFRUVKftpew6WLl1KFhYWdPDgQSorK6OoqCgyMTGhc+fO6bSfzyosLCRPT09qampSac/OziaxWExJSUlUWVlJly9fpoEDB9Kbb76pto2cnByaNGkSERE9ePCAAFB0dLTG8SIjIwkAXbhwQesY+fNTTRp/c2WsE/D19YVMJkP37t0RGhqKmpoa3L59W6WPmZmZ8luYp6cnkpOTUVVVhdTUVEFiCAgIQGVlJVatWiXI9nRRU1ODGzduQC6Xv7Cvj48PFi1ahJs3b2LFihUa+9TV1SEhIQFTp07FzJkzYWNjAy8vL+zYsQMlJSXYuXOn2jotnYP6+nokJydjypQpCAoKgq2tLVauXAmxWNzm479x40YsWLBArY6vv78/li9fjvDwcMhkMgwePBhVVVXYtWuX2r5GREQgOTlZq/H69esHALh06VKb4n7ZcXJlrJMxNzcHADQ2NrbYb/jw4bCyslK5zNlZFRcXg4hgZWWlVf/Y2Fj0798f27dvR05OjtryvLw8VFdXY/jw4Srt3t7eMDc3f+4NQQrPnoMrV66gtrYWgwcPVvaxtLSEk5NTm47/3bt3ceTIEbz//vtqy6Kjo7Fz506cPHkS1dXVuH79Onx9feHj44OCggJlv6ioKMyZMwcuLi5ajak4xvfv32913IyTK2NGzcLCAg8ePNB3GG1WX18P4Mn+aEMikSA1NRUikQgffPAB6urqVJYrpps8O28UAGxtbVFVVaVTfDU1NQCAlStXqsxLvXXrFmpra3Xa1tPi4+Px0Ucfqd3Ade/ePcTHx2POnDkYPXo0rK2t4erqipSUFNy9exebNm0C8OS3/EuXLuHDDz/UekxLS0sAEvfIHwAAIABJREFUvx1z1jqcXBkzUo2NjSgvL0fPnj31HUqbKT7wdXnIgY+PDxYvXoz8/HysW7dOZZmtrS0AaEyirTlmipuEtmzZojaF5syZMzptS6GoqAhfffUV5s+fr7YsPz8fTU1N6NGjh0q7TCaDvb098vLyADy56/vkyZMwMTFRJnxFrOvXr4dIJMJPP/2kso2GhgYAvx1z1jqcXBkzUtnZ2SAijBgxQtlmZmb2wsvJhsjBwQEikUjn+avr1q3DgAEDcOHCBZX2wYMHo0uXLmqJ5ezZs2hoaMCrr76q0zi9evWCRCJBbm6uTuu1JD4+HjNnzoS9vb3aMkXyv3fvnkp7VVUVSktLlVNyUlNT1ZK94kpGdHQ0iEjt0rjiGDs6Ogq2Ly8jTq6MGYnm5maUlZXh8ePHuHjxIiIiItC7d2+V3+vc3d1RWlqKjIwMNDY24sGDBxrnRNrb2+Pu3bu4efMmqqqq0NjYiKysLL1NxbGysoKbmxsKCwt1Wk9xedjU1FStfcmSJTh8+DD27t2LyspKXLp0CfPmzYOzszPCwsJ0HmfWrFn4+uuvkZycjMrKSjQ1NaGwsFCZAENDQ+Ho6KjV4xfv37+PL7/8EosWLdK43NXVFaNGjUJKSgpOnTqFuro6FBQUKOOePXu2TvE/TXGMvby8Wr0NBr53WoFvJWetJcRUnK1bt5KTkxMBICsrK5o0aRJt376drKysCAD169ePrl27Rjt37iSZTEYAqE+fPvTrr78S0ZOpOGKxmFxcXMjMzIxkMhlNnjyZrl27pjLOw4cPadSoUSSRSMjV1ZUWLFhAy5YtIwDk7u6unLZz/vx56tOnD1laWtLrr79ORUVFdOzYMZJKpRQbG9umfSVq3fstPDycxGIx1dbWKtsOHz5McrmcAFC3bt3ok08+0bjusmXL1KbiNDc306ZNm6hfv34kFovJzs6OpkyZQleuXFH20eUcPHr0iJYvX069e/cmMzMz6t69OwUFBVFeXh4REU2ZMoUA0OrVq1+4r4sXL6aZM2e22KekpIQiIiLI3d2dLCwsqEuXLvTaa6/RN9980+J6L5qKExAQQC4uLtTc3PzCOBX481NNGh+N/+IXB2stoea5tkVYWBjZ29vrNQZdtOb9lp+fT2ZmZrRnz552iqp9NTU1kZ+fH+3evVvfoTxXSUkJSSQS2rx5s07r8eenGp7nypixMPaKJu7u7oiJiUFMTAyqq6v1HY5OmpqakJGRgaqqKoSGhuo7nOdau3Ythg4divDwcH2H0ulxchXQhx9+CKlUCpFIJOiNDR0pPj4eAwYMgKWlJaytrTFgwACsWrUKlZWVOm/r2XJgij9zc3M4ODhg5MiR2LRpE8rKytphT5gxioyMREhICEJDQzvVw/mzs7Nx6NAhZGVlaT1Xt6MlJCQgNzcXx44dg1gs1nc4nR4nVwHt2rULKSkp+g6jTf75z3/io48+wu3bt3H//n2sW7cO8fHxCA4O1nlbT5cDs7GxARGhubkZxcXFSEtLg6urK5YvX45Bgwap3bXJtBcVFYXU1FRUVFTA1dUVBw8e1HdI7Wr9+vUIDw/Hhg0b9B2K1saMGYN9+/apPNfZkGRmZuLRo0fIzs6GnZ2dvsMxCmb6DoAZFnNzc3z88cfKSeshISFIT09Heno67t27B2dn5zZtXyQSwdbWFiNHjsTIkSMREBCAadOmISAgAL/++itsbGyE2I2XSlxcHOLi4vQdRocaO3Ysxo4dq+8wjEZgYCACAwP1HYZR4W+uAnu6/FNndPjwYbWnwSgem9Yev3MFBwfj/fffR3FxMXbs2CH49hljTB84ubYBEWHTpk3o378/LCwsYGNjg2XLlqn1a6kUlS4lrX744Qf8z//8D6ysrCCTyeDl5aX8LbQ9y13l5+fD1tYWffr0UbYJWX5MMQ8zKytL2dbZjxlj7CWn7/uVDUVrbiWPjo4mkUhEX3zxBZWVlVFtbS1t375drVzTi0pRaVPSqrq6mmQyGcXHx1NdXR0VFRXR1KlTlWXChC531dDQQIWFhbR161aysLBQm/6gS/kxuVxONjY2z11eWVlJAKhXr17Kts50zAxhKk5nw1M3jAufTzU8z1VB1xdH7f9n797Doqr3/YG/BxhmuMxwUUDUUGAsRQ23aclYmXk2PeYRRUQprLTakWmIKCF4yRBRwwfZmJwSPeyzJQO8hGVqHvVBa+d216MkwqnwgoJKgBcYbnL7/P7YPyaXM+AMLJgBP6/nmT/8ru9a6zNrOfNhrVnf76eujmxtbenPf/6zoP2LL74QJNf6+nqytbWlkJAQwboymYzee+89IvojUdTX12v7tCXpixcvEhHRhQsXCAAdPHhQJxZD9mEsNzc3AkD9+vWjv/71r4K6lcZ6WHIlIpJIJOTo6EhEve+YcXI1Hn8Z9y18PnVk8wNNnXTx4kXU1dVhypQpHfbrbCmqB0taeXl5wdXVFfPmzcOSJUswf/58DB06tEv76EhJSQnu3r2Lc+fOISYmBtu3b8eJEyfg6uraqe11pLa2FkQEpVIJoHces3/+858IDg42er1HVdsUe3zM+gZjp6V8FPBvrp3U9p+prcJEe8QqRWVjY4MTJ07g2Wefxfr16+Hl5YWQkBDU19d3S7krqVQKFxcX+Pv7IzMzEwUFBd32ROpvv/0GABg+fDiA3nvMGGOsDV+5dlLbE7X37t3rsN/9pagiIiK6tM+RI0fi66+/RkVFBZKSkrBx40aMHDlSO+OLGPvQR6VSwdLSUlvGSmxHjhwBAEydOhVA7zxmEyZMwJ49e7q8nUdFdnY25s6dy8esj2g7n+wPfOXaSaNGjYKFhQVOnjzZYT+xSlHduHEDhYWFAP6dfDZs2ICxY8eisLBQtH3cunULr776qk57W+3ItjJWYiorK8OWLVswePBgvPnmmwB61zFjjDF9OLl2kouLC4KCgrB3717s3LkT1dXVOH/+PLZv3y7oZ0gpKkPcuHED7777Ln755Rc0Njbi3LlzuHr1KiZMmCDaPuzs7HD06FGcOHEC1dXVaGpqwrlz5/DGG2/Azs4OkZGR2r7Glh8jItTU1KC1tVVbUzIrKwsTJ06EpaUlcnJytL+59qZjxhhjepn4iSqz0Zmn3TQaDb399tvUr18/sre3p2effZbWrFlDAGjw4MH0888/E1HHpagMLWlVXFxMarWanJycyNLSkgYOHEgrV66k5ubmh+7DGAEBAeTp6Un29vYkk8nI29ubQkJCKD8/X9DPkPJjX331FT355JNka2tL1tbWZGFhQQC0TwY//fTTFBcXR7du3dJZtzcdM35a2Hj8dGnfwudTR7aEiMhkmd2MtP1mwIeDGavtiVf+/dBw/HnrW/h86tjDt4UZY4wxkXFy7eN++eUXnZJv+l7mXGOSsQcdO3YMMTExOmUNX3vtNZ2+/v7+UCgUsLS0xMiRI3H27FkTRGy81tZWbNmyBWq1Wu/yuLg4+Pj4QKlUQiaTQaVS4YMPPtA7B/ju3bsxfvx4KBQKDBkyBAsWLEBZWZl2+VdffYVNmzb1+ZrAPYmTax83fPhwENFDX5mZmaYOlTGDfPjhh0hJSUFsbKygrGG/fv2QkZGBb775RtD/6NGj2LNnD6ZPn46CggKMHTvWRJEbrqioCM8//zwiIyPbHXd94sQJLF68GMXFxaisrERCQgKSk5N1JubIyspCaGgogoODUVpaigMHDuDUqVOYOnUqmpubAQABAQGQy+WYMmUK7t692+3v71HAyZWxPqC+vr7dK5zetI+H2bhxIzIzM5GdnQ2FQiFYlpKSAgsLC4SFhfWqQuoP+vnnn7FixQosXLgQY8aMabefvb09wsLC4OzsDIVCgTlz5iAwMBBHjhxBSUmJtt9nn32GgQMHIioqCg4ODhgzZgwiIyORl5eHM2fOaPstWbIEvr6+ePnll7VJl3UeJ1fG+oCdO3eivLy81++jIxcvXsTq1avx0Ucf6ZRFBAC1Wo2IiAhcv34dy5cvN0GE4vD19cW+ffsQGhoKmUzWbr+DBw/C0tJS0Na/f38AEFztlpSUwN3dXVAOs23M+tWrVwXrr127Fnl5eUhOTu7y+3jUcXJlzASICElJSRgxYgRkMhmcnJwwc+ZMwbzG4eHhsLa2xoABA7RtixYtgp2dHSQSCSorKwEAERERWLZsGS5dugSJRAKVSoWUlBTI5XK4urri3Xffhbu7O+RyOdRqteBqpSv7AMQtPfgwKSkpICIEBAS02yc+Ph6PP/44duzYgWPHjnW4PUPOgTHlDc2hhOH169dhY2MDT09PbZuXl5fOH0Vtv7d6eXkJ2p2cnDBp0iQkJyfzk79d1dODf8wVj9NindWZca5r1qwha2tr2rVrF929e5fOnz9PY8eOpf79+1NZWZm2X2hoKLm5uQnWTUxMJADa0nlEREFBQeTt7S3oFxYWRnZ2dlRYWEgNDQ1UUFBA48ePJ4VCQdeuXRNlH8aUHrxfZz5vXl5e5OPjo3eZt7c3XblyhYiIfvjhB7KwsKChQ4dSTU0NEREdPnyYZsyYIVjH0HNgSHlDIvHLPhIRPfPMM+Tr62tQ39raWlIoFBQeHi5oz83NJalUSikpKVRdXU0XLlygESNG0EsvvaR3OzExMTplMx+Gvz91ZPOVK2M9rL6+HklJSZg1axbmzZsHBwcHjB49Gp9++ikqKyt1ZvnqCisrK+2VmY+PD1JTU6HRaJCeni7K9qdNm4bq6mqsXr1alO21p7a2FleuXIG3t/dD+/r5+WHp0qUoLi7GihUr9PbpzDlQq9VQKpVwcXFBSEgIamtrce3aNQBAQ0MDUlNTERgYiKCgIDg6OmLVqlWQSqWiHeuHSUhIgLu7O+Lj4wXtkyZNQnR0NMLDw6FUKjFq1ChoNBrs2LFD73aGDRsGAMjPz+/2mPsyTq6M9bCCggLU1NRg3Lhxgvbx48fD2tpacNtWbOPGjYOtrW2nSxGaSnl5OYgItra2BvWPj4/HE088gW3btuH777/XWd7Vc/BgecPuKPtojP379yM7OxvffvutzoNeK1euxPbt23H8+HHU1NTg8uXLUKvV8PPzEzz41KbtGP/+++/dHndfxsmVsR7WNtTB3t5eZ5mjoyM0Gk237l8mk6GioqJb9yG2hoYGAOjwAZ/7yeVypKenQyKR4M0330R9fb1gudjnwJQlDDMzM7Fx40bk5uZq6xW3uXnzJjZt2oR33nkHL774Iuzs7ODp6Ym0tDTcuHEDiYmJOtuzsbEB8McxZ53DyZWxHubo6AgAer/A7969i8GDB3fbvpuamrp9H92h7QvfmEkO/Pz8EBkZiaKiIqxbt06wTOxzcH+ZRHpgDPnp06eN2pYxtm7dioyMDJw4cQIDBw7UWd5W0erBZUqlEs7OznrLSDY2NgL445izzuHkylgPGzVqFOzt7fHTTz8J2s+cOYPGxkY89dRT2jYrKyvtrUcx5ObmgogwYcKEbttHd3B1dYVEIjF6/Oq6deswfPhwnDt3TtBuzDkwRE+XMCQiREdHIz8/Hzk5OXqvwAFo/0h4sNKTRqPB7du39ZaRbDvGbm5uIkf9aOHkylgPk8vlWLZsGfbv34+MjAxUV1cjPz8fCxcuhLu7O8LCwrR9VSoVbt++jZycHDQ1NaGiokJnbCIAODs748aNGyguLoZGo9Emy9bWVty5cwfNzc04f/48IiIi4OHhgfnz54uyD2NLD3aWra0tvLy8UFpaatR6bbeHHxwPasw5MHQ/DythGBISAjc3N1GmXywsLMTHH3+MtLQ0SKVSnelMN2/eDADw9PTE5MmTkZaWhlOnTqG+vh4lJSXa9/fWW2/pbLvtGI8ePbrLcT7STPioslnhR8lZZ3VmKE5rayslJibSsGHDSCqVkpOTEwUGBtKvv/4q6Hfr1i2aPHkyyeVy8vT0pPfff5+ioqIIAKlUKu2QmrNnz9KQIUPIxsaGnn32WSorK6OwsDCSSqU0aNAgsrKyIqVSSTNnzqRLly6Jtg9DSg/q05nPW3h4OEmlUqqrq9O27d+/n7y9vQkA9e/fnxYvXqx33aioKJ2hOIacA0PLGxI9vIRhYGAgAaA1a9Z0+D5Pnz5NEydOJHd3dwJAAGjAgAGkVqvp5MmTRESUn5+vXabvlZiYqN1eZWUlRUREkEqlIplMRvb29jRx4kT68ssv9e5/2rRpNGjQIGptbe0wzvvx96eObD4a/x//52CdZa71XMPCwsjZ2dnUYejVmc9bUVERWVlZ0a5du7opqu7V0tJCzz33HO3cudPUobSrsrKS5HI5bd682aj1+PtTB49zZawv60tVTlQqFeLi4hAXF6e38os5a2lpQU5ODjQajVlXoFq7di3GjBmD8PBwU4fS63FyZYz1GjExMQgODkZISEivmpw/NzcX+/btw+HDhw0eq9vTkpKSkJeXh0OHDkEqlZo6nF6PkytjfVBsbCzS09NRVVUFT09P7N2719QhiWb9+vUIDw/Hhg0bTB2KwaZMmYLPP/9cMIezOTlw4ADu3buH3NxcODk5mTqcPsHK1AEwxsSXkJCAhIQEU4fRbfz9/eHv72/qMPqMGTNmYMaMGaYOo0/hK1fGGGNMZJxcGWOMMZFxcmWMMcZExsmVMcYYExknV8YYY0xk/LTwAyQSialDYL0U/98xHh8z1ldxcv3/1Go1srKyTB0GY3qdPn0aycnJ/H+UsV5CQkRk6iAYYx3Lzs7G3LlzwR9XxnqFPfybK2OMMSYyTq6MMcaYyDi5MsYYYyLj5MoYY4yJjJMrY4wxJjJOrowxxpjIOLkyxhhjIuPkyhhjjImMkytjjDEmMk6ujDHGmMg4uTLGGGMi4+TKGGOMiYyTK2OMMSYyTq6MMcaYyDi5MsYYYyLj5MoYY4yJjJMrY4wxJjJOrowxxpjIOLkyxhhjIuPkyhhjjImMkytjjDEmMk6ujDHGmMg4uTLGGGMi4+TKGGOMiYyTK2OMMSYyTq6MMcaYyDi5MsYYYyLj5MoYY4yJjJMrY4wxJjJOrowxxpjIOLkyxhhjIuPkyhhjjInMytQBMMaEKioq8OWXXwrafvrpJwDA9u3bBe0KhQKvvPJKj8XGGDOMhIjI1EEwxv5w7949uLq6oqamBpaWlgCAto+pRCLR9mtqasIbb7yBv/3tb6YIkzHWvj18W5gxMyOTyTB79mxYWVmhqakJTU1NaG5uRnNzs/bfTU1NAIBXX33VxNEyxvTh5MqYGXr11VfR2NjYYR9HR0e8+OKLPRQRY8wYnFwZM0OTJ0+Gi4tLu8ulUinmzZsHKyt+bIIxc8TJlTEzZGFhgdDQUEilUr3Lm5qa+EEmxswYJ1fGzNQrr7yi/W31QQMHDoSfn18PR8QYMxQnV8bM1NNPP40hQ4botFtbW+ONN94QPDnMGDMvnFwZM2Ovvfaazq3hxsZGviXMmJnj5MqYGQsNDdW5NaxSqTB69GgTRcQYMwQnV8bM2PDhw+Hj46O9BSyVSrFgwQITR8UYexhOroyZuddff107U1NzczPfEmasF+DkypiZe+WVV9DS0gIAGDt2LDw9PU0cEWPsYTi5MmbmPDw88MwzzwAA3njjDRNHwxgzhFlN75KUlITTp0+bOgzGzM69e/cgkUhw9OhRnDp1ytThMGZ2IiMjzWrst1lduZ4+fRr//Oc/TR0GY2Zn8ODBcHNzg1wuF7SXlpZi7969Joqq99q7dy9KS0tNHQYTyd69e1FSUmLqMATM6soVACZMmIA9e/aYOgzGzM7FixehUqkEbdnZ2Zg7dy5/ZowkkUiwdOlSzJkzx9ShMBGY44QqZnXlyhhr34OJlTFmvji5MsYYYyLj5MoYY4yJjJMrY4wxJjJOrowxxpjIOLkyxnDo0CE4ODjg66+/NnUoZu/YsWOIiYnBvn374OXlBYlEAolEgtdee02nr7+/PxQKBSwtLTFy5EicPXvWBBEbr7W1FVu2bIFarda7PC4uDj4+PlAqlZDJZFCpVPjggw9QU1Oj03f37t0YP348FAoFhgwZggULFqCsrEy7/KuvvsKmTZu0s5D1FZxcGWMgIlOH0Ct8+OGHSElJQWxsLIKCgnD58mV4e3ujX79+yMjIwDfffCPof/ToUezZswfTp09HQUEBxo4da6LIDVdUVITnn38ekZGRqKur09vnxIkTWLx4MYqLi1FZWYmEhAQkJycjODhY0C8rKwuhoaEIDg5GaWkpDhw4gFOnTmHq1Klobm4GAAQEBEAul2PKlCm4e/dut7+/nsLJlTGGadOmoaqqCtOnTzd1KKivr2/3ismUNm7ciMzMTGRnZ0OhUAiWpaSkwMLCAmFhYaiqqjJRhF33888/Y8WKFVi4cCHGjBnTbj97e3uEhYXB2dkZCoUCc+bMQWBgII4cOSKYzOGzzz7DwIEDERUVBQcHB4wZMwaRkZHIy8vDmTNntP2WLFkCX19fvPzyy9qk29txcmWMmZWdO3eivLzc1GEIXLx4EatXr8ZHH32kM0sWAKjVakREROD69etYvny5CSIUh6+vL/bt24fQ0FDIZLJ2+x08eFBbqalN//79AUBwtVtSUgJ3d3fBJA+PPfYYAODq1auC9deuXYu8vDwkJyd3+X2YA06ujD3ivv/+e3h4eEAikeCTTz4BAKSmpsLOzg62trY4cOAApk6dCqVSicGDB+OLL77QrpuSkgK5XA5XV1e8++67cHd3h1wuh1qtFlyZhIeHw9raGgMGDNC2LVq0CHZ2dpBIJKisrAQAREREYNmyZbh06RIkEol24owjR45AqVRi/fr1PXFIdKSkpICIEBAQ0G6f+Ph4PP7449ixYweOHTvW4faICElJSRgxYgRkMhmcnJwwc+ZM/PLLL9o+hp4DAGhpacGaNWvg4eEBGxsbPPnkk8jKyuramzbS9evXYWNjI6ja5OXlpfOHUtvvrV5eXoJ2JycnTJo0CcnJyX3jZwoyI7Nnz6bZs2ebOgzGeo2srCwS42NcUlJCAGjr1q3atpUrVxIAOn78OFVVVVF5eTk999xzZGdnR42Njdp+YWFhZGdnR4WFhdTQ0EAFBQU0fvx4UigUdO3aNW2/0NBQcnNzE+w3MTGRAFBFRYW2LSgoiLy9vQX9Dh48SAqFguLi4rr8XomIAFBWVpbB/b28vMjHx0fvMm9vb7py5QoREf3www9kYWFBQ4cOpZqaGiIiOnz4MM2YMUOwzpo1a8ja2pp27dpFd+/epfPnz9PYsWOpf//+VFZWpu1n6DlYvnw5yWQy2rt3L925c4diY2PJwsKCfvzxR4Pf44OeeeYZ8vX1NahvbW0tKRQKCg8PF7Tn5uaSVCqllJQUqq6upgsXLtCIESPopZde0rudmJgYAkDnzp0zKlZjz2cPyOYrV8ZYh9RqNZRKJVxcXBASEoLa2lpcu3ZN0MfKykp7Febj44PU1FRoNBqkp6eLEsO0adNQXV2N1atXi7I9Y9TW1uLKlSvw9vZ+aF8/Pz8sXboUxcXFWLFihd4+9fX1SEpKwqxZszBv3jw4ODhg9OjR+PTTT1FZWYnt27frrNPROWhoaEBqaioCAwMRFBQER0dHrFq1ClKpVLTj/zAJCQlwd3dHfHy8oH3SpEmIjo5GeHg4lEolRo0aBY1Ggx07dujdzrBhwwAA+fn53R5zd+PkyhgzmLW1NQCgqampw37jxo2Dra2t4DZnb1VeXg4igq2trUH94+Pj8cQTT2Dbtm34/vvvdZYXFBSgpqYG48aNE7SPHz8e1tbWgtvp+jx4Dn799VfU1dVh1KhR2j42NjYYMGBAjxz//fv3Izs7G99++63Og14rV67E9u3bcfz4cdTU1ODy5ctQq9Xw8/PTW8Wm7Rj//vvv3R53d+PkyhjrFjKZDBUVFaYOo8saGhoAoMMHfO4nl8uRnp4OiUSCN998E/X19YLlbcNN7O3tddZ1dHSERqMxKr7a2loAwKpVq7RjbiUSCa5evdruUBqxZGZmYuPGjcjNzcXQoUMFy27evIlNmzbhnXfewYsvvgg7Ozt4enoiLS0NN27cQGJios72bGxsAPxxzHszTq6MMdE1NTXh7t27GDx4sKlD6bK2L3xjJjnw8/NDZGQkioqKsG7dOsEyR0dHANCbRDtzzFxcXAAAW7ZsAREJXqdPnzZqW8bYunUrMjIycOLECQwcOFBneVFREVpaWnSWKZVKODs7o6CgQGedxsZGAH8c896MkytjTHS5ubkgIkyYMEHbZmVl9dDbyebI1dUVEonE6PGr69atw/Dhw3Hu3DlB+6hRo2Bvb4+ffvpJ0H7mzBk0NjbiqaeeMmo/jz32GORyOfLy8oxar7OICNHR0cjPz0dOTo7eK3AA2j8Sbt68KWjXaDS4ffu2dkjO/dqOsZubm8hR9zxOroyxLmttbcWdO3fQ3NyM8+fPIyIiAh4eHpg/f762j0qlwu3bt5GTk4OmpiZUVFTojHUEAGdnZ9y4cQPFxcXQaDRoamrC4cOHTTYUx9bWFl5eXigtLTVqvbbbww+OB5XL5Vi2bBn279+PjIwMVFdXIz8/HwsXLoS7uzvCwsKM3s+CBQvwxRdfIDU1FdXV1WhpaUFpaak2sYWEhMDNzU2U6RcLCwvx8ccfIy0tDVKpVHArWiKRYPPmzQAAT09PTJ48GWlpaTh16hTq6+tRUlKifX9vvfWWzrbbjvHo0aO7HKfJmfBRZR08FIcx44gxFGfr1q00YMAAAkC2trYUEBBA27ZtI1tbWwJAw4YNo0uXLtH27dtJqVQSABoyZAj99ttvRPTvoThSqZQGDRpEVlZWpFQqaebMmXTp0iXBfm7dukWTJ08muVxOnp6e9P7771NUVBQBIJVKpR22c/bsWRoyZAjZ2NjQs88+S2VlZXTo0CFSKBQUHx/fpffaBkYO3QgPDyepVEp1dXXatv3795O3tzcBoP79+9PixYv1rhsVFaUzFKe1tZUSExNp2LBhJJVADf1lAAAgAElEQVRKycnJiQIDA+nXX3/V9jHmHNy7d4+io6PJw8ODrKysyMXFhYKCgqigoICIiAIDAwkArVmzpsP3efr0aZo4cSK5u7sTAAJAAwYMILVaTSdPniQiovz8fO0yfa/ExETt9iorKykiIoJUKhXJZDKyt7eniRMn0pdffql3/9OmTaNBgwZRa2trh3E+yNjz2QOyObky1ouJNc61K8LCwsjZ2dmkMRjL2C/joqIisrKyol27dnVjVN2npaWFnnvuOdq5c6epQ2lXZWUlyeVy2rx5s9HrmmNy5dvCjLEu62sVTR6kUqkQFxeHuLg4vZVfzFlLSwtycnKg0WgQEhJi6nDatXbtWowZMwbh4eGmDkUUnFwZY8wAMTExCA4ORkhISK+anD83Nxf79u3D4cOHDR6r29OSkpKQl5eHQ4cOQSqVmjocUXBy1aOna1uaUy3NTZs2Yfjw4bCxsYGdnR2GDx+O1atXo7q6usvb3r17NyQSSbdUPHmUz5kpxcbGIj09HVVVVfD09MTevXtNHVK3Wr9+PcLDw7FhwwZTh2KwKVOm4PPPPxfM62xODhw4gHv37iE3NxdOTk6mDkc0VqYOwBxRD08a3dP768h3332Hv/zlL3j99ddhY2ODw4cPIzQ0FGfOnMHRo0e7tO3du3fD29sbp0+fxsWLF7WTsovhUT5nppSQkICEhARTh9Gj/P394e/vb+ow+owZM2ZgxowZpg5DdI/8lau+2pHdWduyp/dnLGtrayxatAguLi6wt7dHcHAwZs6cif/93//VGa9mjFu3bqGwsBAfffQRAODvf/97p7fF54wxZu4e+eTa07UjzbFW5f3279+vU69y0KBBANClBzmys7Mxbdo0BAQEQC6XY9euXZ2++uNzxhgzd70+uX733Xfw8fGBg4MD5HI5Ro8ejW+//VbQZ9euXRg3bhzkcjns7OwwdOhQrFu3Tm/tSH21LUeMGAGJRAILCws89dRT2vk6P/jgA+1+//a3vz00HkP3B4hf77ErioqK4OjoiCFDhmjbjK2vuXv3bsyaNQsKhQL+/v4oLi7Gd999125/PmeMsV7NhOOAdHRmnOuePXto7dq1dPv2bbp16xZNmDCB+vXrp12+ZcsWAkAbNmygW7du0e3bt+mzzz6j0NBQItJfO/LB2pbNzc00dOhQ8vDwoObmZkHfpUuX0pYtWwyOx5D9EYlf79FYjY2NVFpaSlu3biWZTKYzvs+Y+ppXr14lFxcX7bHbtWsXAaC33npLb38+Z4Yzh3GuvRHMb1wk6wIzPJ99bxKJhIQEAkDl5eXU2NhIjo6ONHnyZEGf5uZmSk5OJiLDvzjbvvCzs7O1bbW1teTh4UFVVVUGxWPo/urq6sje3p5CQkIE/f71r38RAEFCa/uirq+v17Zt27aNANDFixfbP1AP4ebmRgCoX79+9Ne//rVLiXrDhg20YMEC7b+rqqpIJpORUqkUzHhDRHzOjDxnnFw7xwy/jFkXmOH57HuTSLSNkWppacH58+dx9+5dvPTSS4I+lpaWWLJkiVHbffvtt+Hg4IDk5GRtW0ZGBmbOnAmlUmlQPIYSu95jZ5SUlKC8vBy7d+/G//zP/+BPf/pTp393bLsl3EapVMLf3x/V1dU4cOCAoC+fs86dswfnd+VXxy8AmDt3rsnj4Jd459Pc9PqhON988w0SExNRUFCA6upqwZdT29jMthJPXWFvb4933nkHiYmJ+Ne//oWnn34a//Vf/6Uzrq+jeAwldr3HzpBKpXBxcYG/vz88PT3x+OOPIyEhQZCoDHHhwgXk5+e3+1Tt3//+d8GsMXzOOicrK6tbt9/XzJ07FxEREfDz8zN1KEwEc+fONXUIOnp1cr127RoCAwMxa9Ys/Pd//zcGDhyIrVu34oMPPgAAbR3ByspKUfYXHh6O5ORkbNmyBQsXLsRjjz0Gb29vg+MxlNj1HrtKpVLB0tJSb/3Fh/n888/xyiuvYPfu3YL2O3fuYNCgQTh69CjKysq0A9z5nHXOnDlzunX7fc3cuXPh5+fHx62PMMfk2qtvC+fn56OpqQnvvfcevLy8IJfLBbcIhg4dCmdn5y5PftBm8ODBmDNnDvbu3YvVq1cjIiLCqHgMJXa9R0PdunULr776qk57W9FjffUXO0JEyMzMxKJFi3SWOTk5ITg4GC0tLYLEy+eMMdYX9Ork6uHhAQA4duwYGhoaUFRUJPhtSyaTITY2FqdOnUJ4eDiuX7+O1tZWaDQaFBYWAtBfO7Ijy5YtQ3NzM+7cuYMXX3zRqHgM3Z/Y9R4NZWdnh6NHj+LEiRPa26Pnzp3DG2+8ATs7O0RGRmr7GlJf84cffoBSqcTEiRP1Ll+4cCEA4YQSfM4YY32CqR+pul9nnhaOjo4mZ2dncnR0pODgYPrkk08IAHl7e2vrQ37yySc0evRoksvlJJfL6U9/+hNt27aNiHRrR65atUqntuWDJk+eTDt27OhUPIbuT+x6j4YKCAggT09Psre3J5lMRt7e3hQSEkL5+fmCfg+rr/nWW2+RnZ0dWVlZka+vL509e1awfN26dYKakYMGDdKeEyI+Z4bip4U7B+b3dCnrAjM8n9kSIvOZJDU4OBgAsGfPHhNHwljvkJ2djblz5/Jcx0aSSCTIysri31z7CDM8n3t69W1hxhhjzBxxcu3jfvnlF4PGiZlzEWXGzMmxY8cQExODffv2wcvLS/sZeu2113T6+vv7Q6FQwNLSEiNHjsTZs2dNELHxWltbsWXLlnbLQ8bFxcHHxwdKpRIymQwqlQoffPCB3vnHd+/ejfHjx0OhUGDIkCFYsGABysrKtMu/+uorbNq0yahx5b0BJ9c+bvjw4SCih74yMzNNHSpjZu/DDz9ESkoKYmNjERQUhMuXL8Pb2xv9+vVDRkYGvvnmG0H/o0ePYs+ePZg+fToKCgowduxYE0VuuKKiIjz//POIjIzUzsn9oBMnTmDx4sUoLi5GZWWldgx82097bbKyshAaGorg4GCUlpbiwIEDOHXqFKZOnYrm5mYA0BbzmDJlina8eF/AyZUx1iX6SvL1xn08zMaNG5GZmYns7GwoFArBspSUFFhYWCAsLAxVVVUmirDrfv75Z6xYsQILFy7EmDFj2u1nb2+PsLAwODs7Q6FQYM6cOQgMDMSRI0dQUlKi7ffZZ59h4MCBiIqKgoODA8aMGYPIyEjk5eUJnspfsmQJfH198fLLL2uTbm/HyZUx1iU9UZLP1GX/Ll68iNWrV+Ojjz7SKckIAGq1GhEREbh+/TqWL19uggjF4evri3379iE0NBQymazdfgcPHoSlpaWgrX///gAguNotKSmBu7u7YOx423j5q1evCtZfu3Yt8vLyjJ4FzlxxcmXsEUMGlMYLDw+HtbW1duYsAFi0aBHs7OwgkUi0M2jpK8mXkpICuVwOV1dXvPvuu3B3d4dcLodarRZcrXRlH4DxZQ+7IiUlBUSEgICAdvvEx8fj8ccfx44dO3Ds2LEOt2fIOTCmPGFLSwvWrFkDDw8P2NjY4Mknn+zxKTGvX78OGxsbeHp6atu8vLx0/ihq+73Vy8tL0O7k5IRJkyYhOTm5bzz93vPDf9onRlUcxh4lnRnnamhpvNDQUHJzcxOsm5iYSACooqJC26avalBYWBjZ2dlRYWEhNTQ0UEFBAY0fP54UCoV2/HlX92FM2cMHwchxkV5eXuTj46N3mbe3N125coWIiH744QeysLCgoUOHUk1NDRERHT58mGbMmCFYR+zyhMuXLyeZTEZ79+6lO3fuUGxsLFlYWNCPP/5o8Ht80DPPPEO+vr4G9a2trSWFQkHh4eGC9tzcXJJKpZSSkkLV1dV04cIFGjFiBL300kt6txMTE0MA6Ny5c0bFauz57AF9ryoOY6x99fX1SEpKwqxZszBv3jw4ODhg9OjR+PTTT1FZWYnt27eLti8rKyvtlZmPjw9SU1Oh0WiQnp4uyvanTZuG6upqrF69WpTttae2thZXrlwRzEndHj8/PyxduhTFxcVYsWKF3j6dOQdqtRpKpRIuLi4ICQlBbW0trl27BgBoaGhAamoqAgMDERQUBEdHR6xatQpSqVS0Y/0wCQkJcHd3R3x8vKB90qRJiI6ORnh4OJRKJUaNGgWNRoMdO3bo3c6wYcMA/Hta0t6Okytjj5CulsbrinHjxsHW1lZw67M3KC8vBxHB1tbWoP7x8fF44oknsG3bNnz//fc6y8UuT/jrr7+irq4Oo0aN0vaxsbHBgAEDeuRY79+/H9nZ2fj22291HvRauXIltm/fjuPHj6OmpgaXL1+GWq2Gn5+f4MGnNm3H+Pfff+/2uLsbJ1fGHiGmLo0nk8lQUVHRrfsQW0NDAwB0+IDP/eRyOdLT0yGRSPDmm2+ivr5esFzsc1BbWwsAWLVqlWDs+tWrV9sdSiOWzMxMbNy4Ebm5uRg6dKhg2c2bN7Fp0ya88847ePHFF2FnZwdPT0+kpaXhxo0bSExM1NmejY0NgD+OeW/GyZWxR4gpS+M1NTWZpGRiV7V94RszyYGfnx8iIyNRVFSEdevWCZaJfQ5cXFwAAFu2bNEZv3769GmjtmWMrVu3IiMjAydOnNCWirxfWzWtB5cplUo4OzvrLWHZ2NgI4I9j3ptxcmXsEWJMaTwrK6tOFY5vT25uLogIEyZM6LZ9dAdXV1dIJBKjx6+uW7cOw4cPx7lz5wTtYpcnfOyxxyCXy5GXl2fUep1FRIiOjkZ+fj5ycnL0XoED0P6RcPPmTUG7RqPB7du39ZawbDvGbm5uIkfd8zi5MvYIMaY0nkqlwu3bt5GTk4OmpiZUVFTojE0E2i/J19raijt37qC5uRnnz59HREQEPDw8MH/+fFH2YUjZQzHY2trCy8sLpaWlRq3Xdnv4wfGgYpcnlMvlWLBgAb744gukpqaiuroaLS0tKC0t1Sa2kJAQuLm5iTL9YmFhIT7++GOkpaVBKpXqTKW6efNmAICnpycmT56MtLQ0nDp1CvX19SgpKdG+v7feektn223HePTo0V2O0+RM+KiyDh6Kw5hxOjMUx5DSeEREt27dosmTJ5NcLidPT096//33KSoqigCQSqXSDql5sCRfWVkZhYWFkVQqpUGDBpGVlRUplUqaOXMmXbp0SbR9PKzsYUdg5NCN8PBwkkqlVFdXp23bv38/eXt7EwDq378/LV68WO+6UVFROkNxxC5PeO/ePYqOjiYPDw+ysrIiFxcXCgoKooKCAiIiCgwMJAC0Zs2aDt/n6dOnaeLEiYJykAMGDCC1Wk0nT54kIqL8/HztMn2vxMRE7fYqKyspIiKCVCoVyWQysre3p4kTJ9KXX36pd//Tpk2jQYMGUWtra4dxPsjY89kDsjm5MtaLmWs917CwMHJ2djZ1GO0y9su4qKiIrKysaNeuXd0YVfdpaWmh5557jnbu3GnqUNpVWVlJcrmcNm/ebPS65phc+bYwY6xb9KUqJyqVCnFxcYiLi9Nb+cWctbS0ICcnBxqNxqyrX61duxZjxoxBeHi4qUMRBSdXxhgzQExMDIKDgxESEtKrJufPzc3Fvn37cPjwYYPH6va0pKQk5OXl4dChQ5BKpaYORxScXBljooqNjUV6ejqqqqrg6emJvXv3mjok0axfvx7h4eHYsGGDqUMx2JQpU/D5558L5nA2JwcOHMC9e/eQm5sLJycnU4cjGitTB8AY61sSEhKQkJBg6jC6jb+/P/z9/U0dRp8xY8YMzJgxw9RhiI6vXBljjDGRcXJljDHGRMbJlTHGGBMZJ1fGGGNMZGb3QFNpaSmys7NNHQZjvULbxOz8mTFed05qz5iEiMjUQbQJDg7uU4/tM8YY6xlZWVmYM2eOqcNos8eskitjTL/s7GzMnTsX/HFlrFfYw7+5MsYYYyLj5MoYY4yJjJMrY4wxJjJOrowxxpjIOLkyxhhjIuPkyhhjjImMkytjjDEmMk6ujDHGmMg4uTLGGGMi4+TKGGOMiYyTK2OMMSYyTq6MMcaYyDi5MsYYYyLj5MoYY4yJjJMrY4wxJjJOrowxxpjIOLkyxhhjIuPkyhhjjImMkytjjDEmMk6ujDHGmMg4uTLGGGMi4+TKGGOMiYyTK2OMMSYyTq6MMcaYyDi5MsYYYyLj5MoYY4yJjJMrY4wxJjJOrowxxpjIOLkyxhhjIuPkyhhjjImMkytjjDEmMk6ujDHGmMg4uTLGGGMiszJ1AIwxodLSUrzxxhtoaWnRtt25cwcKhQIvvPCCoO8TTzyBzz77rIcjZIw9DCdXxszM4MGDcfXqVVy6dEln2cmTJwX/fv7553sqLMaYEfi2MGNm6PXXX4dUKn1ov5CQkB6IhjFmLE6ujJmh0NBQNDc3d9hn5MiR8PHx6aGIGGPG4OTKmBny9vbGk08+CYlEone5VCrFG2+80cNRMcYMxcmVMTP1+uuvw9LSUu+y5uZmBAcH93BEjDFDcXJlzEy98soraG1t1Wm3sLDAhAkTMHTo0J4PijFmEE6ujJkpd3d3TJw4ERYWwo+phYUFXn/9dRNFxRgzBCdXxszYa6+9ptNGRJg1a5YJomGMGYqTK2NmbPbs2YLfXS0tLfEf//EfcHV1NWFUjLGH4eTKmBlzcnLCn//8Z22CJSLMmzfPxFExxh6GkytjZm7evHnaB5ukUilmzpxp4ogYYw/DyZUxMxcQEACZTAYAmD59Ouzt7U0cEWPsYTi5Mmbm7OzstFerfEuYsd5BQkRk6iDMQXZ2NubOnWvqMBhjrNfidKK1h6viPCArK8vUIbBeZsuWLQCApUuXdts+WlpakJWVhVdffbXb9tGTTp8+jeTkZP689RFt55P9gZPrA+bMmWPqEFgvs2fPHgDd/38nMDAQcrm8W/fRk5KTk/nz1odwchXi31wZ6yX6UmJlrK/j5MoYY4yJjJMrY4wxJjJOrowxxpjIOLkyxhhjIuPkypiZOHToEBwcHPD111+bOhSzd+zYMcTExGDfvn3w8vKCRCKBRCLRW0XI398fCoUClpaWGDlyJM6ePWuCiI3X2tqKLVu2QK1W610eFxcHHx8fKJVKyGQyqFQqfPDBB6ipqdHpu3v3bowfPx4KhQJDhgzBggULUFZWpl3+1VdfYdOmTWhpaem29/Oo4eTKmJngAfiG+fDDD5GSkoLY2FgEBQXh8uXL8Pb2Rr9+/ZCRkYFvvvlG0P/o0aPYs2cPpk+fjoKCAowdO9ZEkRuuqKgIzz//PCIjI1FXV6e3z4kTJ7B48WIUFxejsrISCQkJSE5ORnBwsKBfVlYWQkNDERwcjNLSUhw4cACnTp3C1KlT0dzcDODfU2zK5XJMmTIFd+/e7fb39yjg5MqYmZg2bRqqqqowffp0U4eC+vr6dq+YTGnjxo3IzMxEdnY2FAqFYFlKSgosLCwQFhaGqqoqE0XYdT///DNWrFiBhQsXYsyYMe32s7e3R1hYGJydnaFQKDBnzhwEBgbiyJEjKCkp0fb77LPPMHDgQERFRcHBwQFjxoxBZGQk8vLycObMGW2/JUuWwNfXFy+//LI26bLO4+TKGNOxc+dOlJeXmzoMgYsXL2L16tX46KOP9I75VavViIiIwPXr17F8+XITRCgOX19f7Nu3D6GhodqCDfocPHhQUOsXAPr37w8AgqvdkpISuLu7QyKRaNsee+wxAMDVq1cF669duxZ5eXk8IYQIOLkyZga+//57eHh4QCKR4JNPPgEApKamws7ODra2tjhw4ACmTp0KpVKJwYMH44svvtCum5KSArlcDldXV7z77rtwd3eHXC6HWq0WXJmEh4fD2toaAwYM0LYtWrQIdnZ2kEgkqKysBABERERg2bJluHTpEiQSCVQqFQDgyJEjUCqVWL9+fU8cEh0pKSkgIgQEBLTbJz4+Ho8//jh27NiBY8eOdbg9IkJSUhJGjBgBmUwGJycnzJw5E7/88ou2j6HnAPj3FJVr1qyBh4cHbGxs8OSTT/b49I7Xr1+HjY0NPD09tW1eXl46fyi1/d7q5eUlaHdycsKkSZOQnJzMP1N0FTEiIsrKyiI+HKwzZs+eTbNnz+7ydkpKSggAbd26Vdu2cuVKAkDHjx+nqqoqKi8vp+eee47s7OyosbFR2y8sLIzs7OyosLCQGhoaqKCggMaPH08KhYKuXbum7RcaGkpubm6C/SYmJhIAqqio0LYFBQWRt7e3oN/BgwdJoVBQXFxcl99rZz5vXl5e5OPjo3eZt7c3XblyhYiIfvjhB7KwsKChQ4dSTU0NEREdPnyYZsyYIVhnzZo1ZG1tTbt27aK7d+/S+fPnaezYsdS/f38qKyvT9jP0HCxfvpxkMhnt3buX7ty5Q7GxsWRhYUE//vijUe/zfs888wz5+voa1Le2tpYUCgWFh4cL2nNzc0kqlVJKSgpVV1fThQsXaMSIEfTSSy/p3U5MTAwBoHPnzhkcJ39/6sjmK1fGegG1Wg2lUgkXFxeEhISgtrYW165dE/SxsrLSXoX5+PggNTUVGo0G6enposQwbdo0VFdXY/Xq1aJszxi1tbW4cuUKvL29H9rXz88PS5cuRXFxMVasWKG3T319PZKSkjBr1izMmzcPDg4OGD16ND799FNUVlZi+/btOut0dA4aGhqQmpqKwMBABAUFwdHREatWrYJUKhXt+D9MQkIC3N3dER8fL2ifNGkSoqOjER4eDqVSiVGjRkGj0WDHjh16tzNs2DAAQH5+frfH3JdxcmWsl7G2tgYANDU1ddhv3LhxsLW1Fdzm7K3Ky8tBRLC1tTWof3x8PJ544gls27YN33//vc7ygoIC1NTUYNy4cYL28ePHw9raWnA7XZ8Hz8Gvv/6Kuro6jBo1StvHxsYGAwYM6JHjv3//fmRnZ+Pbb7/VedBr5cqV2L59O44fP46amhpcvnwZarUafn5+ggef2rQd499//73b4+7LOLky1ofJZDJUVFSYOowua2hoAIAOH/C5n1wuR3p6OiQSCd58803U19cLlrcNN7G3t9dZ19HRERqNxqj4amtrAQCrVq3SjrmVSCS4evVqu0NpxJKZmYmNGzciNzcXQ4cOFSy7efMmNm3ahHfeeQcvvvgi7Ozs4OnpibS0NNy4cQOJiYk627OxsQHwxzFnncPJlbE+qqmpCXfv3sXgwYNNHUqXtX3hGzPJgZ+fHyIjI1FUVIR169YJljk6OgKA3iTamWPm4uIC4N+1fYlI8Dp9+rRR2zLG1q1bkZGRgRMnTmDgwIE6y4uKitDS0qKzTKlUwtnZGQUFBTrrNDY2AvjjmLPO4eTKWB+Vm5sLIsKECRO0bVZWVg+9nWyOXF1dIZFIjB6/um7dOgwfPhznzp0TtI8aNQr29vb46aefBO1nzpxBY2MjnnrqKaP289hjj0EulyMvL8+o9TqLiBAdHY38/Hzk5OTovQIHoP0j4ebNm4J2jUaD27dva4fk3K/tGLu5uYkc9aOFkytjfURrayvu3LmD5uZmnD9/HhEREfDw8MD8+fO1fVQqFW7fvo2cnBw0NTWhoqJCZ6wjADg7O+PGjRsoLi6GRqNBU1MTDh8+bLKhOLa2tvDy8kJpaalR67XdHn5wPKhcLseyZcuwf/9+ZGRkoLq6Gvn5+Vi4cCHc3d0RFhZm9H4WLFiAL774AqmpqaiurkZLSwtKS0u1iS0kJARubm6iTL9YWFiIjz/+GGlpaZBKpYJb0RKJBJs3bwYAeHp6YvLkyUhLS8OpU6dQX1+PkpIS7ft76623dLbddoxHjx7d5TgfaSZ8VNms8KPkrLPEGIqzdetWGjBgAAEgW1tbCggIoG3btpGtrS0BoGHDhtGlS5do+/btpFQqCQANGTKEfvvtNyL691AcqVRKgwYNIisrK1IqlTRz5ky6dOmSYD+3bt2iyZMnk1wuJ09PT3r//fcpKiqKAJBKpdIO2zl79iwNGTKEbGxs6Nlnn6WysjI6dOgQKRQKio+P79J7Jerc5y08PJykUinV1dVp2/bv30/e3t4EgPr370+LFy/Wu25UVJTOUJzW1lZKTEykYcOGkVQqJScnJwoMDKRff/1V28eYc3Dv3j2Kjo4mDw8PsrKyIhcXFwoKCqKCggIiIgoMDCQAtGbNmg7f5+nTp2nixInk7u5OAAgADRgwgNRqNZ08eZKIiPLz87XL9L0SExO126usrKSIiAhSqVQkk8nI3t6eJk6cSF9++aXe/U+bNo0GDRpEra2tHcZ5P/7+1JHNR+P/4/8crLPEGufaFWFhYeTs7GzSGIzRmc9bUVERWVlZ0a5du7opqu7V0tJCzz33HO3cudPUobSrsrKS5HI5bd682aj1+PtTB49zZayv6OsVTVQqFeLi4hAXF6e38os5a2lpQU5ODjQaDUJCQkwdTrvWrl2LMWPGIDw83NSh9HqcXEX09ttvQ6FQQCKR9NiDDd2toaEBw4cPx6pVq4xe98FyYG0va2truLq64oUXXkBiYiLu3LnTDZGzvigmJgbBwcEICQnpVZPz5+bmYt++fTh8+LDBY3V7WlJSEvLy8nDo0CFIpVJTh9PrcXIV0Y4dO5CWlmbqMES1cuVK/Prrr51a9/5yYA4ODiAitLa2ory8HNnZ2fD09ER0dDRGjhyp89QmM1xsbCzS09NRVVUFT09P7N2719Qhdav169cjPDwcGzZsMHUoBpsyZQo+//xzwbzO5uTAgQO4d+8ecnNz4eTkZOpw+gQrUwfAzNcPP/yACxcuiLpNiUQCR0dHvPDCC3jhhRcwbdo0zJ07F9OmTcNvv/0GBwcHUff3KEhISEBCQoKpw+hR/v7+8Pf3N3UYfcaMGTMwY8YMU4fRp/CVq8juL+vUm9XX1yMqKqrbS0/Nnj0b8+fPR3l5OT799NNu3RdjjPUUTq5dQERITEzEE088AZlMBgcHB0RFRen066gUlTElrU6ePImnn34atra2UCqVGD16NKqrqx+6j85YuXIlFi1apJ155rQiA90AACAASURBVEFilh9rG4d5+PBhbVtvPGaMMdaGk2sXrF69GtHR0QgLC8Pvv/+OsrIyvVU4VqxYgY8//hhbtmzBzZs3MX36dLz66qv46aef8N5772Hp0qWor6+HQqFAVlYWLl26BC8vL/zlL3/RzqZTW1uLgIAAzJ49G7dv30ZRUREef/xx7VRlHe3DWP/4xz9w6dIlvPrqq+32aXsytbW11ejtP2jMmDEAgMuXL2vbetsxY4wxAVMPBjIXxo7TqqurI1tbW/rzn/8saP/iiy8EtRDr6+vJ1taWQkJCBOvKZDJ67733iOiPepH19fXaPtu2bSMAdPHiRSIiunDhAgGggwcP6sRiyD6MeV/jxo2j0tJSIiKqqKggALRy5UqjtnM/b29vcnBw6LCPRCIhR0dHIup9x8wcxrn2Njwusm/h86kjmx9o6qSLFy+irq4OU6ZM6bBfZ0tRPVjSysvLC66urpg3bx6WLFmC+fPnaytgiFnuKjY2Fu+88w4GDRpk1HpdUVtbCyKCUqkE0PuOGfDvKeOys7ONXu9R1TaZPR+zvqE7ixP0WqZO7+bC2L+8Dh06RAB0Zlt58Mr1H//4R7tTlE2YMIGI9F+FpaWlEQD6v//7P23bhQsX6D//8z/JysqKJBIJzZ07l+rq6gzahyG+++47mjJlimDas564cj179iwBIH9/fyLqXceM6N9Xru1ti1/8epReTItnaOosuVwOALh3716H/cQsRTVy5Eh8/fXXuHHjBqKjo5GVlYXNmzeLto+dO3fi+PHjsLCw0E740Lbt9evXQyKRdMvvkUeOHAEATJ06FUDvOmZtZs+erbMdfrX/antwzNRx8Evc88n+wMm1k0aNGgULCwucPHmyw35ilaK6ceMGCgsLAfw7+WzYsAFjx45FYWGhaPtIT0/X+dC0FdpeuXIliAjjxo3r0j4eVFZWhi1btmDw4MF48803AfSuY8YYY/pwcu0kFxcXBAUFYe/evdi5cyeqq6tx/vx5bN++XdDPkFJUhrhx4wbeffdd/PLLL2hsbMS5c+dw9epVTJgwQbR9GMPY8mNEhJqaGrS2tmqTdlZWFiZOnAhLS0vk5ORof3Ptq8eMMfYIIUZEnXvaTaPR0Ntvv039+vUje3t7evbZZ2nNmjUEgAYPHkw///wzEXVcisrQklbFxcWkVqvJycmJLC0taeDAgbRy5Upqbm5+6D66or3fXA0pP/bVV1/Rk08+Sba2tmRtbU0WFhYEQPtk8NNPP01xcXF069YtnXV70zHjp4WNx0+X9i18PnVkS4iITJXYzUl2djbmzp0LPhzMWMHBwQCAPXv2mDiS3oM/b30Ln08de/i2MGOMMSYyTq593C+//KJT8k3fy5xrTDLGWG/DybWPGz58uEGP0mdmZpo6VMYMduzYMcTExOjUDH7ttdd0+vr7+0OhUMDS0hIjR47E2bNnTRCx8VpbW7Flyxao1Wq9y+Pi4uDj4wOlUgmZTAaVSoUPPvhAbyH53bt3Y/z48VAoFBgyZAgWLFiAsrIy7fKvvvoKmzZt0k5ryrqOkytjrFf58MMPkZKSgtjYWEHN4H79+iEjIwPffPONoP/Ro0exZ88eTJ8+HQUFBRg7dqyJIjdcUVERnn/+eURGRqKurk5vnxMnTmDx4sUoLi5GZWUlEhISkJycrH0GoE1WVhZCQ0MRHByM0tJSHDhwAKdOncLUqVPR3NwMAAgICIBcLseUKVNw9+7dbn9/jwJOroz1AfX19e1e4fSmfTzMxo0bkZmZiezsbCgUCsGylJQUWFhYICwsDFVVVSaKsOt+/vlnrFixAgsXLtQWtdDH3t4eYWFhcHZ2hkKhwJw5cxAYGIgjR46gpKRE2++zzz7DwIEDERUVBQcHB4wZMwaRkZHIy8vDmTNntP2WLFkCX19fvPzyy9qkyzqPkytjfcDOnTtRXl7e6/fRkYsXL2L16tX46KOPtDOk3U+tViMiIgLXr1/H8uXLTRChOHx9fbFv3z6EhoZCJpO12+/gwYOwtLQUtPXv3x8ABFe7JSUlcHd3F9SafuyxxwAAV69eFay/du1a5OXldXsd50cBJ1fGTICIkJSUhBEjRkAmk8HJyQkzZ84UFA0IDw+HtbU1BgwYoG1btGgR7OzsIJFIUFlZCQCIiIjAsmXLcOnSJUgkEqhUKqSkpEAul8PV1RXvvvsu3N3dIZfLoVarBVcrXdkHIG5d34dJSUkBESEgIKDdPvHx8Xj88cexY8cOHDt2rMPtGXIOjKkdbA71ga9fvw4bGxt4enpq27y8vHT+KGr7vdXLy0vQ7uTkhEmTJiE5OZmH1XRVT4+sNVc8CJp1VmcmkVizZg1ZW1vTrl276O7du3T+/HkaO3Ys9e/fn8rKyrT9QkNDyc3NTbBuYmIiAaCKigptW1BQEHl7ewv6hYWFkZ2dHRUWFlJDQwMVFBTQ+PHjSaFQ0LVr10TZx8GDB0mhUFBcXJxR778znzcvLy/y8fHRu8zb25uuXLlCREQ//PADWVhY0NChQ6mmpoaIiA4fPkwzZswQrGPoOWgrEnH8+HGqqqqi8vJyeu6558jOzo4aGxu1/ZYvX04ymYz27t1Ld+7codjYWLKwsKAff/zRqPd5v2eeeYZ8fX0N6ltbW0sKhYLCw8MF7bm5uSSVSiklJYWqq6vpwoULNGLECHrppZf0bicmJoaAP4qPGIK/P3XwxP2M9bT6+nokJSVh1qxZmDdvHhwcHDB69Gh8+umnqKys1JlCsyusrKy0V2Y+Pj5ITU2FRqNBenq6KNufNm0aqqursXr1alG2157a2lpcuXIF3t7eD+3r5+eHpUuXori4GCtWrNDbpzPnQK1WQ6lUwsXFBSEhIaitrcW1a9cAAA0NDUhNTUVgYCCCgoLg6OiIVatWQSqVinasHyYhIQHu7u6Ij48XtE+aNAnR0dEIDw+HUqnEqFGjoNFosGPHDr3bGTZsGAAgPz+/22Puyzi5MtbDCgoKUFNTo1MEYfz48bC2thbcthXbuHHjYGtr26mataZUXl4OIoKtra1B/ePj4/HEE09g27Zt+P7773WWd/UcPFg7WOz6wMbav38/srOz8e233+o86LVy5Ups374dx48fR01NDS5fvgy1Wg0/Pz/Bg09t2o7x77//3u1x92WcXBnrYW1DHezt7XWWOTo6QqPRdOv+ZTKZttpRb9HQ0AAAHT7gcz+5XI709HRIJBK8+eabqK+vFywX+xzU1tYCAFatWiWYnOXq1avtDqURS2ZmJjZu3Ijc3FwMHTpUsOzmzZvYtGkT3nnnHbz44ouws7ODp6cn0tLScOPGDSQmJupsz8bGBsAfx5x1DidXxnqYo6MjAOj9Ar979y4GDx7cbftuamrq9n10h7YvfGMmOfDz80NkZCSKioqwbt06wTKxz4HY9YENtXXrVmRkZODEiRMYOHCgzvKioiK0tLToLFMqlXB2dkZBQYHOOo2NjQD+OOasczi5MtbDRo0aBXt7e53C82fOnEFjYyOeeuopbZuVlZX21qMYcnNzQUSYMGFCt+2jO7i6ukIikRg9fnXdunUYPnw4zp07J2g35hwYoqfrAxMRoqOjkZ+fj5ycHL1X4AC0fyQ8WEZRo9Hg9u3b2iE592s7xm5ubiJH/Wjh5MpYD5PL5Vi2bBn279+PjIwMVFdXIz8/HwsXLoS7uzvCwsK0fVUqFW7fvo2cnBw0NTWhoqJCZ2wiADg7O+PGjRsoLi6GRqPRJsvW1lbcuXMHzc3NOH/+PCIiIuDh4YH58+eLsg9j6/p2lq2tLby8vFBaWmrUem23hx8cD2rMOTB0Pw+rDxwSEgI3NzdRpl8sLCzExx9/jLS0NEilUp25wjdv3gwA8PT0xOTJk5GWloZTp07h/7F3p1FRnGnfwP8NNDRLt4AbuKAsxj06RhPBGGOckMc4LogoBpNoNmJiELcouEQRt+BBDkaexGXIeTRGEI0mUROP8aDjGyaTHCUSPHFw3xVc2JHtej/M0EnboN1Q0A3+f+fwgbvuqrq6iu6Lqq77vkpLS3H58mX963vzzTeNtl1zjPv27dvgOB9rFnxU2arwUXKqr/oMxamurpa4uDjp1q2bqNVqcXNzk6CgIDl9+rRBv9u3b8vw4cNFo9GIt7e3fPDBBzJv3jwBIH5+fvohNcePH5cuXbqIo6OjPPvss3Ljxg0JDw8XtVotHTt2FDs7O9HpdDJu3Dg5e/asYvswpa5vberzfouIiBC1Wi0lJSX6tt27d4uvr68AkDZt2siMGTNqXXfevHlGQ3FMOQem1g4WeXR94KCgIAEgS5YseejrzMjIkCFDhoinp6cAEADi4eEhAQEBcuTIERERycrK0i+r7ScuLk6/vby8PImMjBQ/Pz9xcHAQFxcXGTJkiHz11Ve17n/UqFHSsWNHqa6ufmicf8bPTyOpPBr/xT8Oqi9rLZYeHh4u7u7ulg6jVvV5v+Xk5IidnZ1s3bq1kaJqXFVVVTJ06FDZsmWLpUOpU15enmg0Glm7dq1Z6/Hz0wjHuRK1ZC2pyomfnx9iYmIQExNTa+UXa1ZVVYU9e/agsLDQqss7Ll26FP3790dERISlQ2n2mFyJqNmIiopCSEgIQkNDm9Xk/Onp6di1axcOHDhg8ljdphYfH4/MzEzs378farXa0uE0e0yuRC1QdHQ0kpOTkZ+fD29vb6SlpVk6JMWsWLECERERWLVqlaVDMdmIESPwxRdfGMzhbE327t2L+/fvIz09HW5ubpYOp0Wws3QARKS8lStXYuXKlZYOo9EEBgYiMDDQ0mG0GGPHjsXYsWMtHUaLwitXIiIihTG5EhERKYzJlYiISGFMrkRERArjA00PCAkJsXQI1Mz885//BMC/HXPUTLHHY9YymDst5eNAJSJi6SCsQUZGBuLj4y0dBlGtbty4gRMnTmDkyJGWDoWoTjt37rR0CNZiJ5MrUTOQmpqKSZMmgW9XomZhJ79zJSIiUhiTKxERkcKYXImIiBTG5EpERKQwJlciIiKFMbkSEREpjMmViIhIYUyuRERECmNyJSIiUhiTKxERkcKYXImIiBTG5EpERKQwJlciIiKFMbkSEREpjMmViIhIYUyuRERECmNyJSIiUhiTKxERkcKYXImIiBTG5EpERKQwJlciIiKFMbkSEREpjMmViIhIYUyuRERECmNyJSIiUhiTKxERkcKYXImIiBTG5EpERKQwJlciIiKFMbkSEREpjMmViIhIYUyuRERECrOzdABEZKiiogJFRUUGbcXFxQCAu3fvGrSrVCq4uro2WWxEZBomVyIrc+fOHXTs2BFVVVVGy9zd3Q1+Hz58OA4fPtxUoRGRiXhbmMjKtG/fHs899xxsbB7+9lSpVJg8eXITRUVE5mByJbJCr7766iP72NraYvz48U0QDRGZi8mVyAoFBwfDzq7ub21sbW3xP//zP2jdunUTRkVEpmJyJbJCOp0OI0eOrDPBigimTJnSxFERkamYXIms1JQpU2p9qAkA7O3t8be//a2JIyIiUzG5Elmpv/3tb3BycjJqV6vVCAoKgrOzswWiIiJTMLkSWSmNRoPx48dDrVYbtFdUVCAsLMxCURGRKZhciazYK6+8goqKCoM2nU6HF1980UIREZEpmFyJrNhf//pXg4kj1Go1Jk+eDHt7ewtGRUSPwuRKZMXs7OwwefJk/a3hiooKvPLKKxaOiogehcmVyMpNnjxZf2u4ffv2ePbZZy0cERE9CpMrkZULCAhAx44dAQCvvfbaI6dFJCLLs6qJ+zMyMnD58mVLh0FkdQYNGoSrV6+idevWSE1NtXQ4RFYnICAAnTp1snQYeioREUsHUSMkJARpaWmWDoOIiJqZlJQUTJw40dJh1NhpVVeuADBhwgTs3LnT0mEQWZ20tDRMmDDBoC01NRWTJk2CFf2P3CyoVCpr+zCmBlCpVJYOwQi/vCFqJh5MrERkvZhciYiIFMbkSkREpDAmVyIiIoUxuRIRESmMyZWIiEhhTK5EhP3796NVq1b45ptvLB2K1Tt06BCioqKwa9cu+Pj4QKVSQaVS4dVXXzXqGxgYCK1WC1tbW/Tu3RvHjx+3QMTmq66uxrp16xAQEFDr8piYGPTq1Qs6nQ4ODg7w8/PDhx9+iKKiIqO+27dvx6BBg6DVatGlSxdMmzYNN27c0C//+uuvsWbNGlRVVTXa67EEJlci4jhZE3300UdITExEdHQ0goODce7cOfj6+qJ169bYtm0b9u3bZ9D/4MGD2LlzJ0aPHo3s7GwMGDDAQpGbLicnB8899xxmz56NkpKSWvscPnwYM2bMwIULF5CXl4eVK1ciISEBISEhBv1SUlIQFhaGkJAQXLlyBXv37sXRo0cxcuRIVFZWAgDGjBkDjUaDESNG4N69e43++poKkysRYdSoUcjPz8fo0aMtHQpKS0vrvGKypNWrV2PHjh1ITU2FVqs1WJaYmAgbGxuEh4cjPz/fQhE23K+//ooFCxZg+vTp6N+/f539XFxcEB4eDnd3d2i1WkycOBFBQUH47rvvDKaw/eyzz9ChQwfMmzcPrVq1Qv/+/TF79mxkZmbip59+0vebOXMm+vXrh5dfflmfdJs7JlcisipbtmzBrVu3LB2GgTNnzmDx4sVYtmwZNBqN0fKAgABERkbi6tWrmDt3rgUiVEa/fv2wa9cuhIWFwcHBoc5+3377LWxtbQ3a2rRpAwAGV7uXL1+Gp6enwQxKnTt3BgBcvHjRYP2lS5ciMzMTCQkJDX4d1oDJlegxd+zYMXh5eUGlUuGTTz4BACQlJcHZ2RlOTk7Yu3cvRo4cCZ1Oh06dOuHLL7/Ur5uYmAiNRoN27drh3XffhaenJzQaDQICAgyuTCIiImBvbw8PDw992/vvvw9nZ2eoVCrk5eUBACIjIzFnzhycPXsWKpUKfn5+AIDvvvsOOp0OK1asaIpDYiQxMREigjFjxtTZJzY2Fk888QQ2b96MQ4cOPXR7IoL4+Hj07NkTDg4OcHNzw7hx4/D777/r+5h6DgCgqqoKS5YsgZeXFxwdHfHkk08iJSWlYS/aTFevXoWjoyO8vb31bT4+Pkb/KNV83+rj42PQ7ubmhmHDhiEhIaFlfE0hVmTChAkyYcIES4dB1GykpKSIEm/jy5cvCwBZv369vm3hwoUCQH744QfJz8+XW7duydChQ8XZ2VnKy8v1/cLDw8XZ2VlOnTolZWVlkp2dLYMGDRKtViuXLl3S9wsLC5P27dsb7DcuLk4ASG5urr4tODhYfH19Dfp9++23otVqJSYmpsGvVUQEgKSkpJjc38fHR3r16lXrMl9fXzl//ryIiPz4449iY2MjXbt2laKiIhEROXDggIwdO9ZgnSVLloi9vb1s3bpV7t27JydPnpQBAwZImzZt5MaNG/p+pp6DuXPnioODg6Slpcndu3clOjpabGxs5Oeffzb5NT7omWeekX79+pnUt7i4WLRarURERBi0p6eni1qtlsTERCkoKJDffvtNevbsKS+99FKt24mKihIAcuLECbNiNfd8NoFUXrkS0UMFBARAp9Ohbdu2CA0NRXFxMS5dumTQx87OTn8V1qtXLyQlJaGwsBDJycmKxDBq1CgUFBRg8eLFimzPHMXFxTh//jx8fX0f2dff3x+zZs3ChQsXsGDBglr7lJaWIj4+HuPHj8eUKVPQqlUr9O3bF59++iny8vKwceNGo3Uedg7KysqQlJSEoKAgBAcHw9XVFYsWLYJarVbs+D/KypUr4enpidjYWIP2YcOGYf78+YiIiIBOp0OfPn1QWFiIzZs317qdbt26AQCysrIaPebGxuRKRCazt7cHAFRUVDy038CBA+Hk5GRwm7O5unXrFkQETk5OJvWPjY1F9+7dsWHDBhw7dsxoeXZ2NoqKijBw4ECD9kGDBsHe3t7gdnptHjwHp0+fRklJCfr06aPv4+joCA8PjyY5/rt370Zqaiq+//57owe9Fi5ciI0bN+KHH35AUVERzp07h4CAAPj7+9dau7vmGN+8ebPR425sTK5E1CgcHByQm5tr6TAarKysDAAe+oDPn2k0GiQnJ0OlUuGNN95AaWmpwfKa4SYuLi5G67q6uqKwsNCs+IqLiwEAixYt0o+5ValUuHjxYp1DaZSyY8cOrF69Gunp6ejatavBsuvXr2PNmjV455138MILL8DZ2Rne3t7YtGkTrl27hri4OKPtOTo6AvjjmDdnTK5EpLiKigrcu3cPnTp1snQoDVbzgW/OJAf+/v6YPXs2cnJysHz5coNlrq6uAFBrEq3PMWvbti0AYN26dRARg5+MjAyztmWO9evXY9u2bTh8+DA6dOhgtDwnJwdVVVVGy3Q6Hdzd3ZGdnW20Tnl5OYA/jnlzxuRKRIpLT0+HiGDw4MH6Njs7u0feTrZG7dq1g0qlMnv86vLly9GjRw+cOHHCoL1Pnz5wcXHBL7/8YtD+008/oby8HE899ZRZ++ncuTM0Gg0yMzPNWq++RATz589HVlYW9uzZU+sVOAD9PwnXr183aC8sLMSdO3f0Q3L+rOYYt2/fXuGomx6TKxE1WHV1Ne7evYvKykqcPHkSkZGR8PLywtSpU/V9/Pz8cOfOHezZswcVFRXIzc01GusIAO7u7rh27RouXLiAwsJCVFRU4MCBAxYbiuPk5AQfHx9cuXLFrPVqbg8/OB5Uo9Fgzpw52L17N7Zt24aCggJkZWVh+vTp8PT0RHh4uNn7mTZtGr788kskJSWhoKAAVVVVuHLlij6xhYaGon379opMv3jq1Cl8/PHH2LRpE9RqtcGtaJVKhbVr1wIAvL29MXz4cGzatAlHjx5FaWkpLl++rH99b775ptG2a45x3759GxynxVnwUWUjHIpDZB4lhuKsX79ePDw8BIA4OTnJmDFjZMOGDeLk5CQApFu3bnL27FnZuHGj6HQ6ASBdunSRf//73yLyn6E4arVaOnbsKHZ2dqLT6WTcuHFy9uxZg/3cvn1bhg8fLhqNRry9veWDDz6QefPmCQDx8/PTD9s5fvy4dOnSRRwdHeXZZ5+VGzduyP79+0Wr1UpsbGyDXmsNmDl0IyIiQtRqtZSUlOjbdu/eLb6+vgJA2rRpIzNmzKh13Xnz5hkNxamurpa4uDjp1q2bqNVqcXNzk6CgIDl9+rS+jznn4P79+zJ//nzx8vISOzs7adu2rQQHB0t2draIiAQFBQkAWbJkyUNfZ0ZGhgwZMkQ8PT0FgAAQDw8PCQgIkCNHjoiISFZWln5ZbT9xcXH67eXl5UlkZKT4+fmJg4ODuLi4yJAhQ+Srr76qdf+jRo2Sjh07SnV19UPjfJC557MJpDK5EjVjSo1zbYjw8HBxd3e3aAzmMvfDOCcnR+zs7GTr1q2NGFXjqaqqkqFDh8qWLVssHUqd8vLyRKPRyNq1a81e1xqTK28LE1GDtbSKJg/y8/NDTEwMYmJiaq38Ys2qqqqwZ88eFBYWIjQ01NLh1Gnp0qXo378/IiIiLB2KIphca9HU5besudxXWVkZevTogUWLFjV4W9u3b4dKpWqUSdl5zqixRUVFISQkBKGhoc1qcv709HTs2rULBw4cMHmsblOLj49HZmYm9u/fD7VabelwFMHkWgtp4nktm3p/5li4cCFOnz6tyLa2b98OX19fZGRk4MyZM4psswbPmWVER0cjOTkZ+fn58Pb2RlpamqVDalQrVqxAREQEVq1aZelQTDZixAh88cUXBvM6W5O9e/fi/v37SE9Ph5ubm6XDUY5lb0sbssR3riUlJeLv799i99cQ/+///T8JDAwUALJw4cIGbSsvL0+8vb1l27ZtAkAWL15c723xnP3BGr5zbY5gfd/RUQNY4fnkd65NXd7KGstp1aa0tBTz5s1TrPxTamoqRo0apS+MvHXr1npf/fGcEZG1a/bJ9R//+Ad69eqFVq1aQaPRoG/fvvj+++8N+mzduhUDBw6ERqOBs7MzunbtiuXLl9da3qq28ls9e/aESqWCjY0NnnrqKf2UYh9++KF+v59//vkj4zF1f4DyJanMtXDhQrz//vv62V8eZG4JsO3bt2P8+PHQarUIDAzEhQsX8I9//KPO/jxnRNSsWfjS2UB9bgvv3LlTli5dKnfu3JHbt2/L4MGDpXXr1vrl69atEwCyatUquX37tty5c0c+++wzCQsLE5Hay1s9WH6rsrJSunbtKl5eXlJZWWnQd9asWbJu3TqT4zFlfyLKl6Qyx7Fjx2TMmDEiIpKbm1vrbWFzSoBdvHhR2rZtqz92W7duFQDy5ptv1tqf58x0vC1cP7C+24jUAFZ4PlveONeVK1cKALl165aUl5eLq6urDB8+3KBPZWWlJCQkiIjpH5w1H/ipqan6tuLiYvHy8pL8/HyT4jF1fyUlJeLi4iKhoaEG/f71r38JAIOEVvNBXVpaqm/bsGGDAJAzZ87UfaDqUFJSIgMHDpQrV66ISN3J1RyrVq2SadOm6X/Pz88XBwcH0el0BoPyRYTnzMxzxuRaP1b4YUwNYIXnM9Wu8a+Nm1bNY9xVVVU4efIk7t27h5deesmgj62tLWbOnGnWdt966y0sXboUCQkJCAkJAQBs27YN48aNg06nMykeUyldksoc0dHReOedd9CxY0ez163L9u3bsXLlSv3vOp0OgYGB+Oabb7B3716DsXc8Z/Wbe7fm9ZHp1q1bh507d1o6DGqhmv13rvv27cPzzz+Ptm3bwsHBAR9++KF+WUFBAYA/qlA0hIuLC9555x38+OOP+Ne//gUA+N///V+jAc8Pi8dUSpekMtWxY8eQlZWFt956S7Ft/vbbb8jKysLo0aMN5h+tGR/6f//3fwb9ec6IqCVo1leuly5dQlBQEMaPH4+///3v6NChA9avX6//cKwpdZSXl6fI/iIiIpCQkIB169Zh+vTp6Ny5M3x9fU2Ox1RKl6Qy1ZYtW/DDDz/Axsb4f64VK1ZgyCLcigAAIABJREFUxYoV+Pnnn42uzh7miy++wOTJk7F9+3aD9rt376Jjx444ePAgbty4oR+Dx3NWP7wCM49KpcKsWbMwceJES4dCClCpVJYOwUizvnLNyspCRUUF3nvvPfj4+ECj0Rgc5K5du8Ld3R0HDx5UZH+dOnXCxIkTkZaWhsWLFyMyMtKseEyldEkqUyUnJxvVg6wpdr1w4UKIiFmJVUSwY8cOvP/++0bL3NzcEBISgqqqKoPEy3NGRC1Bs06uXl5eAIBDhw6hrKwMOTk5Bt9tOTg4IDo6GkePHkVERASuXr2K6upqFBYW4tSpUwBqL2/1MHPmzEFlZSXu3r2LF154wax4TN2f0iWpGoMpJcB+/PFH6HQ6DBkypNbl06dPB2B4a5jnjIhaBEs+TvWg+jwtPH/+fHF3dxdXV1cJCQmRTz75RACIr6+vvoTVJ598In379hWNRiMajUb+8pe/yIYNG0TEuLzVokWLjMpvPWj48OGyefPmesVj6v6ULklVX3U9LfyoEmBvvvmmODs7i52dnfTr10+OHz9usHz58uUGZa06duyoPyciPGem4tPC9QPre7qUGsAKz2eqSsR6JkmteeKR3x8RmSY1NRWTJk3iXMdmUqlUSElJ4XeuLYQVns+dzfq2MBERkTVicm3hfv/9d4MhMHX9WHOdRyJrcujQIURFRWHXrl3w8fHRv4deffVVo76BgYHQarWwtbVF7969cfz4cQtEbL7q6mqsW7euzvKQMTEx6NWrF3Q6HRwcHODn54cPP/yw1lq327dvx6BBg6DVatGlSxdMmzYNN27c0C//+uuvsWbNmhZXE5jJtYXr0aOH0RPAtf3s2LHD0qESWb2PPvoIiYmJiI6ORnBwMM6dOwdfX1+0bt0a27Ztw759+wz6Hzx4EDt37sTo0aORnZ2NAQMGWChy0+Xk5OC5557D7Nmz9XNyP+jw4cOYMWMGLly4gLy8PKxcudJgspYaKSkpCAsLQ0hICK5cuYK9e/fi6NGjGDlyJCorKwFAX8xjxIgR+vHiLQGTKxE1SGlpaZ1XOM1pH4+yevVq7NixA6mpqdBqtQbLEhMTYWNjg/Dw8GZVSP1Bv/76KxYsWIDp06ejf//+dfZzcXFBeHg43N3dodVqMXHiRAQFBeG7777D5cuX9f0+++wzdOjQAfPmzUOrVq3Qv39/zJ49G5mZmQZP5c+cORP9+vXDyy+/rE+6zR2TKxE1SFOU5LN02b8zZ85g8eLFWLZsGTQajdHygIAAREZG4urVq5g7d64FIlRGv379sGvXLoSFhcHBwaHOft9++y1sbW0N2tq0aQMABle7ly9fhqenp8HY8c6dOwMALl68aLD+0qVLkZmZqViZS0tjciV6zIgJpfEiIiJgb2+vnzkLAN5//304OztDpVLpZ9CqrSRfYmIiNBoN2rVrh3fffReenp7QaDQICAgwuFppyD4A88seNkRiYiJEBGPGjKmzT2xsLJ544gls3rwZhw4deuj2TDkH5pQnrKqqwpIlS+Dl5QVHR0c8+eSTSElJadiLNtPVq1fh6OgIb29vfZuPj4/RP0U137f6+PgYtLu5uWHYsGFISEhoGU+/N/3wn7opURWH6HFSn3GuppbGCwsLk/bt2xusGxcXJwAkNzdX31Zb1aDw8HBxdnaWU6dOSVlZmWRnZ8ugQYNEq9Xqx583dB/mlD18EMwcF+nj4yO9evWqdZmvr6+cP39eRER+/PFHsbGxka5du0pRUZGIiBw4cEDGjh1rsI7S5Qnnzp0rDg4OkpaWJnfv3pXo6GixsbGRn3/+2eTX+KBnnnlG+vXrZ1Lf4uJi0Wq1EhERYdCenp4uarVaEhMTpaCgQH777Tfp2bOnvPTSS7VuJyoqSgDIiRMnzIrV3PPZBFJ55Ur0GCktLUV8fDzGjx+PKVOmoFWrVujbty8+/fRT5OXlYePGjYrty87OTn9l1qtXLyQlJaGwsBDJycmKbH/UqFEoKCjA4sWLFdleXYqLi3H+/HmDOanr4u/vj1mzZuHChQtYsGBBrX3qcw4CAgKg0+nQtm1bhIaGori4GJcuXQIAlJWVISkpCUFBQQgODoarqysWLVoEtVqt2LF+lJUrV8LT0xOxsbEG7cOGDcP8+fMREREBnU6HPn36oLCwEJs3b651O926dQPwn2lJmzsmV6LHSENL4zXEwIED4eTkZHDrszm4desWRAROTk4m9Y+NjUX37t2xYcMGHDt2zGi50uUJT58+jZKSEvTp00ffx9HRER4eHk1yrHfv3o3U1FR8//33Rg96LVy4EBs3bsQPP/yAoqIinDt3DgEBAfD39zd48KlGzTG+efNmo8fd2JhciR4jli6N5+DgoC8G0VyUlZUBwEMf8PkzjUaD5ORkqFQqvPHGGygtLTVYrvQ5KC4uBgAsWrTIYOz6xYsX6xxKo5QdO3Zg9erVSE9PR9euXQ2WXb9+HWvWrME777yDF154Ac7OzvD29samTZtw7do1xMXFGW3P0dERwB/HvDljciV6jFiyNF5FRUWTlN9TWs0HvjmTHPj7+2P27NnIycnB8uXLDZYpfQ7atm0L4D/F3+WB8esZGRlmbcsc69evx7Zt23D48GF9qcg/y8nJQVVVldEynU4Hd3d3ZGdnG61TXl4O4I9j3pwxuRI9RswpjWdnZ/fIikPmSE9Ph4hg8ODBjbaPxtCuXTuoVCqzx68uX74cPXr0wIkTJwzalS5P2LlzZ2g0GmRmZpq1Xn2JCObPn4+srCzs2bOn1itwAPp/Eq5fv27QXlhYiDt37uiH5PxZzTFu3769wlE3PSZXoseIOaXx/Pz8cOfOHezZswcVFRXIzc01GpsI1F2Sr7q6Gnfv3kVlZSVOnjyJyMhIeHl5YerUqYrsw5Syh0pwcnKCj48Prly5YtZ6NbeHHxwPqnR5Qo1Gg2nTpuHLL79EUlISCgoKUFVVhStXrugTW2hoKNq3b6/I9IunTp3Cxx9/jE2bNkGtVhtNpbp27VoAgLe3N4YPH45Nmzbh6NGjKC0txeXLl/Wv78033zTads0x7tu3b4PjtDgLPqpshENxiMxTn6E4ppTGExG5ffu2DB8+XDQajXh7e8sHH3wg8+bNEwDi5+enH1LzYEm+GzduSHh4uKjVaunYsaPY2dmJTqeTcePGydmzZxXbx6PKHj4MzBy6ERERIWq1WkpKSvRtu3fvFl9fXwEgbdq0kRkzZtS67rx584yG4ihdnvD+/fsyf/588fLyEjs7O2nbtq0EBwdLdna2iIgEBQUJAFmyZMlDX2dGRoYMGTLEoBykh4eHBAQEyJEjR0REJCsrS7+stp+4uDj99vLy8iQyMlL8/PzEwcFBXFxcZMiQIfLVV1/Vuv9Ro0ZJx44dpbq6+qFxPsjc89kEUplciZoxa63nGh4eLu7u7pYOo07mfhjn5OSInZ2dbN26tRGjajxVVVUydOhQ2bJli6VDqVNeXp5oNBpZu3at2etaY3LlbWEiahQtqcqJn58fYmJiEBMTU2vlF2tWVVWFPXv2oLCw0KqrXy1duhT9+/dHRESEpUNRBJMrEZEJoqKiEBISgtDQ0GY1OX96ejp27dqFAwcOmDxWt6nFx8cjMzMT+/fvh1qttnQ4imByJSJFRUdHIzk5Gfn5+fD29kZaWpqlQ1LMihUrEBERgVWrVlk6FJONGDECX3zxhcEcztZk7969uH//PtLT0+Hm5mbpcBRjZ+kAiKhlWblyJVauXGnpMBpNYGAgAgMDLR1GizF27FiMHTvW0mEojleuRERECmNyJSIiUhiTKxERkcKYXImIiBTG5EpERKQwq3taOC0tDSqVytJhEDUrfM+Yb9KkSZg0aZKlw6AWSiUiYukgamRkZNRaQJfocZeRkYGEhASkpKRYOhQiqxQQEGBN5Qx3WlVyJaLapaamYtKkSeDblahZ2MnvXImIiBTG5EpERKQwJlciIiKFMbkSEREpjMmViIhIYUyuRERECmNyJSIiUhiTKxERkcKYXImIiBTG5EpERKQwJlciIiKFMbkSEREpjMmViIhIYUyuRERECmNyJSIiUhiTKxERkcKYXImIiBTG5EpERKQwJlciIiKFMbkSEREpjMmViIhIYUyuRERECmNyJSIiUhiTKxERkcKYXImIiBTG5EpERKQwJlciIiKFMbkSEREpjMmViIhIYUyuRERECmNyJSIiUhiTKxERkcLsLB0AERnKzc3FV199ZdD2yy+/AAA2btxo0K7VajF58uQmi42ITKMSEbF0EET0h/v376Ndu3YoKiqCra0tAKDmbapSqfT9Kioq8Prrr+Pzzz+3RJhEVLedvC1MZGUcHBwwYcIE2NnZoaKiAhUVFaisrERlZaX+94qKCgDAK6+8YuFoiag2TK5EVuiVV15BeXn5Q/u4urrihRdeaKKIiMgcTK5EVmj48OFo27ZtncvVajWmTJkCOzs+NkFkjZhciayQjY0NwsLCoFara11eUVHBB5mIrBiTK5GVmjx5sv671Qd16NAB/v7+TRwREZmKyZXISj399NPo0qWLUbu9vT1ef/11gyeHici6MLkSWbFXX33V6NZweXk5bwkTWTkmVyIrFhYWZnRr2M/PD3379rVQRERkCiZXIivWo0cP9OrVS38LWK1WY9q0aRaOiogehcmVyMq99tpr+pmaKisreUuYqBlgciWycpMnT0ZVVRUAYMCAAfD29rZwRET0KEyuRFbOy8sLzzzzDADg9ddft3A0RGQKTu/yXxkZGYiPj7d0GES1un//PlQqFQ4ePIijR49aOhyiWu3cudPSIVgNXrn+1+XLl5GWlmbpMKgZ+uc//4l//vOfjbqPTp06oX379tBoNI26n6Zy5coVvt9aEJ5PY7xyfQD/8yJzhYSEAGj8v50zZ87Az8+vUffRVFJTUzFp0iS+31qImvNJf+CVK1Ez0VISK9HjgMmViIhIYUyuRERECmNyJSIiUhiTKxERkcKYXImsxP79+9GqVSt88803lg7F6h06dAhRUVHYtWsXfHx8oFKpoFKp8Oqrrxr1DQwMhFarha2tLXr37o3jx49bIGLzVVdXY926dQgICKh1eUxMDHr16gWdTgcHBwf4+fnhww8/RFFRkVHf7du3Y9CgQdBqtejSpQumTZuGGzdu6Jd//fXXWLNmjX4mMGo4JlciKyEilg6hWfjoo4+QmJiI6OhoBAcH49y5c/D19UXr1q2xbds27Nu3z6D/wYMHsXPnTowePRrZ2dkYMGCAhSI3XU5ODp577jnMnj0bJSUltfY5fPgwZsyYgQsXLiAvLw8rV65EQkKCfmhYjZSUFISFhSEkJARXrlzB3r17cfToUYwcORKVlZUAgDFjxkCj0WDEiBG4d+9eo7++xwGTK5GVGDVqFPLz8zF69GhLh4LS0tI6r5gsafXq1dixYwdSU1Oh1WoNliUmJsLGxgbh4eHIz8+3UIQN9+uvv2LBggWYPn06+vfvX2c/FxcXhIeHw93dHVqtFhMnTkRQUBC+++47XL58Wd/vs88+Q4cOHTBv3jy0atUK/fv3x+zZs5GZmYmffvpJ32/mzJno168fXn75ZX3SpfpjciUiI1u2bMGtW7csHYaBM2fOYPHixVi2bFmtM1UFBAQgMjISV69exdy5cy0QoTL69euHXbt2ISwsDA4ODnX2+/bbb/XVkmq0adMGAAyudi9fvgxPT0992UIA6Ny5MwDg4sWLBusvXboUmZmZSEhIaPDreNwxuRJZgWPHjsHLywsqlQqffPIJACApKQnOzs5wcnLC3r17MXLkSOh0OnTq1Alffvmlft3ExERoNBq0a9cO7777Ljw9PaHRaBAQEGBwZRIREQF7e3t4eHjo295//304OztDpVIhLy8PABAZGYk5c+bg7NmzUKlU+skrvvvuO+h0OqxYsaIpDomRxMREiAjGjBlTZ5/Y2Fg88cQT2Lx5Mw4dOvTQ7YkI4uPj0bNnTzg4OMDNzQ3jxo3D77//ru9j6jkAgKqqKixZsgReXl5wdHTEk08+iZSUlIa9aDNdvXoVjo6OBpWTfHx8jP5Rqvm+1cfHx6Ddzc0Nw4YNQ0JCAr+maCghERFJSUkRHg6qjwkTJsiECRMavJ3Lly8LAFm/fr2+beHChQJAfvjhB8nPz5dbt27J0KFDxdnZWcrLy/X9wsPDxdnZWU6dOiVlZWWSnZ0tgwYNEq1WK5cuXdL3CwsLk/bt2xvsNy4uTgBIbm6uvi04OFh8fX0N+n377bei1WolJiamwa+1Pu83Hx8f6dWrV63LfH195fz58yIi8uOPP4qNjY107dpVioqKRETkwIEDMnbsWIN1lixZIvb29rJ161a5d++enDx5UgYMGCBt2rSRGzdu6PuZeg7mzp0rDg4OkpaWJnfv3pXo6GixsbGRn3/+2azX+WfPPPOM9OvXz6S+xcXFotVqJSIiwqA9PT1d1Gq1JCYmSkFBgfz222/Ss2dPeemll2rdTlRUlACQEydOmBwnPz+NpPLKlagZCAgIgE6nQ9u2bREaGori4mJcunTJoI+dnZ3+KqxXr15ISkpCYWEhkpOTFYlh1KhRKCgowOLFixXZnjmKi4tx/vx5+Pr6PrKvv78/Zs2ahQsXLmDBggW19iktLUV8fDzGjx+PKVOmoFWrVujbty8+/fRT5OXlYePGjUbrPOwclJWVISkpCUFBQQgODoarqysWLVoEtVqt2PF/lJUrV8LT0xOxsbEG7cOGDcP8+fMREREBnU6HPn36oLCwEJs3b651O926dQMAZGVlNXrMLRmTK1EzY29vDwCoqKh4aL+BAwfCycnJ4DZnc3Xr1i2ICJycnEzqHxsbi+7du2PDhg04duyY0fLs7GwUFRVh4MCBBu2DBg2Cvb29we302jx4Dk6fPo2SkhL06dNH38fR0REeHh5Ncvx3796N1NRUfP/990YPei1cuBAbN27EDz/8gKKiIpw7dw4BAQHw9/c3ePCpRs0xvnnzZqPH3ZIxuRK1YA4ODsjNzbV0GA1WVlYGAA99wOfPNBoNkpOToVKp8MYbb6C0tNRgec1wExcXF6N1XV1dUVhYaFZ8xcXFAIBFixbpx9yqVCpcvHixzqE0StmxYwdWr16N9PR0dO3a1WDZ9evXsWbNGrzzzjt44YUX4OzsDG9vb2zatAnXrl1DXFyc0fYcHR0B/HHMqX6YXIlaqIqKCty7dw+dOnWydCgNVvOBb84kB/7+/pg9ezZycnKwfPlyg2Wurq4AUGsSrc8xa9u2LQBg3bp1EBGDn4yMDLO2ZY7169dj27ZtOHz4MDp06GC0PCcnB1VVVUbLdDod3N3dkZ2dbbROeXk5gD+OOdUPkytRC5Weng4RweDBg/VtdnZ2j7ydbI3atWsHlUpl9vjV5cuXo0ePHjhx4oRBe58+feDi4oJffvnFoP2nn35CeXk5nnrqKbP207lzZ2g0GmRmZpq1Xn2JCObPn4+srCzs2bOn1itwAPp/Eq5fv27QXlhYiDt37uiH5PxZzTFu3769wlE/XphciVqI6upq3L17F5WVlTh58iQiIyPh5eWFqVOn6vv4+fnhzp072LNnDyoqKpCbm2s01hEA3N3dce3aNVy4cAGFhYWoqKjAgQMHLDYUx8nJCT4+Prhy5YpZ69XcHn5wPKhGo8GcOXOwe/dubNu2DQUFBcjKysL06dPh6emJ8PBws/czbdo0fPnll0hKSkJBQQGqqqpw5coVfWILDQ1F+/btFZl+8dSpU/j444+xadMmqNVqg1vRKpUKa9euBQB4e3tj+PDh2LRpE44ePYrS0lJcvnxZ//refPNNo23XHOO+ffs2OM7HmgUfVbYqfJSc6kuJoTjr168XDw8PASBOTk4yZswY2bBhgzg5OQkA6datm5w9e1Y2btwoOp1OAEiXLl3k3//+t4j8ZyiOWq2Wjh07ip2dneh0Ohk3bpycPXvWYD+3b9+W4cOHi0ajEW9vb/nggw9k3rx5AkD8/Pz0w3aOHz8uXbp0EUdHR3n22Wflxo0bsn//ftFqtRIbG9ug1ypSv/dbRESEqNVqKSkp0bft3r1bfH19BYC0adNGZsyYUeu68+bNMxqKU11dLXFxcdKtWzdRq9Xi5uYmQUFBcvr0aX0fc87B/fv3Zf78+eLl5SV2dnbStm1bCQ4OluzsbBERCQoKEgCyZMmSh77OjIwMGTJkiHh6egoAASAeHh4SEBAgR44cERGRrKws/bLafuLi4vTby8vLk8jISPHz8xMHBwdxcXGRIUOGyFdffVXr/keNGiUdO3aU6urqh8b5Z/z8NJLKo/Ff/OOg+lJqnGtDhIeHi7u7u0VjMEd93m85OTliZ2cnW7dubaSoGldVVZUMHTpUtmzZYulQ6pSXlycajUbWrl1r1nr8/DTCca5ELUVLr2ji5+eHmJgYxMTE1Fr5xZpVVVVhz549KCwsRGhoqKXDqdPSpUvRv39/REREWDqUZo/JlYiajaioKISEhCA0NLRZTc6fnp6OXbt24cCBAyaP1W1q8fHxyMzMxP79+6FWqy0dTrPH5Kqgt956C1qtFiqVqsmeGlRabGys0cMRKpXKYHC8qR6stVnzY29vj3bt2uH5559HXFwc7t692wiv5PERHR2N5ORk5Ofnw9vbG2lpaZYOqVGtWLECERERWLVqlaVDMdmIESPwxRdfGMzrbE327t2L+/fvIz09HW5ubpYOp0VgclXQ5s2bsWnTJkuHYTX+XGuzVatWEBFUV1fj1q1bSE1Nhbe3N+bPn4/evXsbDYkg061cuRL379+HiOD8+fOYMGGCpUNqdIGBgVi9erWlw2gxxo4di6ioKKOnqqn+mFzJyNatW40Gwv/222+KbFulUsHV1RXPP/88kpOTkZqaips3b+prmRIRtQRMrgr7c81EerQJEyZg6tSpuHXrFj799FNLh0NEpAgm1wYQEcTFxaF79+5wcHBAq1atMG/ePKN+D6vzaE69yCNHjuDpp5+Gk5MTdDod+vbti4KCgkfuozEoWduzZpKDAwcO6Nta4jEjoscHk2sDLF68GPPnz0d4eDhu3ryJGzdu1FriasGCBfj444+xbt06XL9+HaNHj8Yrr7yCX375Be+99x5mzZqF0tJSaLVapKSk4OzZs/Dx8cHbb7+tn6quuLgYY8aMwYQJE3Dnzh3k5OTgiSee0M8D+rB9mCsqKgpubm6wt7eHt7c3xo0bh59//tmgT82wj+rqarO3/6D+/fsDAM6dO6dva27HjIjIgAUH2VoVcwdBl5SUiJOTk7z44osG7V9++aVBoeHS0lJxcnKS0NBQg3UdHBzkvffeE5E/ijGXlpbq+2zYsEEAyJkzZ0RE5LfffhMA8u233xrFYso+THXp0iU5fvy4FBYWyv379yUjI0P+8pe/iKOjo/z2229mbauGr6+vtGrV6qF9VCqVuLq6ikjzO2bWMIlEc8NJB1oWnk8jqXaWSurN3ZkzZ1BSUoIRI0Y8tF996zw+WC/Sx8cH7dq1w5QpUzBz5kxMnTpVX15KyVqSnTt3NpjMe/DgwUhOTkb//v2xYcMGJCUlmbU9UxQXF0NEoNPpADS/YwYAaWlp/L69HnjMqKVicq2nmsmta0pN1eXPdR4XLVpksMzT09Pk/Tk6OuLw4cNYsGABVqxYgZiYGEycOBHJycmK7aMuffv2ha2tLf797383eFu1qdlujx49ADTPYzZ48GDMmjXL7PUeVxkZGUhISOB33C1EzfmkPzC51pNGowEA3L9//6H9/lznMTIyskH77N27N7755hvk5uYiPj4eq1evRu/evfXTqSmxj9pUV1ejurra5ELV5vruu+8AACNHjgTQPI9Zp06dMHHixAZv53GSkJDAY9aCMLka4gNN9dSnTx/Y2NjgyJEjD+2nVJ3Ha9eu4dSpUwD+k3xWrVqFAQMG4NSpU4rWknzppZeM2n7++WeICPz9/Ru8/QfduHED69atQ6dOnfDGG28AaH7HjIjoQUyu9dS2bVsEBwcjLS0NW7ZsQUFBAU6ePImNGzca9DOlzqMprl27hnfffRe///47ysvLceLECVy8eBGDBw9WbB8AcPXqVezYsQP37t1DRUUFMjIy8NZbb8HLywvTp0/X9zO3tqeIoKioCNXV1RAR5ObmIiUlBUOGDIGtrS327Nmj/861uR0zIiIjln2gynrU52m3wsJCeeutt6R169bi4uIizz77rCxZskQASKdOneTXX38VkYfXeTS1XuSFCxckICBA3NzcxNbWVjp06CALFy6UysrKR+7DHHPmzBFfX19xdnYWOzs76dSpk7z99tty7do1g36m1Pb8+uuv5cknnxQnJyext7cXGxsbAaB/Mvjpp5+WmJgYuX37ttG6zemY8Wlh8/Hp0paF59NIqkpExGKZ3YqkpqZi0qRJ4OEgc4WEhAAAdu7caeFImg++31oWnk8jO3lbmIiISGFMri3c77//XmsJuQd/rLmAM5EpDh06hKioKKNSh6+++qpR38DAQGi1Wtja2qJ37944fvy4BSI2X3V1NdatW4eAgIA6+xw7dgxDhgyBk5MTPD09MX/+fINRDV9//TXWrFmjn2WNGgeTawvXo0cPowo3tf3s2LHD0qES1dtHH32ExMREREdHG5Q6bN26NbZt24Z9+/YZ9D948CB27tyJ0aNHIzs7GwMGDLBQ5KbLycnBc889h9mzZ6OkpKTWPtnZ2QgMDMSIESOQm5uL3bt34+9//7vBw4hjxoyBRqPBiBEjcO/evaYK/7HD5ErUApSWlj70aqa57KM+Vq9ejR07diA1NRVardZgWWJiImxsbBAeHt6sSxr++uuvWLBgAaZPn66fi7s2y5cvh4eHB5YtWwZnZ2f4+/tj/vz5+Pzzzw1mHps5cyb69euHl19+GZWVlU3xEh47TK5ELcCWLVtw69atZr8Pc505cwaLFy/GsmXL9BO7/FlAQAAiIyNx9eo6a2OpAAAgAElEQVRVzJ071wIRKqNfv37YtWsXwsLC6pzMpbKyEvv27cOwYcMMppUcOXIkRAR79+416L906VJkZmZy8odGwuRKZAEigvj4ePTs2RMODg5wc3PDuHHjDK4uIiIiYG9vDw8PD33b+++/D2dnZ6hUKuTl5QEAIiMjMWfOHJw9exYqlQp+fn5ITEyERqNBu3bt8O6778LT0xMajQYBAQH46aefFNkHoGzpwfpITEyEiGDMmDF19omNjcUTTzyBzZs349ChQw/dninnxZySh01Z1vDcuXMoKiqCl5eXQbuvry8A4OTJkwbtbm5uGDZsGBISEviUb2No4rE/VovjtKi+6jPOdcmSJWJvby9bt26Ve/fuycmTJ2XAgAHSpk0buXHjhr5fWFiYtG/f3mDduLg4ASC5ubn6tuDgYPH19TXoFx4eLs7OznLq1CkpKyuT7OxsGTRokGi1Wrl06ZIi+/j2229Fq9VKTEyMWa9fqfebj4+P9OrVq9Zlvr6+cv78eRER+fHHH8XGxka6du0qRUVFIiJy4MABGTt2rME6pp6XmqpMP/zwg+Tn58utW7dk6NCh4uzsLOXl5fp+c+fOFQcHB0lLS5O7d+9KdHS02NjYyM8//1zv1/zMM89Iv379jNqPHDkiACQuLs5omaOjo4wYMcKoPSoqyqCKV33x89NIKq9ciZpYaWkp4uPjMX78eEyZMgWtWrVC37598emnnyIvL89olq+GsLOz01+F9erVC0lJSSgsLERycrIi2x81ahQKCgqwePFiRbZnjuLiYpw/f15/ZfYw/v7+mDVrFi5cuFBrzWWgfuclICAAOp0Obdu2RWhoKIqLi3Hp0iUAQFlZGZKSkhAUFITg4GC4urpi0aJFUKvVih3/P6t5ItjW1tZomVqtRmlpqVF7t27dAABZWVmKx/O4Y3IlamLZ2dkoKirCwIEDDdoHDRoEe3t7g9u2Shs4cCCcnJzqVVbP2ty6dQsiAicnJ5P6x8bGonv37tiwYQOOHTtmtLyh5+XBkodKlzV8lJrvnGt7QKm8vByOjo5G7TXH7ubNm4rH87hjciVqYjXDH1xcXIyWubq6orCwsFH37+DggNzc3EbdR1MoKysDAJOrNWk0GiQnJ0OlUuGNN94wupJT+rz8uazhn8eUX7x4sc6hNA1R8715QUGBQXtJSQnKyspqLaVYk3BrjiUph8mVqIm5uroCQK0f1vfu3UOnTp0abd8VFRWNvo+mUpMYzJkMwd/fH7Nnz0ZOTg6WL19usEzp8/Ln0onywLjyjIwMs7ZlCm9vb2i1Wly8eNGg/cyZMwCAJ5980mid8vJyAKj1qpYahsmVqIn16dMHLi4u+OWXXwzaf/rpJ5SXl+Opp57St9nZ2elvMyohPT0dIoLBgwc32j6aSrt27aBSqcwev7p8+XL06NEDJ06cMGg357yYoqnLGtrZ2eHll1/G0aNHUV1drW8/cOAAVCpVrU9U1xy79u3bN0mMjxMmV6ImptFoMGfOHOzevRvbtm1DQUEBsrKyMH36dHh6eiI8PFzf18/PD3fu3MGePXtQUVGB3NxcoysTAHB3d8e1a9dw4cIFFBYW6pNldXU17t69i8rKSpw8eRKRkZHw8vLC1KlTFdmHuaUHleTk5AQfHx9cuXLFrPVqbg8/+OCPOefF1P08qqxhaGgo2rdvr9j0i4sXL8bNmzfx0Ucfobi4GBkZGYiLi8PUqVPRvXt3o/41x65v376K7J/+xJLPKlsTPkpO9VWfoTjV1dUSFxcn3bp1E7VaLW5ubhIUFCSnT5826Hf79m0ZPny4aDQa8fb2lg8++EDmzZsnAMTPz08/pOb48ePSpUsXcXR0lGeffVZu3Lgh4eHholarpWPHjmJnZyc6nU7GjRsnZ8+eVWwfppQerI1S77eIiAhRq9VSUlKib9u9e7f4+voKAGnTpo3MmDGj1nXnzZtnNBTHlPNiaslDkUeXNQwKChIAsmTJkoe+zoyMDBkyZIh4enoKAAEgHh4eEhAQIEeOHDHoe+TIEXn66afFwcFBPD09Zd68eVJWVlbrdkeNGiUdO3aU6urqh+7/Ufj5aSSVR+O/+MdB9WWt9VzDw8PF3d3d0mHUSqn3W05OjtjZ2cnWrVsViKrpVVVVydChQ2XLli1Nvu+8vDzRaDSydu3aBm+Ln59GOM6VqCVr6ZVP/Pz8EBMTg5iYGBQVFVk6HLNUVVVhz549KCwstEhVqqVLl6J///6IiIho8n0/DphciahZi4qKQkhICEJDQ5vV5Pzp6enYtWsXDhw4YPJYXaXEx8cjMzMT+/fvh1qtbtJ9Py6YXIlaoOjoaCQnJyM/Px/e3t5IS0uzdEiNasWKFYiIiMCqVassHYrJRowYgS+++MJgXuemsHfvXty/fx/p6elwc3Nr0n0/TuwsHQARKW/lypVYuXKlpcNoUoGBgQgMDLR0GFZv7NixGDt2rKXDaPF45UpERKQwJlciIiKFMbkSEREpjMmViIhIYXyg6QGpqamWDoGamZop5Pi3Y7qaiet5zFqGxihE0NypREQsHYQ1SE1NxaRJkywdBhFRs8V0oreTyZWoGaj5549vV6JmYSe/cyUiIlIYkysREZHCmFyJiIgUxuRKRESkMCZXIiIihTG5EhERKYzJlYiISGFMrkRERApjciUiIlIYkysREZHCmFyJiIgUxuRKRESkMCZXIiIihTG5EhERKYzJlYiISGFMrkRERApjciUiIlIYkysREZHCmFyJiIgUxuRKRESkMCZXIiIihTG5EhERKYzJlYiISGFMrkRERApjciUiIlIYkysREZHCmFyJiIgUxuRKRESkMCZXIiIihTG5EhERKYzJlYiISGFMrkRERApjciUiIlKYnaUDICJDV65cweuvv46qqip92927d6HVavH8888b9O3evTs+++yzJo6QiB6FyZXIynTq1AkXL17E2bNnjZYdOXLE4PfnnnuuqcIiIjPwtjCRFXrttdegVqsf2S80NLQJoiEiczG5ElmhsLAwVFZWPrRP79690atXryaKiIjMweRKZIV8fX3x5JNPQqVS1bpcrVbj9ddfb+KoiMhUTK5EVuq1116Dra1trcsqKysREhLSxBERkamYXIms1OTJk1FdXW3UbmNjg8GDB6Nr165NHxQRmYTJlchKeXp6YsiQIbCxMXyb2tjY4LXXXrNQVERkCiZXIiv26quvGrWJCMaPH2+BaIjIVEyuRFZswoQJBt+72tra4q9//SvatWtnwaiI6FGYXImsmJubG1588UV9ghURTJkyxcJREdGjMLkSWbkpU6boH2xSq9UYN26chSMiokdhciWycmPGjIGDgwMAYPTo0XBxcbFwRET0KEyuRFbO2dlZf7XKW8JEzYNKRMTSQTxMXTPUEBHR42nChAnYuXOnpcN4mJ3NoipOZGQk/P39LR0GkcVUVVUhJSUFr7zyyiP7rlu3DgAwa9asxg6rxcjIyEBCQgJSUlIsHQo9Qs3ft7VrFsnV398fEydOtHQYRBYVFBQEjUbzyH41/9HzPWOehIQEHrNmwMqvWPX4nStRM2FKYiUi68DkSkREpDAmVyIiIoUxuRIRESmMyZWIiEhhTK5EVKv9+/ejVatW+OabbywditU7dOgQoqKisGvXLvj4+EClUkGlUtVa1SgwMBBarRa2trbo3bs3jh8/boGIzVddXY1169YhICCgzj7Hjh3DkCFD4OTkBE9PT8yfPx/379/XL//666+xZs0aVFVVNUXIFsXkSkS1svL5ZazGRx99hMTERERHRyM4OBjnzp2Dr68vWrdujW3btmHfvn0G/Q8ePIidO3di9OjRyM7OxoABAywUuelycnLw3HPPYfbs2SgpKam1T3Z2NgIDAzFixAjk5uZi9+7d+Pvf/47p06fr+4wZMwYajQYjRozAvXv3mip8i2ByJaJajRo1Cvn5+Rg9erSlQ0FpaelDr5gsZfXq1dixYwdSU1Oh1WoNliUmJsLGxgbh4eHIz8+3UIQN9+uvv2LBggWYPn06+vfvX2e/5cuXw8PDA8uWLYOzszP8/f0xf/58fP755/j999/1/WbOnIl+/frh5ZdfRmVlZVO8BItgciUiq7dlyxbcunXL0mEYOHPmDBYvXoxly5bVOgY5ICAAkZGRuHr1KubOnWuBCJXRr18/7Nq1C2FhYfoCEg+qrKzEvn37MGzYMIMpa0eOHAkRwd69ew36L126FJmZmUhISGjU2C2JyZWIjBw7dgxeXl5QqVT45JNPAABJSUlwdnaGk5MT9u7di5EjR0Kn06FTp0748ssv9esmJiZCo9GgXbt2ePfdd+Hp6QmNRoOAgAD89NNP+n4RERGwt7eHh4eHvu3999+Hs7MzVCoV8vLyAPxn+tM5c+bg7NmzUKlU8PPzAwB899130Ol0WLFiRVMcEiOJiYkQEYwZM6bOPrGxsXjiiSewefNmHDp06KHbExHEx8ejZ8+ecHBwgJubG8aNG2dw1WfqOQD+M2XmkiVL4OXlBUdHRzz55JONNr3juXPnUFRUBC8vL4N2X19fAMDJkycN2t3c3DBs2DAkJCS02K8fmFyJyMizzz6LH3/80aDtvffew6xZs1BaWgqtVouUlBScPXsWPj4+ePvtt1FRUQHgP0lz6tSpKCkpwcyZM3HhwgUcP34clZWVePHFF3H58mUA/0lOD043uGHDBixbtsygLSEhAaNHj4avry9EBGfOnAEA/UMxNbVum9q+ffvQvXt3ODk51dnH0dERn3/+OWxsbPD222+juLi4zr5Lly5FVFQUFi5ciFu3buHo0aO4fPkyhg4dips3bwIw/RwAwIIFC/Dxxx9j3bp1uH79OkaPHo1XXnkFv/zyi3IH4b9u3LgBAEa3xjUaDRwdHfXx/9lf/vIXXL16Fb/++qvi8VgDJlciMltAQAB0Oh3atm2L0NBQFBcX49KlSwZ97Ozs9FdhvXr1QlJSEgoLC5GcnKxIDKNGjUJBQQEWL16syPbMUVxcjPPnz+uvzB7G398fs2bNwoULF7BgwYJa+5SWliI+Ph7jx4/HlClT0KpVK/Tt2xeffvop8vLysHHjRqN1HnYOysrKkJSUhKCgIAQHB8PV1RWLFi2CWq1W7Pj/Wc0Twba2tkbL1Go1SktLjdq7desGAMjKylI8HmvA5EpEDWJvbw8ABldNtRk4cCCcnJwMbnM2V7du3YKIPPSq9c9iY2PRvXt3bNiwAceOHTNanp2djaKiIgwcONCgfdCgQbC3tze4nV6bB8/B6dOnUVJSgj59+uj7ODo6wsPDo1GOf813zrU9oFReXg5HR0ej9ppjV9tVbUvA5EpETcbBwQG5ubmWDqPBysrKAKDOB3wepNFokJycDJVKhTfeeMPoSq5mWIqLi4vRuq6urigsLDQrvprbz4sWLdKPuVWpVLh48WKdQ2kaouZ784KCAoP2kpISlJWVwdPT02idmoRbcyxbGiZXImoSFRUVuHfvHjp16mTpUBqsJjGYMxmCv78/Zs+ejZycHCxfvvz/t3fnMVGdXx/Av6MzcgFBQFEoMgqD1VpxjxGsP2NNaapRRERpbROsWuo2bqW4oQgqtRghKrQ1WowoCqjRtkpqbIJoOmoTRJSmiloX3BEFZJ+Z8/7RzLxeFp2BYRY8n2T+8N7n3udwn8kc7/Yc0ToXFxcAaDaJtuaYubu7A/iv9ikRiT4qlcqofRnCx8cHTk5OuHPnjmi57v744MGDm2xTX18PAM2e1XYEnFwZY2aRm5sLIsLo0aP1y6RS6RsvJ1ujnj17QiKRGP3+anx8PAYMGIBLly6Jlg8aNAhdu3Zt8rDRhQsXUF9fjxEjRhjVj7e3NwRBQEFBgVHbtZZUKsXEiRORl5cnesAsJycHEomk2SeqdceuV69eZonR3Di5MsbahVarxfPnz6FWq1FYWIilS5dCLpcjIiJC38bPzw9lZWU4duwYGhoa8PTp0yZnPwDg5uaGBw8e4Pbt26isrERDQwNycnIs9iqOg4MDfH19UVJSYtR2usvDjR/8EQQBK1aswNGjR7F//35UVFTgypUrmD9/Pjw9PREZGWl0P7Nnz8bBgweRmpqKiooKaDQalJSU4OHDhwCA8PBw9OrVy2TTL8bExODx48dYv349qqqqoFKpkJiYiIiICPTv379Je92x8/f3N0n/VoesHADKzMy0dBiM2Yzp06fT9OnT27SPHTt2kIeHBwEgBwcHmjJlCqWkpJCDgwMBoH79+tHNmzdp165d5OzsTACoT58+dP36dSIiioyMJJlMRl5eXiSVSsnZ2ZmmTp1KN2/eFPXz7NkzGj9+PAmCQD4+PrR48WKKiooiAOTn50d3794lIqL8/Hzq06cP2dvb0wcffECPHj2ikydPkpOTE23cuLFNfysRUWZmJhn7c6hUKkkmk1F1dbV+2dGjR0mhUBAA6tGjBy1atKjZbaOioig4OFi0TKvVUmJiIvXr149kMhm5urpSSEgIXbt2Td/GmDGoq6uj6OhoksvlJJVKyd3dnUJDQ6moqIiIiEJCQggArVu37rV/p0qlojFjxpCnpycBIADk4eFBgYGBdObMGVHbM2fO0KhRo8jOzo48PT0pKiqKamtrm93vpEmTyMvLi7Ra7Wv7b8wU328zyOLkylgHYw0/PpGRkeTm5mbRGIzRmuRaXFxMUqmU0tPT2ymq9qXRaGjs2LG0Z88es/ddWlpKgiDQ1q1bjd7WGr7fBsjiy8KMsXbR0Suf+Pn5IS4uDnFxcXj58qWlwzGKRqPBsWPHUFlZifDwcLP3Hxsbi6FDh0KpVJq9b3Ph5GoAc5fesqZSXxs3bhQ9yq/7vPr+XGtlZGRAIpG0y4Tsb/OYMfNZtWoVwsLCEB4eblOT8+fm5uLIkSPIyckx+F1dU9m2bRsKCgpw8uRJyGQys/ZtTpxcDUBmnvvS3P1ZSkZGBhQKBVQqlf6RfVPhMbOc1atXIy0tDeXl5fDx8cHhw4ctHVK72rRpE5RKJRISEiwdisEmTJiAAwcOiOZ1Nofjx4+jrq4Oubm5cHV1NWvfZmfZy9JvBjPfc62urqaAgIAO25+x4uPj2+WeUmlpKfn4+ND+/fsJAMXExLR6XzxmYjZyT8qqtOaeK7MMG/l+8z3Xxsxd2soaS2mZQ1ZWFiZNmqQvnpyent7qsz8eM8aYtelwyfXs2bMYOHAgunXrBkEQ4O/vj99//13UJj09HSNHjoQgCHB0dETfvn0RHx/fbGmr5kpvvffee5BIJOjUqRNGjBihn07s22+/1fe7d+/eN8ZjaH+A6ctRmZqx5b8yMjIwbdo0ODk5ISgoCLdv38bZs2dbbM9jxhizKRY+dX4jGHlZODs7m2JjY6msrIyePXtGo0ePpu7du+vXJyUlEQBKSEigZ8+eUVlZGf300080a9YsIiIKDQ0lhUIh2ue9e/cIAO3YsYOIiNRqNfXt25fkcjmp1WpR22XLllFSUpLB8RjSHxHRunXrqEuXLpSenk4vXrygwsJCGj58OPXo0YMePXqkb7dmzRoCQH/88QeVl5fTkydPaOzYseTo6Ej19fUGH0ed+Ph46t27N7m4uJBMJqO+fftScHAwXbx4UdTut99+IycnJ4qLi3vjPu/cuUPu7u76Y5eenk4AaM6cOc225zEzjo1cNrMqfFnYdtjI97vjv+e6efNmAkBPnjyh+vp6cnFxofHjx4vaqNVqSk5OJiLDfzh1P/hZWVn6ZVVVVSSXy6m8vNygeAztr7q6mrp27Urh4eGidhcvXiQAooSm+6GuqanRL0tJSSEAdOPGjZYPVAvu3r1L+fn5VFlZSXV1daRSqWjYsGFkb29PV69eNXp/REQJCQk0e/Zs/b/Ly8vJzs6OnJ2dRS/kExGPWSvGzEZ+fKwKJ1fbYSPf7yypec6PLUf3qLdGo0FhYSFevHiBjz/+WNSmc+fOWLJkiVH7nTt3LmJjY5GcnIywsDAAwP79+zF16lQ4OzsbFI+hTF2Oyhje3t7w9vbW/3v06NFIS0vD0KFDkZKSgtTUVKP3mZGRgc2bN+v/7ezsjKCgIPz66684fvy46L07HrPWzbtbUlKCrKysVm37NtJNZs/HzPqVlJTYRPGHDpdcT5w4gcTERBQVFaGiokL046Qrh6SrQNEWXbt2xVdffYXExERcvHgRo0aNwg8//NDktYPXxWMoU5ejait/f3907twZ169fN3rbq1ev4sqVK5g8eXKz6/ft2ydKrjxmrXP+/HnMnDmzXfvoiPiY2Ybp06dbOoQ36lAPNN29exchISHw8PDAhQsXUF5eji1btujXv/POOwCA0tJSk/SnVCohk8mQlJSEvLw8eHt7Q6FQGByPoUxdjqqttFottFqtwbUsX3XgwAF8+umnTcpglZWVwd7eHqdOncKjR4/07XnMWmf69OlNjjF/Wv5kZmYCgMXj4M+bP7aQWIEOllyvXLmChoYGLFiwAL6+vhAEARKJRL++b9++cHNzw6lTp0zSX+/evTFjxgwcPnwYMTExWLp0qVHxGMrU5aiM0fhyLAD89ddfICIEBAQYtS8iwqFDh7Bw4cIm61xdXREWFgaNRoOMjAz9ch4zxpgt6lDJVS6XAwBOnz6N2tpaFBcXi+5t2dnZYfXq1cjLy4NSqcT9+/eh1WpRWVmJv//+G0Dzpa1eZ8WKFVCr1Xj+/Dk+/PBDo+IxtD9Tl6Myxv3793Ho0CG8ePECDQ0NUKlUmDt3LuRyOebPn69vZ0j5rz///BPOzs4YM2ZMs+t1+9u3b59+GY8ZY8wmkZWDkU8LR0dHk5ubG7m4uFBYWBjt3LmTAJBCodCXr9q5cyf5+/uTIAgkCAINGzaMUlJSiKhpaau1a9c2Kb3V2Pjx42n37t2tisfQ/kxdjspQK1asIIVCQY6OjiSVSql37940b948evDggajdm8p/zZkzR7+PIUOGUH5+vmh9fHy8qKSVl5eXfkyIeMyMYSNPU1oVflrYdtjI9ztLQkRWPSmqRCJBZmYmZsyYYelQGLMJuiehs7OzLRyJ7cjKysLMmTNh5T+HDDbz/c7uUJeFGWOMMWvAyfUt888//zRbQq7xxxI1HhljrKPg5PqWGTBggEGPux86dMjSoTJmM06fPo1Vq1bhyJEj8PX11f8n9YsvvmjSNigoCE5OTujcuTPef/995OfnWyBi42m1WiQlJb22/vK5c+cwZswYODg4wNPTE9HR0airq9Ov/+WXX7BlyxajJmSxVZxcGWOsDdavX4/t27dj9erVCA0Nxa1bt6BQKNC9e3fs378fJ06cELU/deoUsrOzMXnyZBQVFWH48OEWitxwxcXF+N///ofly5fri140VlRUhKCgIEyYMAFPnz7F0aNH8fPPP4veKtBVwZowYYJ+opWOipMrY8zkampqXnuGYyt9vMl3332HQ4cOISsrC05OTqJ127dvR6dOnRAZGYny8nILRdh2ly9fxsqVKzF//nwMHTq0xXbx8fHw8PDAhg0b4OjoiICAAERHR2Pv3r2iSlBLlizBkCFDMHHiRKjVanP8CRbByZUxZnLmqHlr6bq6N27cQExMDDZs2ABBEJqsDwwMxNKlS3H//n188803FojQNIYMGYIjR45g1qxZLc7KplarceLECYwbN0406conn3wCIsLx48dF7WNjY1FQUIDk5OR2jd2SOLkyxkD05tqzSqUSXbp0gYeHh37ZwoUL4ejoCIlEop+isrmat9u3b4cgCOjZsye+/vpreHp6QhAEBAYGiibpaEsfgPF1hdti+/btICJMmTKlxTYbN27Eu+++i927d+P06dOv3Z8hY2BM/V+NRoN169ZBLpfD3t4egwcP1k/zaGq3bt3Cy5cv9ZOw6OimFi0sLBQtd3V1xbhx45CcnNxhX3/i5MoYQ2xsLFatWoU1a9bgyZMnyMvLw7179zB27Fg8fvwYwH/JpPH75ikpKdiwYYNoWXJyMiZPngyFQgEiwo0bN6BUKhEREYHq6mosWbIEt2/fRn5+PtRqNT766CPcu3evzX0A/1+5SKvVmu7gtODEiRPo378/HBwcWmxjb2+PvXv3olOnTpg3bx6qqqpabGvIGCxYsADLli1DTU0NnJyckJmZiZs3b8LX1xfz5s0TzRa2cuVKfP/990hKSsLDhw8xefJkfPbZZ02m5DQF3XzgjS+NC4IAe3t7ffyvGjZsGO7fv4/Lly+bPB5rwMmVsbdcTU0Ntm3bhmnTpuHzzz9Ht27d4O/vjx9//BGlpaXYtWuXyfqSSqX6M7OBAwciNTUVlZWVSEtLM8n+J02ahIqKCsTExJhkfy2pqqrCv//+Kyr60JKAgAAsW7YMt2/fxsqVK5tt05oxCAwMhLOzM9zd3REeHo6qqircvXsXAFBbW4vU1FSEhIQgNDQULi4uWLt2LWQymcmO9at0TwR37ty5yTqZTIaampomy/v16wfgv/m8OyJOroy95dpae7YtRo4cCQcHB9GlT1vw5MkTENFrz1pftXHjRvTv3x8pKSk4d+5ck/Wmrv977do1VFdXY9CgQfo29vb28PDwaJdjrbvn3NwDSvX19bC3t2+yXHfsmjur7Qg4uTL2lrN07Vk7Ozs8ffq0XfswtdraWgAwuOyiIAhIS0uDRCLBl19+2eRMztRjoLv8vHbtWtHkMHfu3GnxVZq20N0j19Vf1qmurkZtbS08PT2bbKNLuLpj2dFwcmXsLWfJ2rMNDQ0WqUncVrrEYMxkCAEBAVi+fDmKi4sRHx8vWmfqMXB3dwcAJCUlNZkgRqVSGbUvQ/j4+MDJyQl37twRLdfdCx88eHCTberr6wGg2bPajoCTK2NvOWNqz0ql0jeW9DNGbm4uiAijR49utz7aQ8+ePSGRSIx+fzU+Ph4DBgzApUuXRMtNXf/X29sbgiCgoKDAqO1aSyqVYuLEicjLyxM9TJaTkwOJRNLsE9W6Y9erVy+zxGhunCV9WFgAAAMzSURBVFwZe8sZU3vWz88PZWVlOHbsGBoaGvD06dMmZytAyzVvtVotnj9/DrVajcLCQixduhRyuRwREREm6cOQusKm4ODgAF9fX5SUlBi1ne7ycOMHf0xd/1cQBMyePRsHDx5EamoqKioqoNFoUFJSgocPHwIAwsPD0atXL5NNvxgTE4PHjx9j/fr1qKqqgkqlQmJiIiIiItC/f/8m7XXHzt/f3yT9Wx2zVbdrJRhZz5Wxt11r6l0aUnuWiOjZs2c0fvx4EgSBfHx8aPHixRQVFUUAyM/PT18zuXHN20ePHlFkZCTJZDLy8vIiqVRKzs7ONHXqVLp586bJ+nhTXeGWtKaeq1KpJJlMRtXV1fplR48eJYVCQQCoR48etGjRoma3jYqKouDgYNEyU9f/rauro+joaJLL5SSVSsnd3Z1CQ0OpqKiIiIhCQkIIAK1bt+61f6dKpaIxY8aI6i17eHhQYGAgnTlzRtT2zJkzNGrUKLKzsyNPT0+Kioqi2traZvc7adIk8vLyIq1W+9r+G7OVeq6cXBnrYKz1xycyMpLc3NwsHUazWpNci4uLSSqVUnp6ejtF1b40Gg2NHTuW9uzZY/a+S0tLSRAE2rp1q9HbWuv3u5EsvizMGDObjlQNxc/PD3FxcYiLi8PLly8tHY5RNBoNjh07hsrKSouUl4yNjcXQoUOhVCrN3re5cHJljLFWWrVqFcLCwhAeHm5Tk/Pn5ubiyJEjyMnJMfhdXVPZtm0bCgoKcPLkSchkMrP2bU6cXBlj7W716tVIS0tDeXk5fHx8cPjwYUuHZDKbNm2CUqlEQkKCpUMx2IQJE3DgwAHRHM7mcPz4cdTV1SE3Nxeurq5m7dvcpJYOgDHW8W3evBmbN2+2dBjtJigoCEFBQZYOw+oFBwcjODjY0mGYBZ+5MsYYYybGyZUxxhgzMU6ujDHGmIlxcmWMMcZMzCYeaEpKSkJ2dralw2DMJpw/fx4AEBYWZuFIbIduKj4+Ztbv/PnzormorZWEiMjSQbwOf9kZY4y9SldhyIplW31yZYwxxmxMNt9zZYwxxkyMkytjjDFmYpxcGWOMMRPj5MoYY4yZ2P8BRD1b5KdeJVkAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l4fUp32359cu"
      },
      "source": [
        "model.compile(\n",
        "    loss='categorical_crossentropy',\n",
        "    optimizer='adam',\n",
        "    metrics=['accuracy']\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u9TbRuwk599m",
        "outputId": "42c50197-49da-469e-924a-0e3803abc6a1"
      },
      "source": [
        "#50번 반복\n",
        "start_1 = time.time()\n",
        "\n",
        "history = model.fit(\n",
        "    x_train,\n",
        "    y_train,\n",
        "    epochs=50,\n",
        "    batch_size=32,\n",
        "    validation_split=0.1,\n",
        "    verbose = 1,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "sec_1 = time.time() - start_1\n",
        "times_1 = str(datetime.timedelta(seconds=sec_1)).split(\".\")\n",
        "times_1 = times_1[0]\n",
        "print(times_1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.5040 - accuracy: 0.8466 - val_loss: 0.1111 - val_accuracy: 0.9677\n",
            "Epoch 2/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.1133 - accuracy: 0.9655 - val_loss: 0.0975 - val_accuracy: 0.9735\n",
            "Epoch 3/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.0754 - accuracy: 0.9762 - val_loss: 0.0898 - val_accuracy: 0.9733\n",
            "Epoch 4/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.0523 - accuracy: 0.9836 - val_loss: 0.0899 - val_accuracy: 0.9733\n",
            "Epoch 5/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.0412 - accuracy: 0.9870 - val_loss: 0.0871 - val_accuracy: 0.9742\n",
            "Epoch 6/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.0289 - accuracy: 0.9902 - val_loss: 0.0856 - val_accuracy: 0.9768\n",
            "Epoch 7/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.0247 - accuracy: 0.9919 - val_loss: 0.0869 - val_accuracy: 0.9788\n",
            "Epoch 8/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.0182 - accuracy: 0.9942 - val_loss: 0.0881 - val_accuracy: 0.9780\n",
            "Epoch 9/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.0172 - accuracy: 0.9944 - val_loss: 0.0938 - val_accuracy: 0.9805\n",
            "Epoch 10/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.0137 - accuracy: 0.9953 - val_loss: 0.0950 - val_accuracy: 0.9782\n",
            "Epoch 11/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.0101 - accuracy: 0.9967 - val_loss: 0.1083 - val_accuracy: 0.9752\n",
            "Epoch 12/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.0116 - accuracy: 0.9962 - val_loss: 0.1090 - val_accuracy: 0.9760\n",
            "Epoch 13/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.0093 - accuracy: 0.9967 - val_loss: 0.1070 - val_accuracy: 0.9783\n",
            "Epoch 14/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.0088 - accuracy: 0.9974 - val_loss: 0.1215 - val_accuracy: 0.9778\n",
            "Epoch 15/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.0065 - accuracy: 0.9978 - val_loss: 0.1330 - val_accuracy: 0.9753\n",
            "Epoch 16/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.0075 - accuracy: 0.9977 - val_loss: 0.1061 - val_accuracy: 0.9807\n",
            "Epoch 17/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.0071 - accuracy: 0.9978 - val_loss: 0.1208 - val_accuracy: 0.9773\n",
            "Epoch 18/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.0086 - accuracy: 0.9971 - val_loss: 0.1339 - val_accuracy: 0.9770\n",
            "Epoch 19/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.0066 - accuracy: 0.9977 - val_loss: 0.1426 - val_accuracy: 0.9775\n",
            "Epoch 20/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.0070 - accuracy: 0.9975 - val_loss: 0.1219 - val_accuracy: 0.9780\n",
            "Epoch 21/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.0062 - accuracy: 0.9977 - val_loss: 0.1357 - val_accuracy: 0.9780\n",
            "Epoch 22/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.0051 - accuracy: 0.9982 - val_loss: 0.1415 - val_accuracy: 0.9788\n",
            "Epoch 23/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.0076 - accuracy: 0.9975 - val_loss: 0.1528 - val_accuracy: 0.9757\n",
            "Epoch 24/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.0058 - accuracy: 0.9977 - val_loss: 0.1570 - val_accuracy: 0.9758\n",
            "Epoch 25/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.0067 - accuracy: 0.9974 - val_loss: 0.1465 - val_accuracy: 0.9777\n",
            "Epoch 26/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.0058 - accuracy: 0.9979 - val_loss: 0.1382 - val_accuracy: 0.9808\n",
            "Epoch 27/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.0063 - accuracy: 0.9984 - val_loss: 0.1291 - val_accuracy: 0.9810\n",
            "Epoch 28/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.0044 - accuracy: 0.9985 - val_loss: 0.1429 - val_accuracy: 0.9785\n",
            "Epoch 29/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.0043 - accuracy: 0.9985 - val_loss: 0.1433 - val_accuracy: 0.9790\n",
            "Epoch 30/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.0047 - accuracy: 0.9987 - val_loss: 0.1388 - val_accuracy: 0.9795\n",
            "Epoch 31/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.0027 - accuracy: 0.9991 - val_loss: 0.1551 - val_accuracy: 0.9788\n",
            "Epoch 32/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.0043 - accuracy: 0.9987 - val_loss: 0.1512 - val_accuracy: 0.9795\n",
            "Epoch 33/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.0037 - accuracy: 0.9988 - val_loss: 0.1605 - val_accuracy: 0.9803\n",
            "Epoch 34/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.0030 - accuracy: 0.9989 - val_loss: 0.1478 - val_accuracy: 0.9793\n",
            "Epoch 35/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.0053 - accuracy: 0.9983 - val_loss: 0.1569 - val_accuracy: 0.9790\n",
            "Epoch 36/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.0032 - accuracy: 0.9987 - val_loss: 0.1601 - val_accuracy: 0.9788\n",
            "Epoch 37/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.0046 - accuracy: 0.9986 - val_loss: 0.1802 - val_accuracy: 0.9777\n",
            "Epoch 38/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.0078 - accuracy: 0.9979 - val_loss: 0.1860 - val_accuracy: 0.9798\n",
            "Epoch 39/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.0057 - accuracy: 0.9982 - val_loss: 0.1901 - val_accuracy: 0.9768\n",
            "Epoch 40/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.0038 - accuracy: 0.9988 - val_loss: 0.1917 - val_accuracy: 0.9787\n",
            "Epoch 41/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.0033 - accuracy: 0.9993 - val_loss: 0.1915 - val_accuracy: 0.9763\n",
            "Epoch 42/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.0068 - accuracy: 0.9979 - val_loss: 0.1670 - val_accuracy: 0.9793\n",
            "Epoch 43/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.0041 - accuracy: 0.9986 - val_loss: 0.1801 - val_accuracy: 0.9778\n",
            "Epoch 44/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.0040 - accuracy: 0.9986 - val_loss: 0.1694 - val_accuracy: 0.9812\n",
            "Epoch 45/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.0025 - accuracy: 0.9993 - val_loss: 0.1912 - val_accuracy: 0.9772\n",
            "Epoch 46/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.0054 - accuracy: 0.9982 - val_loss: 0.1991 - val_accuracy: 0.9785\n",
            "Epoch 47/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.0028 - accuracy: 0.9991 - val_loss: 0.1851 - val_accuracy: 0.9783\n",
            "Epoch 48/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.0018 - accuracy: 0.9995 - val_loss: 0.1929 - val_accuracy: 0.9780\n",
            "Epoch 49/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.0056 - accuracy: 0.9984 - val_loss: 0.1836 - val_accuracy: 0.9795\n",
            "Epoch 50/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.0055 - accuracy: 0.9986 - val_loss: 0.1730 - val_accuracy: 0.9802\n",
            "0:03:11\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KXCXFhSDong-",
        "outputId": "fae8216f-fae5-45f1-dcaf-6a0c80e0e2ad"
      },
      "source": [
        "#with dropout 50%\n",
        "model_dropout_50 = Sequential()\n",
        "model_dropout_50.add(Flatten(input_shape=(28, 28)))\n",
        "model_dropout_50.add(Dense(128))\n",
        "model_dropout_50.add(Dropout(0.5))\n",
        "model_dropout_50.add(Activation('relu'))\n",
        "model_dropout_50.add(Dense(128))\n",
        "model_dropout_50.add(Dropout(0.5))\n",
        "model_dropout_50.add(Activation('relu'))\n",
        "model_dropout_50.add(Dense(10))\n",
        "model_dropout_50.add(Activation('softmax'))\n",
        "model_dropout_50.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_2 (Flatten)          (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 128)               100480    \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "activation_6 (Activation)    (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "activation_7 (Activation)    (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 10)                1290      \n",
            "_________________________________________________________________\n",
            "activation_8 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 118,282\n",
            "Trainable params: 118,282\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ml3yolQEoo9D"
      },
      "source": [
        "model_dropout_50.compile(\n",
        "    loss='categorical_crossentropy',\n",
        "    optimizer='adam',\n",
        "    metrics=['accuracy']\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w5Hxw38RotGu",
        "outputId": "bbbc4a88-2130-4138-e1f8-411f9d57d1e4"
      },
      "source": [
        "#50번 반복//dropout 50%\n",
        "\n",
        "start_2 = time.time()\n",
        "\n",
        "history_50 = model_dropout_50.fit(\n",
        "    x_train,\n",
        "    y_train,\n",
        "    epochs=50,\n",
        "    batch_size=32,\n",
        "    validation_split=0.1,\n",
        "    verbose = 1,\n",
        "    shuffle=True\n",
        ")\n",
        "sec_2 = time.time() - start_2\n",
        "times_2 = str(datetime.timedelta(seconds=sec_2)).split(\".\")\n",
        "times_2 = times_2[0]\n",
        "print(times_2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "1688/1688 [==============================] - 5s 2ms/step - loss: 0.8557 - accuracy: 0.7298 - val_loss: 0.1655 - val_accuracy: 0.9498\n",
            "Epoch 2/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.3100 - accuracy: 0.9102 - val_loss: 0.1368 - val_accuracy: 0.9600\n",
            "Epoch 3/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.2394 - accuracy: 0.9305 - val_loss: 0.1081 - val_accuracy: 0.9688\n",
            "Epoch 4/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.2098 - accuracy: 0.9391 - val_loss: 0.0976 - val_accuracy: 0.9725\n",
            "Epoch 5/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.1972 - accuracy: 0.9414 - val_loss: 0.0885 - val_accuracy: 0.9753\n",
            "Epoch 6/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.1804 - accuracy: 0.9477 - val_loss: 0.0889 - val_accuracy: 0.9740\n",
            "Epoch 7/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.1722 - accuracy: 0.9496 - val_loss: 0.0901 - val_accuracy: 0.9757\n",
            "Epoch 8/50\n",
            "1688/1688 [==============================] - 4s 3ms/step - loss: 0.1627 - accuracy: 0.9525 - val_loss: 0.0856 - val_accuracy: 0.9743\n",
            "Epoch 9/50\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 0.1540 - accuracy: 0.9543 - val_loss: 0.0891 - val_accuracy: 0.9735\n",
            "Epoch 10/50\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 0.1487 - accuracy: 0.9550 - val_loss: 0.0809 - val_accuracy: 0.9785\n",
            "Epoch 11/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.1453 - accuracy: 0.9567 - val_loss: 0.0795 - val_accuracy: 0.9772\n",
            "Epoch 12/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.1328 - accuracy: 0.9595 - val_loss: 0.0764 - val_accuracy: 0.9787\n",
            "Epoch 13/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.1379 - accuracy: 0.9582 - val_loss: 0.0843 - val_accuracy: 0.9763\n",
            "Epoch 14/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.1346 - accuracy: 0.9588 - val_loss: 0.0766 - val_accuracy: 0.9778\n",
            "Epoch 15/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.1288 - accuracy: 0.9607 - val_loss: 0.0802 - val_accuracy: 0.9783\n",
            "Epoch 16/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.1238 - accuracy: 0.9621 - val_loss: 0.0787 - val_accuracy: 0.9773\n",
            "Epoch 17/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.1234 - accuracy: 0.9614 - val_loss: 0.0780 - val_accuracy: 0.9785\n",
            "Epoch 18/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.1186 - accuracy: 0.9640 - val_loss: 0.0846 - val_accuracy: 0.9788\n",
            "Epoch 19/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.1169 - accuracy: 0.9645 - val_loss: 0.0777 - val_accuracy: 0.9798\n",
            "Epoch 20/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.1135 - accuracy: 0.9660 - val_loss: 0.0769 - val_accuracy: 0.9797\n",
            "Epoch 21/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.1187 - accuracy: 0.9646 - val_loss: 0.0776 - val_accuracy: 0.9792\n",
            "Epoch 22/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.1121 - accuracy: 0.9657 - val_loss: 0.0773 - val_accuracy: 0.9788\n",
            "Epoch 23/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.1110 - accuracy: 0.9659 - val_loss: 0.0787 - val_accuracy: 0.9783\n",
            "Epoch 24/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.1142 - accuracy: 0.9666 - val_loss: 0.0783 - val_accuracy: 0.9785\n",
            "Epoch 25/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.1072 - accuracy: 0.9670 - val_loss: 0.0780 - val_accuracy: 0.9783\n",
            "Epoch 26/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.1081 - accuracy: 0.9674 - val_loss: 0.0768 - val_accuracy: 0.9788\n",
            "Epoch 27/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.1083 - accuracy: 0.9678 - val_loss: 0.0779 - val_accuracy: 0.9788\n",
            "Epoch 28/50\n",
            "1688/1688 [==============================] - 4s 3ms/step - loss: 0.1058 - accuracy: 0.9691 - val_loss: 0.0756 - val_accuracy: 0.9790\n",
            "Epoch 29/50\n",
            "1688/1688 [==============================] - 4s 3ms/step - loss: 0.1047 - accuracy: 0.9678 - val_loss: 0.0749 - val_accuracy: 0.9783\n",
            "Epoch 30/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.1029 - accuracy: 0.9700 - val_loss: 0.0808 - val_accuracy: 0.9800\n",
            "Epoch 31/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.1013 - accuracy: 0.9694 - val_loss: 0.0804 - val_accuracy: 0.9792\n",
            "Epoch 32/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.1059 - accuracy: 0.9687 - val_loss: 0.0775 - val_accuracy: 0.9780\n",
            "Epoch 33/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.0948 - accuracy: 0.9713 - val_loss: 0.0863 - val_accuracy: 0.9777\n",
            "Epoch 34/50\n",
            "1688/1688 [==============================] - 4s 3ms/step - loss: 0.1012 - accuracy: 0.9695 - val_loss: 0.0818 - val_accuracy: 0.9788\n",
            "Epoch 35/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.0987 - accuracy: 0.9709 - val_loss: 0.0846 - val_accuracy: 0.9795\n",
            "Epoch 36/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.1013 - accuracy: 0.9689 - val_loss: 0.0842 - val_accuracy: 0.9785\n",
            "Epoch 37/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.0968 - accuracy: 0.9690 - val_loss: 0.0857 - val_accuracy: 0.9795\n",
            "Epoch 38/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.0955 - accuracy: 0.9707 - val_loss: 0.0894 - val_accuracy: 0.9790\n",
            "Epoch 39/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.0940 - accuracy: 0.9720 - val_loss: 0.0846 - val_accuracy: 0.9803\n",
            "Epoch 40/50\n",
            "1688/1688 [==============================] - 4s 3ms/step - loss: 0.0906 - accuracy: 0.9724 - val_loss: 0.0850 - val_accuracy: 0.9777\n",
            "Epoch 41/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.0920 - accuracy: 0.9726 - val_loss: 0.0869 - val_accuracy: 0.9765\n",
            "Epoch 42/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.0938 - accuracy: 0.9711 - val_loss: 0.0926 - val_accuracy: 0.9775\n",
            "Epoch 43/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.0861 - accuracy: 0.9725 - val_loss: 0.0930 - val_accuracy: 0.9775\n",
            "Epoch 44/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.0930 - accuracy: 0.9719 - val_loss: 0.0935 - val_accuracy: 0.9792\n",
            "Epoch 45/50\n",
            "1688/1688 [==============================] - 4s 3ms/step - loss: 0.0888 - accuracy: 0.9733 - val_loss: 0.0859 - val_accuracy: 0.9787\n",
            "Epoch 46/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.0953 - accuracy: 0.9715 - val_loss: 0.0881 - val_accuracy: 0.9772\n",
            "Epoch 47/50\n",
            "1688/1688 [==============================] - 4s 3ms/step - loss: 0.0827 - accuracy: 0.9737 - val_loss: 0.0896 - val_accuracy: 0.9792\n",
            "Epoch 48/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.0864 - accuracy: 0.9738 - val_loss: 0.0917 - val_accuracy: 0.9775\n",
            "Epoch 49/50\n",
            "1688/1688 [==============================] - 4s 3ms/step - loss: 0.0879 - accuracy: 0.9738 - val_loss: 0.0912 - val_accuracy: 0.9778\n",
            "Epoch 50/50\n",
            "1688/1688 [==============================] - 4s 3ms/step - loss: 0.0887 - accuracy: 0.9720 - val_loss: 0.0927 - val_accuracy: 0.9783\n",
            "0:03:28\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n7J2poRZrMjV",
        "outputId": "519b4ff5-3ac1-4077-c875-23e5d1f80c98"
      },
      "source": [
        "start_3 = time.time()\n",
        "\n",
        "history_50_half = model_dropout_50.fit(\n",
        "    x_train,\n",
        "    y_train,\n",
        "    epochs=25,\n",
        "    batch_size=32,\n",
        "    validation_split=0.1,\n",
        "    verbose = 1,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "sec_3 = time.time() - start_3\n",
        "times_3 = str(datetime.timedelta(seconds=sec_3)).split(\".\")\n",
        "times_3 = times_3[0]\n",
        "print(times_3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.0881 - accuracy: 0.9727 - val_loss: 0.0838 - val_accuracy: 0.9793\n",
            "Epoch 2/25\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.0880 - accuracy: 0.9736 - val_loss: 0.0893 - val_accuracy: 0.9788\n",
            "Epoch 3/25\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.0863 - accuracy: 0.9741 - val_loss: 0.0909 - val_accuracy: 0.9785\n",
            "Epoch 4/25\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.0865 - accuracy: 0.9732 - val_loss: 0.0899 - val_accuracy: 0.9800\n",
            "Epoch 5/25\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.0886 - accuracy: 0.9733 - val_loss: 0.0896 - val_accuracy: 0.9810\n",
            "Epoch 6/25\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.0856 - accuracy: 0.9741 - val_loss: 0.0951 - val_accuracy: 0.9807\n",
            "Epoch 7/25\n",
            "1688/1688 [==============================] - 4s 3ms/step - loss: 0.0863 - accuracy: 0.9736 - val_loss: 0.0916 - val_accuracy: 0.9797\n",
            "Epoch 8/25\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.0880 - accuracy: 0.9733 - val_loss: 0.0885 - val_accuracy: 0.9805\n",
            "Epoch 9/25\n",
            "1688/1688 [==============================] - 4s 3ms/step - loss: 0.0853 - accuracy: 0.9742 - val_loss: 0.0927 - val_accuracy: 0.9788\n",
            "Epoch 10/25\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.0859 - accuracy: 0.9738 - val_loss: 0.0922 - val_accuracy: 0.9792\n",
            "Epoch 11/25\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.0842 - accuracy: 0.9742 - val_loss: 0.0967 - val_accuracy: 0.9797\n",
            "Epoch 12/25\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.0853 - accuracy: 0.9736 - val_loss: 0.0942 - val_accuracy: 0.9787\n",
            "Epoch 13/25\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.0836 - accuracy: 0.9732 - val_loss: 0.1005 - val_accuracy: 0.9775\n",
            "Epoch 14/25\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.0838 - accuracy: 0.9747 - val_loss: 0.0957 - val_accuracy: 0.9793\n",
            "Epoch 15/25\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.0825 - accuracy: 0.9751 - val_loss: 0.1021 - val_accuracy: 0.9785\n",
            "Epoch 16/25\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.0807 - accuracy: 0.9749 - val_loss: 0.0961 - val_accuracy: 0.9795\n",
            "Epoch 17/25\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.0824 - accuracy: 0.9757 - val_loss: 0.0997 - val_accuracy: 0.9778\n",
            "Epoch 18/25\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.0800 - accuracy: 0.9745 - val_loss: 0.1013 - val_accuracy: 0.9793\n",
            "Epoch 19/25\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.0815 - accuracy: 0.9756 - val_loss: 0.1038 - val_accuracy: 0.9773\n",
            "Epoch 20/25\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.0777 - accuracy: 0.9755 - val_loss: 0.1075 - val_accuracy: 0.9757\n",
            "Epoch 21/25\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.0807 - accuracy: 0.9759 - val_loss: 0.1019 - val_accuracy: 0.9782\n",
            "Epoch 22/25\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.0826 - accuracy: 0.9750 - val_loss: 0.1012 - val_accuracy: 0.9767\n",
            "Epoch 23/25\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.0799 - accuracy: 0.9760 - val_loss: 0.0980 - val_accuracy: 0.9788\n",
            "Epoch 24/25\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.0775 - accuracy: 0.9768 - val_loss: 0.1008 - val_accuracy: 0.9785\n",
            "Epoch 25/25\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.0794 - accuracy: 0.9758 - val_loss: 0.1042 - val_accuracy: 0.9785\n",
            "0:01:42\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L6TYXprnud_n",
        "outputId": "4becbdd8-f537-47e9-d735-720c85f0e69e"
      },
      "source": [
        "#with dropout 75%\n",
        "model_dropout_75 = Sequential()\n",
        "model_dropout_75.add(Flatten(input_shape=(28, 28)))\n",
        "model_dropout_75.add(Dense(128))\n",
        "model_dropout_75.add(Dropout(0.75))\n",
        "model_dropout_75.add(Activation('relu'))\n",
        "model_dropout_75.add(Dense(128))\n",
        "model_dropout_75.add(Dropout(0.75))\n",
        "model_dropout_75.add(Activation('relu'))\n",
        "model_dropout_75.add(Dense(10))\n",
        "model_dropout_75.add(Activation('softmax'))\n",
        "model_dropout_75.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_3 (Flatten)          (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 128)               100480    \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "activation_9 (Activation)    (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "activation_10 (Activation)   (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 10)                1290      \n",
            "_________________________________________________________________\n",
            "activation_11 (Activation)   (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 118,282\n",
            "Trainable params: 118,282\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QpMQzGNYuyWL"
      },
      "source": [
        "model_dropout_75.compile(\n",
        "    loss='categorical_crossentropy',\n",
        "    optimizer='adam',\n",
        "    metrics=['accuracy']\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rDp2jFVCun3b",
        "outputId": "78f5dab4-697d-4aa1-85ba-d576c6dcd38f"
      },
      "source": [
        "start_4 = time.time()\n",
        "\n",
        "history_75 = model_dropout_75.fit(\n",
        "    x_train,\n",
        "    y_train,\n",
        "    epochs=50,\n",
        "    batch_size=32,\n",
        "    validation_split=0.1,\n",
        "    verbose = 1,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "sec_4 = time.time() - start_4\n",
        "times_4 = str(datetime.timedelta(seconds=sec_4)).split(\".\")\n",
        "times_4 = times_4[0]\n",
        "print(times_4)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 1.4178 - accuracy: 0.5074 - val_loss: 0.2750 - val_accuracy: 0.9283\n",
            "Epoch 2/50\n",
            "1688/1688 [==============================] - 4s 3ms/step - loss: 0.6310 - accuracy: 0.8146 - val_loss: 0.2166 - val_accuracy: 0.9457\n",
            "Epoch 3/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.5342 - accuracy: 0.8486 - val_loss: 0.1882 - val_accuracy: 0.9502\n",
            "Epoch 4/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.5184 - accuracy: 0.8559 - val_loss: 0.1853 - val_accuracy: 0.9507\n",
            "Epoch 5/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.4873 - accuracy: 0.8637 - val_loss: 0.1724 - val_accuracy: 0.9537\n",
            "Epoch 6/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.4722 - accuracy: 0.8675 - val_loss: 0.1630 - val_accuracy: 0.9563\n",
            "Epoch 7/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.4507 - accuracy: 0.8729 - val_loss: 0.1570 - val_accuracy: 0.9580\n",
            "Epoch 8/50\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 0.4367 - accuracy: 0.8794 - val_loss: 0.1601 - val_accuracy: 0.9590\n",
            "Epoch 9/50\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 0.4184 - accuracy: 0.8817 - val_loss: 0.1463 - val_accuracy: 0.9588\n",
            "Epoch 10/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.4202 - accuracy: 0.8804 - val_loss: 0.1519 - val_accuracy: 0.9592\n",
            "Epoch 11/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.4109 - accuracy: 0.8852 - val_loss: 0.1422 - val_accuracy: 0.9640\n",
            "Epoch 12/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.4103 - accuracy: 0.8834 - val_loss: 0.1382 - val_accuracy: 0.9620\n",
            "Epoch 13/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.4102 - accuracy: 0.8854 - val_loss: 0.1501 - val_accuracy: 0.9600\n",
            "Epoch 14/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.4141 - accuracy: 0.8855 - val_loss: 0.1495 - val_accuracy: 0.9615\n",
            "Epoch 15/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.4019 - accuracy: 0.8871 - val_loss: 0.1413 - val_accuracy: 0.9620\n",
            "Epoch 16/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.3967 - accuracy: 0.8862 - val_loss: 0.1462 - val_accuracy: 0.9635\n",
            "Epoch 17/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.3925 - accuracy: 0.8892 - val_loss: 0.1399 - val_accuracy: 0.9620\n",
            "Epoch 18/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.3903 - accuracy: 0.8903 - val_loss: 0.1467 - val_accuracy: 0.9630\n",
            "Epoch 19/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.3805 - accuracy: 0.8926 - val_loss: 0.1432 - val_accuracy: 0.9627\n",
            "Epoch 20/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.3912 - accuracy: 0.8891 - val_loss: 0.1399 - val_accuracy: 0.9655\n",
            "Epoch 21/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.3763 - accuracy: 0.8920 - val_loss: 0.1465 - val_accuracy: 0.9643\n",
            "Epoch 22/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.3848 - accuracy: 0.8932 - val_loss: 0.1370 - val_accuracy: 0.9652\n",
            "Epoch 23/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.3845 - accuracy: 0.8927 - val_loss: 0.1398 - val_accuracy: 0.9638\n",
            "Epoch 24/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.3758 - accuracy: 0.8926 - val_loss: 0.1398 - val_accuracy: 0.9632\n",
            "Epoch 25/50\n",
            "1688/1688 [==============================] - 4s 3ms/step - loss: 0.3703 - accuracy: 0.8956 - val_loss: 0.1379 - val_accuracy: 0.9658\n",
            "Epoch 26/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.3673 - accuracy: 0.8955 - val_loss: 0.1464 - val_accuracy: 0.9620\n",
            "Epoch 27/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.3713 - accuracy: 0.8936 - val_loss: 0.1357 - val_accuracy: 0.9648\n",
            "Epoch 28/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.3681 - accuracy: 0.8939 - val_loss: 0.1431 - val_accuracy: 0.9650\n",
            "Epoch 29/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.3664 - accuracy: 0.8961 - val_loss: 0.1380 - val_accuracy: 0.9653\n",
            "Epoch 30/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.3649 - accuracy: 0.8943 - val_loss: 0.1367 - val_accuracy: 0.9663\n",
            "Epoch 31/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.3610 - accuracy: 0.8964 - val_loss: 0.1401 - val_accuracy: 0.9665\n",
            "Epoch 32/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.3549 - accuracy: 0.8992 - val_loss: 0.1412 - val_accuracy: 0.9658\n",
            "Epoch 33/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.3682 - accuracy: 0.8967 - val_loss: 0.1406 - val_accuracy: 0.9667\n",
            "Epoch 34/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.3626 - accuracy: 0.8954 - val_loss: 0.1396 - val_accuracy: 0.9663\n",
            "Epoch 35/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.3449 - accuracy: 0.8994 - val_loss: 0.1343 - val_accuracy: 0.9665\n",
            "Epoch 36/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.3616 - accuracy: 0.8993 - val_loss: 0.1388 - val_accuracy: 0.9653\n",
            "Epoch 37/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.3495 - accuracy: 0.8984 - val_loss: 0.1378 - val_accuracy: 0.9673\n",
            "Epoch 38/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.3580 - accuracy: 0.8998 - val_loss: 0.1374 - val_accuracy: 0.9687\n",
            "Epoch 39/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.3485 - accuracy: 0.8997 - val_loss: 0.1327 - val_accuracy: 0.9683\n",
            "Epoch 40/50\n",
            "1688/1688 [==============================] - 4s 3ms/step - loss: 0.3392 - accuracy: 0.9011 - val_loss: 0.1427 - val_accuracy: 0.9670\n",
            "Epoch 41/50\n",
            "1688/1688 [==============================] - 4s 3ms/step - loss: 0.3556 - accuracy: 0.8967 - val_loss: 0.1388 - val_accuracy: 0.9673\n",
            "Epoch 42/50\n",
            "1688/1688 [==============================] - 4s 3ms/step - loss: 0.3453 - accuracy: 0.9007 - val_loss: 0.1440 - val_accuracy: 0.9678\n",
            "Epoch 43/50\n",
            "1688/1688 [==============================] - 4s 3ms/step - loss: 0.3453 - accuracy: 0.9001 - val_loss: 0.1431 - val_accuracy: 0.9670\n",
            "Epoch 44/50\n",
            "1688/1688 [==============================] - 4s 3ms/step - loss: 0.3506 - accuracy: 0.8993 - val_loss: 0.1407 - val_accuracy: 0.9682\n",
            "Epoch 45/50\n",
            "1688/1688 [==============================] - 4s 3ms/step - loss: 0.3425 - accuracy: 0.9000 - val_loss: 0.1484 - val_accuracy: 0.9648\n",
            "Epoch 46/50\n",
            "1688/1688 [==============================] - 4s 3ms/step - loss: 0.3476 - accuracy: 0.9001 - val_loss: 0.1469 - val_accuracy: 0.9680\n",
            "Epoch 47/50\n",
            "1688/1688 [==============================] - 4s 3ms/step - loss: 0.3447 - accuracy: 0.8999 - val_loss: 0.1403 - val_accuracy: 0.9673\n",
            "Epoch 48/50\n",
            "1688/1688 [==============================] - 4s 3ms/step - loss: 0.3365 - accuracy: 0.9039 - val_loss: 0.1413 - val_accuracy: 0.9663\n",
            "Epoch 49/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.3399 - accuracy: 0.9027 - val_loss: 0.1460 - val_accuracy: 0.9667\n",
            "Epoch 50/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.3367 - accuracy: 0.9046 - val_loss: 0.1353 - val_accuracy: 0.9690\n",
            "0:03:31\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YCY1Kx87vEoy",
        "outputId": "b93bd0d4-ed47-488c-e887-089660012446"
      },
      "source": [
        "start_5 = time.time()\n",
        "\n",
        "history_75 = model_dropout_75.fit(\n",
        "    x_train,\n",
        "    y_train,\n",
        "    epochs=25,\n",
        "    batch_size=32,\n",
        "    validation_split=0.1,\n",
        "    verbose = 1,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "sec_5 = time.time() - start_5\n",
        "times_5 = str(datetime.timedelta(seconds=sec_5)).split(\".\")\n",
        "times_5 = times_5[0]\n",
        "print(times_5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "1688/1688 [==============================] - 4s 3ms/step - loss: 0.3449 - accuracy: 0.9013 - val_loss: 0.1458 - val_accuracy: 0.9667\n",
            "Epoch 2/25\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.3428 - accuracy: 0.9016 - val_loss: 0.1416 - val_accuracy: 0.9663\n",
            "Epoch 3/25\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.3426 - accuracy: 0.9000 - val_loss: 0.1514 - val_accuracy: 0.9668\n",
            "Epoch 4/25\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.3398 - accuracy: 0.9011 - val_loss: 0.1421 - val_accuracy: 0.9710\n",
            "Epoch 5/25\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.3424 - accuracy: 0.8998 - val_loss: 0.1479 - val_accuracy: 0.9688\n",
            "Epoch 6/25\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.3433 - accuracy: 0.9003 - val_loss: 0.1415 - val_accuracy: 0.9672\n",
            "Epoch 7/25\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.3377 - accuracy: 0.9020 - val_loss: 0.1448 - val_accuracy: 0.9665\n",
            "Epoch 8/25\n",
            "1688/1688 [==============================] - 4s 3ms/step - loss: 0.3451 - accuracy: 0.9016 - val_loss: 0.1436 - val_accuracy: 0.9670\n",
            "Epoch 9/25\n",
            "1688/1688 [==============================] - 4s 3ms/step - loss: 0.3390 - accuracy: 0.9014 - val_loss: 0.1445 - val_accuracy: 0.9678\n",
            "Epoch 10/25\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.3345 - accuracy: 0.9032 - val_loss: 0.1453 - val_accuracy: 0.9678\n",
            "Epoch 11/25\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.3407 - accuracy: 0.9030 - val_loss: 0.1438 - val_accuracy: 0.9685\n",
            "Epoch 12/25\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.3391 - accuracy: 0.9026 - val_loss: 0.1449 - val_accuracy: 0.9682\n",
            "Epoch 13/25\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.3384 - accuracy: 0.9028 - val_loss: 0.1424 - val_accuracy: 0.9682\n",
            "Epoch 14/25\n",
            "1688/1688 [==============================] - 4s 3ms/step - loss: 0.3375 - accuracy: 0.9011 - val_loss: 0.1427 - val_accuracy: 0.9678\n",
            "Epoch 15/25\n",
            "1688/1688 [==============================] - 4s 3ms/step - loss: 0.3477 - accuracy: 0.9004 - val_loss: 0.1519 - val_accuracy: 0.9660\n",
            "Epoch 16/25\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.3351 - accuracy: 0.9015 - val_loss: 0.1521 - val_accuracy: 0.9680\n",
            "Epoch 17/25\n",
            "1688/1688 [==============================] - 4s 3ms/step - loss: 0.3332 - accuracy: 0.9020 - val_loss: 0.1485 - val_accuracy: 0.9692\n",
            "Epoch 18/25\n",
            "1688/1688 [==============================] - 4s 3ms/step - loss: 0.3351 - accuracy: 0.9029 - val_loss: 0.1412 - val_accuracy: 0.9663\n",
            "Epoch 19/25\n",
            "1688/1688 [==============================] - 4s 3ms/step - loss: 0.3350 - accuracy: 0.9022 - val_loss: 0.1483 - val_accuracy: 0.9660\n",
            "Epoch 20/25\n",
            "1688/1688 [==============================] - 4s 3ms/step - loss: 0.3352 - accuracy: 0.9030 - val_loss: 0.1489 - val_accuracy: 0.9680\n",
            "Epoch 21/25\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.3338 - accuracy: 0.9034 - val_loss: 0.1474 - val_accuracy: 0.9672\n",
            "Epoch 22/25\n",
            "1688/1688 [==============================] - 4s 3ms/step - loss: 0.3388 - accuracy: 0.9016 - val_loss: 0.1520 - val_accuracy: 0.9698\n",
            "Epoch 23/25\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.3359 - accuracy: 0.9029 - val_loss: 0.1462 - val_accuracy: 0.9692\n",
            "Epoch 24/25\n",
            "1688/1688 [==============================] - 4s 3ms/step - loss: 0.3267 - accuracy: 0.9035 - val_loss: 0.1518 - val_accuracy: 0.9687\n",
            "Epoch 25/25\n",
            "1688/1688 [==============================] - 4s 3ms/step - loss: 0.3256 - accuracy: 0.9064 - val_loss: 0.1502 - val_accuracy: 0.9675\n",
            "0:01:46\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7gCmMkgO6EzD",
        "outputId": "2ab56a0a-fd1d-4935-88fd-9605ca4a7a5f"
      },
      "source": [
        "weight_array_50 = model_dropout_50.get_weights()\n",
        "weight_array_50\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([[-0.06526154, -0.03391934,  0.00629923, ...,  0.04787786,\n",
              "         -0.02168988,  0.06990128],\n",
              "        [-0.05644856,  0.0498646 ,  0.0098365 , ...,  0.07672832,\n",
              "          0.07871274, -0.01903446],\n",
              "        [ 0.00280005,  0.03488851, -0.06356074, ..., -0.02683819,\n",
              "         -0.02091702, -0.03646635],\n",
              "        ...,\n",
              "        [-0.02395352,  0.07279383, -0.01720546, ..., -0.06917419,\n",
              "         -0.00539654,  0.0719874 ],\n",
              "        [ 0.01464762,  0.07335281,  0.00271396, ...,  0.01807696,\n",
              "          0.0762684 , -0.06908229],\n",
              "        [ 0.05730804, -0.07146813, -0.00092696, ...,  0.01155809,\n",
              "         -0.00890138, -0.02690056]], dtype=float32),\n",
              " array([-0.19160196, -0.48444143, -0.05657321, -0.47530577,  0.14700063,\n",
              "         0.0277285 , -0.3785028 , -0.10574704,  0.0368518 , -0.2195262 ,\n",
              "        -0.01469063, -0.13358323, -0.8352137 , -0.3553853 , -0.53196335,\n",
              "        -0.24124819, -0.0077738 , -0.09785039, -0.02227728, -0.27971262,\n",
              "        -0.5984076 , -0.19048947, -0.27796838, -0.3115249 , -0.1738765 ,\n",
              "        -0.8677474 , -0.05698395,  0.36914256, -0.96395695, -0.00752298,\n",
              "        -0.4094031 , -0.33205268, -0.2018411 ,  0.23814292, -0.63781834,\n",
              "        -0.5238939 , -0.00744135, -0.493432  , -0.07178122, -0.02232371,\n",
              "        -0.63268954,  0.13823606, -0.36761495, -0.02063436, -0.45472956,\n",
              "        -0.09566581, -0.25848842, -0.13827564,  0.05841715, -0.96020293,\n",
              "        -0.14867578, -0.10069851, -1.1192683 , -0.37443784, -0.33789802,\n",
              "        -0.26241025, -0.46470752, -0.18332194,  0.36067125, -0.24661516,\n",
              "        -0.47446394, -0.4435328 , -0.1146755 , -0.46155176, -0.10974985,\n",
              "        -0.35466918, -0.20598263, -0.7467645 ,  0.01432039,  0.15193826,\n",
              "        -0.5434002 , -0.06052158,  0.03046431,  0.12918863,  0.10010395,\n",
              "        -0.08876815,  0.03389094, -0.31565574, -0.03656777, -0.10507982,\n",
              "        -0.21444926, -0.07826653, -0.04698242,  0.03644682, -0.02873721,\n",
              "        -0.55735916, -0.07933018, -0.13618185, -0.3612021 , -0.08004639,\n",
              "        -0.06018788, -0.7736559 , -0.09134025, -0.42019784, -0.16690396,\n",
              "        -0.35330513,  0.0311452 , -0.07275102, -0.39430752, -0.0112242 ,\n",
              "        -0.19781962, -0.2752422 , -0.8516894 , -0.25690073,  0.08309258,\n",
              "        -0.36111456, -0.23053586,  0.03568941, -0.12341336, -0.46065333,\n",
              "         0.1831341 ,  0.26221234,  0.14651781, -0.06676731, -0.08393431,\n",
              "        -0.53962576, -0.2540467 , -0.27871105, -0.16470581, -1.3850654 ,\n",
              "         0.17800112, -0.32612914, -1.1154302 , -0.4258388 ,  0.2554979 ,\n",
              "        -0.23115993,  0.14753605,  0.06620589], dtype=float32),\n",
              " array([[-0.65919876,  0.2960123 , -0.5109955 , ..., -0.07766209,\n",
              "          0.16576529,  0.22036727],\n",
              "        [ 0.01804912, -0.74623686, -0.11501849, ...,  0.5164638 ,\n",
              "          0.11077293,  0.00835315],\n",
              "        [-0.76761234,  0.57295084, -0.12211868, ..., -0.01397012,\n",
              "         -0.20745887, -0.42782506],\n",
              "        ...,\n",
              "        [-0.60587436,  0.00098428, -0.6999823 , ...,  0.0052393 ,\n",
              "         -0.06895095, -0.12294241],\n",
              "        [-0.08703155,  0.237725  ,  0.9381868 , ..., -0.19167326,\n",
              "         -0.35543773, -0.00673128],\n",
              "        [-0.7511042 ,  0.20436999, -0.03362662, ..., -0.37697768,\n",
              "          0.1409523 ,  0.48446342]], dtype=float32),\n",
              " array([ 0.4625659 ,  0.06895496, -0.08534371,  0.0426801 , -0.01798783,\n",
              "        -0.04138407,  0.09818968,  0.18843243, -0.242638  ,  0.19507702,\n",
              "         0.20122573, -0.34663   , -0.6924504 ,  0.08909932,  0.25096673,\n",
              "        -0.06780597, -0.6721068 ,  0.35940957, -0.42482468,  0.24075651,\n",
              "        -0.5833104 ,  0.13577744,  0.09905574, -0.37646204, -1.06131   ,\n",
              "         0.08259926,  0.10371382, -0.7462823 ,  0.25502324, -0.54038554,\n",
              "        -0.41023898,  0.03822173, -0.05364403, -0.16512874, -0.46199062,\n",
              "         0.05517248, -0.43429396, -0.01458452, -0.07042621,  0.2443863 ,\n",
              "         0.28895065,  0.10852942, -0.548622  ,  0.6494245 ,  0.30178034,\n",
              "        -0.08451711, -0.23232834, -0.4840542 , -0.15799509, -0.42678997,\n",
              "         0.04034195,  0.09494775,  0.5635568 , -0.19800553,  0.04886703,\n",
              "         0.41486362,  0.5120682 , -0.13382116, -0.34902015,  0.29609862,\n",
              "         0.38372043,  0.36569965,  0.5818573 , -0.948539  , -0.25695354,\n",
              "         0.30391493, -1.0017602 , -0.66753566,  0.2072397 ,  0.26574582,\n",
              "        -0.21027476, -0.04595806,  0.10697105,  0.23207313,  0.39732373,\n",
              "        -0.93025196, -0.46040255, -0.41923183,  0.04558564,  0.08136845,\n",
              "        -1.0763564 ,  0.21204005,  0.04078868, -0.08080038, -0.9325499 ,\n",
              "         0.07997109, -0.55099034,  0.17597488, -0.5243492 , -0.02689414,\n",
              "        -0.3781061 ,  0.06130194,  0.2647921 , -0.6404291 ,  0.28034335,\n",
              "         0.5456246 , -0.38227338, -0.7592524 , -0.03010965,  0.03967849,\n",
              "        -0.08315254, -0.05786988,  0.590241  , -0.6344435 ,  0.04252156,\n",
              "        -0.4042521 , -0.8387552 , -0.05522842, -0.08120269, -0.67857623,\n",
              "         0.0375288 ,  0.07759053,  0.41874123,  0.10107309,  0.31955576,\n",
              "         0.23333383,  0.2543483 , -0.14264986,  0.20412438, -0.20045614,\n",
              "        -0.01350551,  0.03302381,  0.394662  ,  0.14560845, -0.15057342,\n",
              "         0.27844647,  0.12466402, -0.1640272 ], dtype=float32),\n",
              " array([[ 0.1568885 , -0.22566186, -0.04076631, ...,  0.11461718,\n",
              "          0.15101646,  0.07227472],\n",
              "        [ 0.03739363, -0.15175433, -0.24116288, ...,  0.07889244,\n",
              "         -0.71295756,  0.07543747],\n",
              "        [-0.93161523, -0.16243513, -0.35984185, ...,  0.10268225,\n",
              "          0.0312758 ,  0.09616185],\n",
              "        ...,\n",
              "        [-0.27913427,  0.0795748 ,  0.09191956, ...,  0.1053337 ,\n",
              "          0.09994728, -0.6189789 ],\n",
              "        [ 0.0604375 , -0.64956546,  0.01898013, ..., -0.4402535 ,\n",
              "          0.08053026, -0.15669204],\n",
              "        [ 0.07152934, -0.3431166 ,  0.10702402, ...,  0.09410325,\n",
              "         -0.368739  ,  0.05797601]], dtype=float32),\n",
              " array([ 0.7098913 , -0.22134705, -1.0428084 , -0.09258387,  0.2877675 ,\n",
              "        -0.85766536, -0.01655424, -0.5783452 ,  1.0890386 ,  0.52586466],\n",
              "       dtype=float32)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XV3nJBalAeG-",
        "outputId": "ef3b36ee-f9c4-442b-bb41-366e0c15561a"
      },
      "source": [
        "n = len(weight_array_50)\n",
        "n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJMjcK4Kwlyk"
      },
      "source": [
        "class MatrixFactorization():\n",
        "    def __init__(self, R, k, learning_rate, reg_param, epochs, verbose=False):\n",
        "        \"\"\"\n",
        "        :param R: rating matrix\n",
        "        :param k: latent parameter\n",
        "        :param learning_rate: alpha on weight update\n",
        "        :param reg_param: beta on weight update\n",
        "        :param epochs: training epochs\n",
        "        :param verbose: print status\n",
        "        \"\"\"\n",
        "\n",
        "        self._R = R\n",
        "        self.x, self.y = R.shape\n",
        "        self._k = k\n",
        "        self._learning_rate = learning_rate\n",
        "        self._reg_param = reg_param\n",
        "        self._epochs = epochs\n",
        "        self._verbose = verbose\n",
        "\n",
        "\n",
        "    def fit(self):\n",
        "        \"\"\"\n",
        "        training Matrix Factorization : Update matrix latent weight and bias\n",
        "\n",
        "        참고: self._b에 대한 설명\n",
        "        - global bias: input R에서 평가가 매겨진 rating의 평균값을 global bias로 사용\n",
        "        - 정규화 기능. 최종 rating에 음수가 들어가는 것 대신 latent feature에 음수가 포함되도록 해줌.\n",
        "\n",
        "        :return: training_process\n",
        "        \"\"\"\n",
        "        # init latent features\n",
        "        self._P = np.random.normal(size=(self.x, self._k))\n",
        "        self._Q = np.random.normal(size=(self.y, self._k))\n",
        "\n",
        "        # init biases\n",
        "        self._b_P = np.zeros(self.x)\n",
        "        self._b_Q = np.zeros(self.y)\n",
        "        self._b = np.mean(self._R[np.where(self._R != 0)])\n",
        "        \n",
        "\n",
        "        # train while epochs\n",
        "        self._training_process = []\n",
        "        for epoch in range(self._epochs):\n",
        "\n",
        "            # rating이 존재하는 index를 기준으로 training\n",
        "            for i in range(self.x):\n",
        "                for j in range(self.y):\n",
        "                    if self._R[i, j] > 0:\n",
        "                        self.gradient_descent(i, j, self._R[i, j])\n",
        "            cost = self.cost()\n",
        "            self._training_process.append((epoch, cost))\n",
        "\n",
        "            # print status\n",
        "            if self._verbose == True and ((epoch + 1) % 10 == 0):\n",
        "                print(\"Iteration: %d ; cost = %.4f\" % (epoch + 1, cost))\n",
        "\n",
        "\n",
        "    def cost(self):\n",
        "        \"\"\"\n",
        "        compute root mean square error\n",
        "        :return: rmse cost\n",
        "        \"\"\"\n",
        "\n",
        "        # xi, yi: R[xi, yi]는 nonzero인 value를 의미한다.\n",
        "        # 참고: http://codepractice.tistory.com/90\n",
        "        Xi, Yi = self._R.nonzero()\n",
        "        predicted = self.get_complete_matrix()\n",
        "        cost = 0\n",
        "        for X, Y in zip(Xi, Yi):\n",
        "            cost += pow(self._R[X, Y] - predicted[X, Y], 2)\n",
        "        return np.sqrt(cost) / len(Xi)\n",
        "\n",
        "\n",
        "    def gradient(self, error, i, j):\n",
        "        \"\"\"\n",
        "        gradient of latent feature for GD\n",
        "\n",
        "        :param error: rating - prediction error\n",
        "        :param i: user index\n",
        "        :param j: item index\n",
        "        :return: gradient of latent feature tuple\n",
        "        \"\"\"\n",
        "\n",
        "        dp = (error * self._Q[j, :]) - (self._reg_param * self._P[i, :])\n",
        "        dq = (error * self._P[i, :]) - (self._reg_param * self._Q[j, :])\n",
        "        return dp, dq\n",
        "\n",
        "\n",
        "    def gradient_descent(self, i, j, rating):\n",
        "        \"\"\"\n",
        "        graident descent function\n",
        "\n",
        "        :param i: user index of matrix\n",
        "        :param j: item index of matrix\n",
        "        :param rating: rating of (i,j)\n",
        "        \"\"\"\n",
        "\n",
        "        # get error\n",
        "        prediction = self.get_prediction(i, j)\n",
        "        error = rating - prediction\n",
        "\n",
        "        # update biases\n",
        "        self._b_P[i] += self._learning_rate * (error - self._reg_param * self._b_P[i])\n",
        "        self._b_Q[j] += self._learning_rate * (error - self._reg_param * self._b_Q[j])\n",
        "\n",
        "        # update latent feature\n",
        "        dp, dq = self.gradient(error, i, j)\n",
        "        self._P[i, :] += self._learning_rate * dp\n",
        "        self._Q[j, :] += self._learning_rate * dq\n",
        "\n",
        "\n",
        "    def get_prediction(self, i, j):\n",
        "        \"\"\"\n",
        "        get predicted rating: user_i, item_j\n",
        "        :return: prediction of r_ij\n",
        "        \"\"\"\n",
        "        return self._b + self._b_P[i] + self._b_Q[j] + self._P[i, :].dot(self._Q[j, :].T)\n",
        "\n",
        "\n",
        "    def get_complete_matrix(self):\n",
        "        \"\"\"\n",
        "        computer complete matrix PXQ + P.bias + Q.bias + global bias\n",
        "\n",
        "        - PXQ 행렬에 b_P[:, np.newaxis]를 더하는 것은 각 열마다 bias를 더해주는 것\n",
        "        - b_Q[np.newaxis:, ]를 더하는 것은 각 행마다 bias를 더해주는 것\n",
        "        - b를 더하는 것은 각 element마다 bias를 더해주는 것\n",
        "\n",
        "        - newaxis: 차원을 추가해줌. 1차원인 Latent들로 2차원의 R에 행/열 단위 연산을 해주기위해 차원을 추가하는 것.\n",
        "\n",
        "        :return: complete matrix R^\n",
        "        \"\"\"\n",
        "        return self._b + self._b_P[:, np.newaxis] + self._b_Q[np.newaxis:, ] + self._P.dot(self._Q.T)\n",
        "\n",
        "\n",
        "    def print_results(self):\n",
        "        \"\"\"\n",
        "        print fit results\n",
        "        \"\"\"\n",
        "\n",
        "        print(\"User Latent P:\")\n",
        "        print(self._P)\n",
        "        print(\"Item Latent Q:\")\n",
        "        print(self._Q.T)\n",
        "        print(\"P x Q:\")\n",
        "        print(self._P.dot(self._Q.T))\n",
        "        print(\"bias:\")\n",
        "        print(self._b)\n",
        "        print(\"User Latent bias:\")\n",
        "        print(self._b_P)\n",
        "        print(\"Item Latent bias:\")\n",
        "        print(self._b_Q)\n",
        "        print(\"Final R matrix:\")\n",
        "        global matrix_2 \n",
        "        matrix_2 = self.get_complete_matrix()\n",
        "        print(matrix_2)\n",
        "        print(\"Final RMSE:\")\n",
        "        print(self._training_process[self._epochs-1][1])\n",
        "        \n",
        "\n",
        "        #df = pd.DataFrame(matrix_2)\n",
        "        #df.to_csv('sample.csv', index=False)\n",
        "\n",
        "    #def to_dataframe(self):\n",
        "        #matrix를 csv파일로 내보내기위해 dataframe으로 변환\n",
        "        #array df\n",
        "        #df=pd.DataFrame(self.get_complete_matrix(), columns = df_user_movie_ratings.columns)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uRILbCmiyCuV"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8hlT9FCexHRF",
        "outputId": "059fb71b-2f30-4e90-f1f7-3b54110021e9"
      },
      "source": [
        "# run example\n",
        "if __name__ == \"__main__\":\n",
        "    # rating matrix - User X Item : (7 X 5)\n",
        "    \n",
        "\n",
        "    R1 = weight_array_50[0]\n",
        "\n",
        "    start_6 = time.time()\n",
        "\n",
        "    # P, Q is (7 X k), (k X 5) matrix\n",
        "    factorizer1_50 = MatrixFactorization(R1, k=50, learning_rate=0.01, reg_param=0.01, epochs=100, verbose=True)\n",
        "    factorizer1_50.fit()\n",
        "    factorizer1_50.print_results()\n",
        "\n",
        "    sec_6 = time.time() - start_6\n",
        "    times_6 = str(datetime.timedelta(seconds=sec_6)).split(\".\")\n",
        "    times_6 = times_6[0]\n",
        "    print(times_6)\n",
        "\n",
        "\n",
        "  \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration: 10 ; cost = 0.0014\n",
            "Iteration: 20 ; cost = 0.0013\n",
            "Iteration: 30 ; cost = 0.0013\n",
            "Iteration: 40 ; cost = 0.0013\n",
            "Iteration: 50 ; cost = 0.0013\n",
            "Iteration: 60 ; cost = 0.0013\n",
            "Iteration: 70 ; cost = 0.0013\n",
            "Iteration: 80 ; cost = 0.0013\n",
            "Iteration: 90 ; cost = 0.0013\n",
            "Iteration: 100 ; cost = 0.0013\n",
            "User Latent P:\n",
            "[[-0.17021886  0.18634057 -0.48128278 ...  0.35215488 -0.23531371\n",
            "   0.30113367]\n",
            " [ 0.44495634  0.39461224  0.29916141 ...  0.4087484  -0.36496483\n",
            "   0.70032861]\n",
            " [ 0.20817768 -0.1638659   0.02969753 ...  0.64344001 -0.84903232\n",
            "   0.18220043]\n",
            " ...\n",
            " [-0.61144425  0.55253623  0.06757476 ...  0.39710631  0.79040476\n",
            "   0.10947617]\n",
            " [-0.22086989 -0.46896247 -0.45277568 ...  0.21542169  0.05699159\n",
            "   1.52417167]\n",
            " [-1.09240458  0.62944177 -0.21195631 ... -0.31069664 -0.49287751\n",
            "   0.03148328]]\n",
            "Item Latent Q:\n",
            "[[ 0.00447114 -0.00807136 -0.02736001 ... -0.01203089 -0.01872339\n",
            "  -0.04295212]\n",
            " [ 0.00662307  0.01001004  0.01398147 ...  0.04673808 -0.00675216\n",
            "   0.0255097 ]\n",
            " [ 0.00531394  0.07340561 -0.01482498 ... -0.01594186  0.00071422\n",
            "   0.01394468]\n",
            " ...\n",
            " [-0.00172444 -0.0107934  -0.00563729 ... -0.03194194 -0.02062368\n",
            "  -0.00279496]\n",
            " [-0.01763793  0.0214213   0.02575056 ... -0.02121042  0.01167161\n",
            "   0.00680839]\n",
            " [-0.00249549 -0.02634642  0.03179186 ...  0.00765767 -0.00976828\n",
            "  -0.01249202]]\n",
            "P x Q:\n",
            "[[ 0.07884945 -0.03744797  0.02332505 ...  0.00730116 -0.00113162\n",
            "  -0.08356697]\n",
            " [ 0.00818034  0.03244997  0.03697305 ... -0.02779353 -0.02474194\n",
            "  -0.0762713 ]\n",
            " [-0.03878934  0.00014385 -0.01346449 ... -0.02537899 -0.03895228\n",
            "   0.03986669]\n",
            " ...\n",
            " [ 0.05543331  0.06236227  0.00909648 ...  0.05776353 -0.00616686\n",
            "   0.08966621]\n",
            " [-0.0407403  -0.02645744  0.0385952  ... -0.02479547  0.08589164\n",
            "  -0.08328628]\n",
            " [ 0.03907619  0.05436476  0.04164303 ...  0.01527392 -0.03144161\n",
            "   0.0612698 ]]\n",
            "bias:\n",
            "-0.03049954\n",
            "User Latent bias:\n",
            "[-5.44334776e-02 -7.95244260e-02 -5.95374687e-02 -8.43615927e-02\n",
            " -4.20545023e-02 -5.85593431e-02 -9.51714338e-02 -6.59010940e-02\n",
            " -8.19636670e-02 -7.49208107e-02 -8.74279016e-02 -8.76350494e-02\n",
            " -4.63864577e-02 -1.60853366e-02 -3.83073720e-02 -5.18178561e-02\n",
            " -9.76775146e-02 -6.81296708e-02 -9.07434439e-02 -6.88212794e-02\n",
            " -5.65835228e-02 -4.39259984e-02 -7.88755326e-02 -7.25325310e-02\n",
            " -7.33391634e-02 -5.70234158e-02 -5.60450815e-02 -3.73423079e-02\n",
            " -5.71560987e-02 -7.28589992e-02 -4.32939543e-02 -6.30704940e-02\n",
            " -4.75149540e-02 -2.65637203e-02  1.09089539e-03  6.32221614e-02\n",
            "  6.06685371e-02  1.25488432e-01  1.93465966e-01  1.56209122e-01\n",
            "  1.92379305e-01  1.80441686e-01  1.39429475e-01  1.28157600e-01\n",
            "  1.55582513e-01  1.34055205e-01  2.21404497e-01  1.47001209e-01\n",
            "  8.64204648e-02  8.66302418e-02 -8.30243107e-03 -2.52472781e-02\n",
            " -6.61162035e-02 -5.36778381e-02 -5.83124325e-02 -5.59979633e-02\n",
            " -7.07322690e-02 -5.59104358e-02 -4.35637936e-02  3.14804296e-02\n",
            "  5.85644381e-02 -2.95411354e-03  8.15693174e-02  2.07864231e-01\n",
            "  1.90318521e-01  3.38159141e-01  3.05202744e-01  2.76112048e-01\n",
            "  3.65475254e-01  2.97293251e-01  2.51098438e-01  1.97439905e-01\n",
            "  2.67505935e-01  2.41718455e-01  1.86916927e-01  2.22736176e-01\n",
            "  1.70845775e-01  2.35988260e-01  1.32176042e-01  1.07999097e-01\n",
            "  1.13175348e-01  1.43473569e-02 -6.49962278e-02 -9.96784825e-02\n",
            " -5.95303650e-02 -7.42029922e-02 -1.54334750e-02  7.19883892e-02\n",
            "  6.92684126e-02  2.00318975e-01  2.38946500e-01  1.62286682e-01\n",
            "  2.19455116e-01  1.88233349e-01  1.32993455e-01  9.86004661e-02\n",
            "  2.23942510e-01  2.12094263e-01  1.52236890e-01  1.51177628e-01\n",
            "  1.54278440e-01  9.02517885e-02  1.90657349e-01  1.91830132e-01\n",
            "  1.40528677e-01  9.65268828e-02  2.04023472e-01  1.78018963e-01\n",
            "  1.67056571e-01  1.29724055e-01  1.77456271e-02 -5.52896593e-02\n",
            " -5.86448919e-02 -4.84387049e-02  3.73412632e-02  7.28333918e-02\n",
            "  1.35948116e-01  1.38728714e-01  1.83927907e-01  1.11717422e-01\n",
            "  1.26236685e-01  1.47661943e-01  1.16389646e-01  1.56730026e-01\n",
            "  6.47098661e-02  9.99076197e-02  1.26763771e-01  7.89147808e-02\n",
            "  9.77290840e-02  6.36178456e-02  3.71149036e-02  8.40138111e-02\n",
            "  7.85034937e-02  7.77986486e-02  1.57045315e-01  9.66628500e-02\n",
            "  1.13599108e-01  1.61745853e-01  1.35839658e-01  3.36236916e-02\n",
            " -7.19551606e-02 -8.10995244e-02  8.04411681e-02  2.29795118e-01\n",
            "  1.85172827e-01  1.38011595e-01  1.10556946e-01  6.22819170e-02\n",
            "  6.40236155e-02  7.55848757e-02  8.98610138e-02  9.09381677e-02\n",
            "  4.40976498e-02  5.54730570e-02  2.57685624e-02  6.36718600e-02\n",
            "  3.78223921e-02  9.58565340e-02  8.63402609e-02  6.79762358e-02\n",
            "  6.20735224e-02  8.36974384e-02  1.08356990e-01  1.11100945e-01\n",
            "  1.11825748e-01  8.11314937e-02  1.24395336e-01  2.69609147e-02\n",
            " -7.22666858e-02 -5.72947136e-02  1.31952265e-01  1.30600229e-01\n",
            "  1.70484943e-01  1.28964548e-01  8.77896103e-02  5.16206429e-02\n",
            "  6.38771571e-02  7.71791994e-02  1.08812668e-01  5.21479869e-02\n",
            "  4.64593895e-02  9.33368559e-02  6.33887631e-02  1.08110620e-02\n",
            "  1.14490434e-01  5.55609949e-02  3.75141124e-02  8.61948002e-02\n",
            "  4.87337424e-04  6.94032203e-02  5.89108201e-02  5.67896707e-02\n",
            "  1.40132606e-01  1.33185307e-01  1.91360694e-01  7.60218519e-02\n",
            " -5.47361269e-02  1.09657233e-01  1.40019477e-01  1.94139452e-01\n",
            "  1.52921200e-01  7.00175046e-02  1.04223525e-01  8.91754297e-02\n",
            "  1.00084612e-01  7.06546109e-02  3.90196517e-02 -1.84188652e-04\n",
            " -1.94082294e-02  9.02139840e-02  1.33149912e-01  9.17064416e-03\n",
            "  1.03631149e-01  7.39414929e-02  8.26721697e-02  8.08036464e-02\n",
            "  1.83735699e-02  2.26907546e-02  7.23322055e-02  7.53602161e-02\n",
            "  1.18822657e-01  1.49765223e-01  1.79661252e-01  6.88058164e-02\n",
            " -4.62721093e-02  9.03244701e-02  1.59429672e-01  1.92332611e-01\n",
            "  1.46187480e-01  4.12860342e-02  4.62172000e-02  8.52529900e-02\n",
            "  7.77641334e-02  9.32426004e-02  6.85930423e-02  1.21019518e-01\n",
            "  7.87228086e-02  7.60877242e-02  1.19575668e-01  7.93339153e-02\n",
            "  4.53477786e-02  4.70160006e-02  7.57639947e-02  5.88224434e-02\n",
            "  6.67311204e-02  4.00456376e-02  3.09434048e-02  6.28116125e-02\n",
            "  1.35685001e-01  1.48145708e-01  1.87963628e-01  9.29256887e-02\n",
            " -7.88631187e-02  1.37090428e-01  1.40854256e-01  1.83587075e-01\n",
            "  1.24419463e-01  1.33763147e-01  9.89894630e-02  4.40840319e-02\n",
            "  3.66078328e-02  4.92539669e-02  2.40116486e-02  7.81112056e-02\n",
            "  8.64085241e-02  7.45396603e-02  1.74796934e-01  4.11709037e-02\n",
            "  6.52219884e-02  1.15230396e-01  8.51679325e-02  4.54669892e-02\n",
            "  5.24592650e-02  4.91473569e-02  8.73868828e-02  7.44378688e-02\n",
            "  1.48930023e-01  1.92325414e-01  1.44552051e-01  1.15296172e-01\n",
            " -7.14486723e-02  1.28498724e-01  1.45417285e-01  1.00594476e-01\n",
            "  1.12477927e-01  1.27251060e-01  8.27256847e-02  4.31474526e-02\n",
            "  4.96450189e-02  1.65280299e-02  8.51183960e-02  1.27584053e-01\n",
            "  5.33505770e-03  1.68809455e-01  1.04220351e-01  1.01965604e-01\n",
            "  1.12217515e-01  9.48744169e-02  2.97951591e-02  1.01453408e-01\n",
            "  3.85474002e-02  6.34910834e-02  9.16212503e-02  9.20574223e-02\n",
            "  1.67074389e-01  1.76824008e-01  1.98041519e-01  5.37487017e-02\n",
            " -7.61476578e-02  1.02222638e-01  2.30200196e-01  1.47784722e-01\n",
            "  1.07778702e-01  9.20072186e-02  2.46035231e-02  6.29048918e-02\n",
            "  8.22721654e-02  7.47480605e-02  7.61148017e-02  1.40142786e-01\n",
            "  6.29318167e-02  8.60971184e-02  1.24236963e-01  1.38964939e-01\n",
            "  1.19928091e-01  6.96175189e-02  6.68841761e-02  3.09652821e-02\n",
            "  7.87818421e-02  1.31811906e-01  5.44060788e-02  2.03540222e-02\n",
            "  9.35663808e-02  1.69958840e-01  1.91631030e-01  8.04572970e-02\n",
            " -8.02916145e-02  1.22751498e-01  1.52148322e-01  1.77579769e-01\n",
            "  8.65535671e-02  7.26456295e-02  1.42648654e-02  6.93703121e-02\n",
            "  2.03222871e-02  4.57525280e-02  6.55853927e-02  9.56635148e-02\n",
            "  1.20038344e-01  1.33854846e-01  2.08343373e-01  9.83195199e-02\n",
            "  1.34664744e-01  6.48529109e-02  7.10606865e-02  3.53810206e-02\n",
            "  2.90660192e-02  7.62286699e-02  9.46555225e-02  7.80190764e-02\n",
            "  1.01489834e-01  2.39430910e-01  1.21123700e-01  6.45205306e-02\n",
            " -2.09381410e-02  7.46223569e-02  1.37712027e-01  1.30881915e-01\n",
            "  1.10594285e-01  9.52251851e-02  7.78576613e-02  8.17266793e-02\n",
            "  5.74117950e-02  8.53290699e-02  9.36413059e-02  8.03303919e-02\n",
            "  1.01431535e-01  1.00166656e-01  1.07551654e-01  6.27324957e-02\n",
            "  7.36622037e-02  3.73170174e-02  4.32006261e-02  3.80137518e-02\n",
            "  3.06481568e-02  4.83079561e-02  1.51307325e-02  7.20893546e-02\n",
            "  1.08077536e-01  1.00543284e-01  2.24219119e-01  5.79300382e-02\n",
            " -2.76831999e-02  2.33721099e-02  9.24979625e-02  1.52605281e-01\n",
            "  1.70416947e-01  1.41001818e-01  1.61437987e-01  9.57048905e-02\n",
            "  4.66665104e-02  9.45216766e-02  1.16954261e-01  1.09683095e-01\n",
            "  1.47692426e-01  7.03499938e-02  8.77827587e-02  5.46062984e-02\n",
            "  1.19925776e-01  8.46483616e-02  3.78815949e-02  1.27675792e-01\n",
            "  1.42095607e-02  4.90645651e-02  7.37396670e-02  1.01720855e-01\n",
            "  1.34371488e-01  1.13094553e-01  1.49768103e-01  1.00773546e-01\n",
            "  1.86032279e-03  2.48357011e-03  1.26061602e-01  1.80822485e-01\n",
            "  1.53420522e-01  7.41841210e-02  1.62699829e-01  8.61055500e-02\n",
            "  4.11437217e-02  6.25119595e-02  1.00557815e-01  8.43853496e-02\n",
            "  6.31509206e-02  1.40227839e-01  6.59073946e-02  1.06143812e-01\n",
            "  1.07403715e-01  1.05798185e-01  8.13721154e-02  2.32527909e-02\n",
            "  6.44738358e-02  6.85052502e-02  7.10502175e-02  7.01540499e-02\n",
            "  1.40971383e-01  9.49894515e-02  2.26420616e-01  7.87941304e-02\n",
            "  6.12227963e-03  5.32739886e-02  1.90439312e-01  1.48340616e-01\n",
            "  1.15206470e-01  9.18782681e-02  9.40539624e-02  7.19641188e-02\n",
            "  6.47712851e-02  7.97137965e-02  5.43433183e-02  1.49032049e-01\n",
            "  1.05856796e-01  9.07188602e-02  7.64011204e-02  1.05330845e-01\n",
            "  7.54709076e-02  7.75988540e-02  2.30299198e-02  4.40770759e-02\n",
            "  4.63194534e-02  9.43187666e-02  1.12627159e-01  1.03198328e-01\n",
            "  1.92834414e-01  2.30472034e-01  1.80859667e-01  9.89712329e-02\n",
            " -5.34941870e-02  7.49430175e-02  1.99965785e-01  1.43322773e-01\n",
            "  9.38958347e-02  1.05207149e-01  1.08984446e-01  1.08673487e-01\n",
            "  6.90622596e-02  3.49020418e-02  1.01255659e-01  5.13515675e-02\n",
            "  5.95146764e-02  7.25296717e-02  1.10783556e-01  9.85707035e-02\n",
            "  3.55330279e-02  7.77060998e-02  1.11000960e-01  8.54503233e-03\n",
            "  5.27259496e-02  7.20203877e-02  7.28543031e-02  5.82263396e-02\n",
            "  8.45742464e-02  1.58210176e-01  1.18552250e-01  1.90032375e-01\n",
            "  4.32588023e-02  1.87537240e-02  2.53296662e-01  1.57170213e-01\n",
            "  6.90494793e-02  1.21178641e-01  9.08629997e-02  1.28857959e-01\n",
            "  9.14304891e-02  8.86533003e-02  8.00502906e-03  8.99473978e-02\n",
            "  1.47329745e-01  7.22672607e-02  6.51184924e-02  4.30459087e-02\n",
            "  8.86226982e-02  4.23412282e-02  6.14028436e-02  3.35282258e-02\n",
            "  4.82670783e-02  6.47298989e-02  6.09735268e-02  9.88316672e-02\n",
            "  1.24815751e-01  2.00045977e-01  1.94316438e-01  1.30742436e-01\n",
            " -5.61796471e-02  8.33646120e-02  1.51171388e-01  1.65765695e-01\n",
            "  9.96362813e-02  4.97665058e-02  7.95883362e-02  5.53398812e-02\n",
            "  7.19308923e-02  8.93864042e-02  7.91571233e-02  1.17446252e-01\n",
            "  1.45775949e-01  1.05099918e-01  6.69655009e-02  1.10356713e-01\n",
            "  5.34370987e-02  7.41378831e-02  7.74198196e-02  6.32065915e-02\n",
            "  6.45914569e-02  5.04956185e-02  6.38706981e-02  1.32570876e-01\n",
            "  1.25619544e-01  2.19774834e-01  1.78109064e-01  5.26410298e-02\n",
            " -8.52721846e-02  8.45623231e-02  1.42460077e-01  1.56429494e-01\n",
            "  9.96881738e-02  5.79020028e-02  7.61539511e-02  7.51416304e-02\n",
            "  3.73360833e-02  5.50640545e-02  9.30767994e-02  1.26563915e-01\n",
            "  6.85447556e-02  4.78748346e-02  6.88647461e-02  7.72454295e-02\n",
            "  9.39391087e-02  7.97509585e-02  6.56172291e-02  8.89426663e-02\n",
            "  1.60322285e-02  6.74542741e-02  1.13360059e-01  1.18844683e-01\n",
            "  1.58167431e-01  1.82320446e-01  1.68455298e-01 -6.37383232e-02\n",
            "  4.46909215e-03  2.78088097e-02  1.61895803e-01  1.18940189e-01\n",
            "  1.36039136e-01  8.49455139e-02  1.09788173e-01  8.45103110e-02\n",
            " -5.03381640e-03  3.77536133e-02  5.91740860e-02  1.01337769e-01\n",
            "  4.39321608e-02  7.44595430e-02  4.44054085e-02  4.62528186e-02\n",
            "  4.35398843e-02  3.41924150e-02  4.78198985e-02  7.46267390e-02\n",
            "  6.27361537e-02  5.39058052e-02  7.97257271e-02  1.37726160e-01\n",
            "  2.05741133e-01  1.93701552e-01  1.57338821e-01 -4.56371059e-02\n",
            " -2.61584116e-02 -3.87508985e-02  1.63817181e-01  1.40848318e-01\n",
            "  1.32015595e-01  1.13284290e-01  1.64718372e-02  4.59823729e-02\n",
            "  3.79190111e-02  5.86527688e-02  1.09227846e-01  1.26974895e-01\n",
            " -2.09345517e-03  4.02954515e-02  7.52093299e-02  4.87032871e-02\n",
            "  2.50574079e-02  1.11070002e-02  6.14014834e-02  9.67473092e-02\n",
            "  6.64602126e-02  9.96934365e-02  1.20247547e-01  2.13449890e-01\n",
            "  1.86155857e-01  1.97446006e-01  1.63662071e-01 -7.36109884e-03\n",
            " -8.27313287e-02 -7.47593111e-02  2.10884120e-01  1.72295513e-01\n",
            "  1.35771525e-01  1.10818130e-01  9.58429938e-02  4.79473821e-02\n",
            "  7.07493134e-02  4.44342146e-02  1.25254498e-01  1.14440052e-01\n",
            "  6.20040748e-02  8.60291874e-02  5.89770714e-02  4.05811859e-02\n",
            "  6.55911599e-02  9.37873593e-02  4.79594511e-02  5.45274261e-02\n",
            "  7.42750164e-02  8.13469618e-02  1.74727242e-01  1.89251953e-01\n",
            "  1.39566070e-01  1.82645012e-01  1.69861499e-01 -7.95954134e-02\n",
            " -1.02584999e-01 -7.40709966e-02  6.47665011e-02  1.59443865e-01\n",
            "  1.69132614e-01  1.30708335e-01  1.17050441e-01  6.80079254e-02\n",
            "  1.02683221e-01  1.13168982e-01  1.24533865e-01  8.25114691e-02\n",
            "  6.98980631e-02  7.66421462e-02  1.09998766e-01  1.31537837e-01\n",
            "  7.26122159e-02  9.77762402e-02  1.29152721e-01  1.35341634e-01\n",
            "  7.92439390e-02  1.21250727e-01  7.44467852e-02  1.67852705e-01\n",
            "  1.79396543e-01  1.59444229e-01  4.51160699e-03 -4.18163894e-02\n",
            " -5.75516365e-02 -7.19415614e-02 -1.02694628e-02  9.42700304e-02\n",
            "  1.76842676e-01  1.45900387e-01  1.17421935e-01  1.60398848e-01\n",
            "  1.50962382e-01  1.57423522e-01  1.73863387e-01  1.20420232e-01\n",
            "  2.45654576e-01  1.75629763e-01  7.97677284e-02  4.87076667e-02\n",
            "  1.72230884e-01  2.53491147e-01  1.13509725e-01  1.22462765e-01\n",
            "  1.97407676e-01  1.43424439e-01  1.87280051e-01  1.83369273e-01\n",
            "  1.58596194e-01  5.68159029e-02 -2.87157866e-03 -7.67908816e-02\n",
            " -5.42920687e-02 -7.63629117e-02 -6.32168626e-02 -9.42695279e-04\n",
            "  1.57094591e-01  1.61784168e-01  2.36585684e-01  2.39929871e-01\n",
            "  2.08246209e-01  2.31393773e-01  1.92881997e-01  2.23101277e-01\n",
            "  1.87073995e-01  2.27707432e-01  3.24458980e-01  3.10940034e-01\n",
            "  3.21252888e-01  2.18293543e-01  2.31503744e-01  2.23747356e-01\n",
            "  2.33042527e-01  3.05763974e-01  2.26834183e-01  1.56042664e-01\n",
            "  8.51082601e-04 -2.77960919e-02 -7.58317699e-02 -7.55995729e-02\n",
            " -5.17369950e-02 -7.64110238e-02 -5.99609254e-02 -7.20801113e-02\n",
            " -2.17047919e-02  2.17701389e-02  3.94206321e-02  9.58216856e-02\n",
            "  9.97900398e-02  1.84159607e-01  3.13210114e-01  2.06275476e-01\n",
            "  2.77469673e-01  4.47683423e-01  3.52307462e-01  2.21204618e-01\n",
            "  2.38187678e-01  3.46677818e-01  2.29850796e-01  1.66350534e-01\n",
            "  9.40038863e-02  5.04319510e-02  5.38138653e-02  7.94656643e-03\n",
            " -6.87109002e-02 -9.39725175e-02 -5.68253555e-02 -8.93536994e-02]\n",
            "Item Latent bias:\n",
            "[ 0.1645036   0.18563819  0.09625164  0.14791698  0.12382659  0.16917422\n",
            "  0.14636289  0.1532239   0.20762258  0.12538671  0.14292058  0.14431577\n",
            "  0.11135017  0.09389942  0.13931497  0.23127423  0.10931322  0.13647522\n",
            "  0.162227    0.12277582  0.15500841  0.10846252  0.13828754  0.11800909\n",
            "  0.1354293   0.13638389  0.14764714  0.17887311  0.10134614  0.22420068\n",
            "  0.16242892  0.10838973  0.10238499  0.12578119  0.2157581   0.12345424\n",
            "  0.15482836  0.20201879  0.13653566  0.15387091  0.14643685  0.14079316\n",
            "  0.12384073  0.17720822  0.13521282  0.1482614   0.0984106   0.1234405\n",
            "  0.12435909  0.12718331  0.08205149  0.13919155  0.14038934  0.11365234\n",
            "  0.14317879  0.15127876  0.21542224  0.11453752  0.13689198  0.10226807\n",
            "  0.13334674  0.15202016  0.18116893  0.12091427  0.17972061  0.13854416\n",
            "  0.13251836  0.1260744   0.15448708  0.16374445  0.14855922  0.10823786\n",
            "  0.10359087  0.18705479  0.13695378  0.1451054   0.11576257  0.18871051\n",
            " -0.01837638  0.13770022  0.12675297  0.1590711   0.10613143  0.10846096\n",
            "  0.10253491  0.10934971  0.11062893  0.11873261  0.24796853  0.17720313\n",
            "  0.12162908  0.16286473  0.20688982  0.12049966  0.15653599  0.09604997\n",
            "  0.17703023  0.11631898  0.12262504  0.1281687   0.21213766  0.19973743\n",
            "  0.1445455   0.08624968  0.11065209  0.21332136  0.181904    0.12382783\n",
            "  0.10929517  0.13678979  0.14247442  0.13033191  0.12613923  0.14947022\n",
            "  0.15227465  0.2376451   0.14610425  0.11770795  0.13876352  0.24165961\n",
            "  0.14237563  0.13336442  0.13491899  0.12095881  0.14539737  0.14746518\n",
            "  0.11215411  0.13214242]\n",
            "Final R matrix:\n",
            "[[ 0.15842003  0.06325721  0.03464368 ...  0.06983333  0.02608947\n",
            "  -0.03635757]\n",
            " [ 0.06265997  0.1080642   0.02320073 ...  0.00964769 -0.0226118\n",
            "  -0.05415285]\n",
            " [ 0.03567725  0.09574503 -0.00724985 ...  0.03204919 -0.01683519\n",
            "   0.0819721 ]\n",
            " ...\n",
            " [ 0.09546486  0.1235284  -0.01912394 ...  0.08075666 -0.01848481\n",
            "   0.09733658]\n",
            " [ 0.03643841  0.07185585  0.04752195 ...  0.03534481  0.11072085\n",
            "  -0.03846876]\n",
            " [ 0.08372655  0.12014971  0.01804144 ...  0.04288587 -0.03914075\n",
            "   0.07355898]]\n",
            "Final RMSE:\n",
            "0.0013289397932410192\n",
            "0:03:02\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kVOE0_cI5uee"
      },
      "source": [
        "matrix_50_R1 = matrix_2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GJErgI0j51wW",
        "outputId": "d820ac8c-d50c-478c-d0fd-593f44b42eca"
      },
      "source": [
        "matrix_50_R1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.15842003,  0.06325721,  0.03464368, ...,  0.06983333,\n",
              "         0.02608947, -0.03635757],\n",
              "       [ 0.06265997,  0.1080642 ,  0.02320073, ...,  0.00964769,\n",
              "        -0.0226118 , -0.05415285],\n",
              "       [ 0.03567725,  0.09574503, -0.00724985, ...,  0.03204919,\n",
              "        -0.01683519,  0.0819721 ],\n",
              "       ...,\n",
              "       [ 0.09546486,  0.1235284 , -0.01912394, ...,  0.08075666,\n",
              "        -0.01848481,  0.09733658],\n",
              "       [ 0.03643841,  0.07185585,  0.04752195, ...,  0.03534481,\n",
              "         0.11072085, -0.03846876],\n",
              "       [ 0.08372655,  0.12014971,  0.01804144, ...,  0.04288587,\n",
              "        -0.03914075,  0.07355898]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YDf9qnVnm2Pa",
        "outputId": "c2e0cfcd-ac13-4e1e-8df4-66e70ebde630"
      },
      "source": [
        "np.shape(weight_array_50[4])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(128, 10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6u-ZHFBv6GPL",
        "outputId": "11711198-47b4-4036-8ad6-7896a27de261"
      },
      "source": [
        "# run example\n",
        "if __name__ == \"__main__\":\n",
        "    # rating matrix - User X Item : (7 X 5)\n",
        "\n",
        "    R4 = weight_array_50[4]\n",
        "\n",
        "    start_7 = time.time()\n",
        "\n",
        "    # P, Q is (7 X k), (k X 5) matrix\n",
        "    factorizer1_50 = MatrixFactorization(R4, k=3, learning_rate=0.01, reg_param=0.01, epochs=100, verbose=True)\n",
        "    factorizer1_50.fit()\n",
        "    factorizer1_50.print_results()\n",
        "\n",
        "    sec_7 = time.time() - start_7\n",
        "    times_7 = str(datetime.timedelta(seconds=sec_7)).split(\".\")\n",
        "    times_7 = times_7[0]\n",
        "    print(times_7)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration: 10 ; cost = 0.0099\n",
            "Iteration: 20 ; cost = 0.0099\n",
            "Iteration: 30 ; cost = 0.0099\n",
            "Iteration: 40 ; cost = 0.0099\n",
            "Iteration: 50 ; cost = 0.0099\n",
            "Iteration: 60 ; cost = 0.0099\n",
            "Iteration: 70 ; cost = 0.0099\n",
            "Iteration: 80 ; cost = 0.0098\n",
            "Iteration: 90 ; cost = 0.0098\n",
            "Iteration: 100 ; cost = 0.0098\n",
            "User Latent P:\n",
            "[[-8.03504805e-03 -5.94382888e-01  5.54822732e-01]\n",
            " [-7.78721088e-01 -1.15827338e-01 -4.82025073e-01]\n",
            " [ 4.70478789e-01  6.52638871e-01  8.46245599e-02]\n",
            " [ 7.70630356e-01 -1.29037124e-01  6.29539212e-01]\n",
            " [-3.02947220e-01 -1.70907156e-01 -6.32495577e-02]\n",
            " [ 1.38697417e+00  7.10187815e-01  5.77464096e-01]\n",
            " [ 4.88828402e-01  2.03701924e-01  1.75166888e+00]\n",
            " [-1.27357955e+00  7.79938657e-01 -4.55115793e-01]\n",
            " [ 1.57688586e+00  9.44126908e-01  9.36380990e-01]\n",
            " [ 3.97139315e-01  2.03199242e-01  2.96134814e-01]\n",
            " [-5.26245628e-01  2.14477551e-01 -1.78358373e-01]\n",
            " [ 9.65357587e-02  3.33386328e-01 -6.78180432e-01]\n",
            " [-1.30821457e-01  1.69449317e-01  2.53087108e-01]\n",
            " [-8.89175980e-01 -1.67671809e-01 -5.08850215e-01]\n",
            " [ 8.02214356e-01 -5.34651850e-01 -4.12533368e-01]\n",
            " [-2.87671414e-01 -1.73976015e-02  1.33476430e-01]\n",
            " [-9.08340558e-01 -5.88739401e-01 -1.85717658e-05]\n",
            " [ 6.60372142e-01  9.51318274e-01 -3.95952379e-01]\n",
            " [ 5.76844748e-01  1.29094208e-01  2.65666917e-01]\n",
            " [-9.38866103e-01  1.96358177e+00 -1.51705088e+00]\n",
            " [ 2.41535486e+00  6.76113684e-01 -7.82265406e-01]\n",
            " [-1.17567189e+00 -1.20440301e+00 -4.90363462e-01]\n",
            " [ 1.64977943e+00  9.17595822e-01  4.43111854e-01]\n",
            " [-7.06969958e-01 -1.22702727e+00  1.16438560e+00]\n",
            " [-2.59619726e-01 -5.02049768e-01 -1.47819012e+00]\n",
            " [-6.02053200e-01  5.22757795e-01  8.02776939e-02]\n",
            " [-7.16646472e-01 -5.82982578e-01 -2.23905081e-01]\n",
            " [ 6.17404705e-01  1.86377544e-02  1.86467485e-01]\n",
            " [ 1.09743322e+00  6.82016693e-01  7.39334979e-01]\n",
            " [ 1.08682390e+00 -5.71169805e-01 -2.16011254e-01]\n",
            " [-8.71453597e-01  9.29845591e-01 -9.60023808e-02]\n",
            " [ 1.45301912e+00 -7.24400021e-01  5.92413315e-01]\n",
            " [-1.82379684e+00  1.32478493e+00  6.54297507e-02]\n",
            " [-1.87690890e-01  2.14527294e-01  3.28019766e-01]\n",
            " [-1.48974156e+00  2.88969463e-01 -5.11326796e-01]\n",
            " [ 1.09545565e+00  9.27448796e-01  3.07361654e-01]\n",
            " [-5.67838666e-02 -1.51130857e-01 -8.06318491e-01]\n",
            " [ 7.78820821e-01 -1.60610947e+00 -1.59000649e-01]\n",
            " [ 1.43790803e+00 -1.66301321e+00 -8.66231130e-01]\n",
            " [-1.69709327e-01  4.02527947e-01  1.34345406e-01]\n",
            " [-3.39101093e-01 -9.02000195e-01 -1.57433630e-01]\n",
            " [-4.90800283e-01  1.32581187e+00  1.04106397e+00]\n",
            " [ 9.13859740e-01 -4.28723732e-01 -5.04261198e-01]\n",
            " [-1.79124603e-01  7.98485921e-02 -1.93523695e+00]\n",
            " [-8.19789408e-01 -8.29375344e-01 -6.85906402e-01]\n",
            " [ 1.44987046e+00  3.17884661e-02 -1.97046253e+00]\n",
            " [-5.79034965e-01  4.69764072e-03 -1.01639576e+00]\n",
            " [ 7.61171213e-01  1.41419407e-01  1.79118267e+00]\n",
            " [ 2.15729375e-01  4.91406486e-01  4.13027753e-01]\n",
            " [-3.16456863e-01 -4.71690235e-01 -1.02828992e+00]\n",
            " [-9.29426655e-01  7.11987670e-01 -1.55051390e+00]\n",
            " [-3.62451179e-01  1.27204024e-01 -2.48079673e+00]\n",
            " [ 1.23047399e+00 -7.68548225e-01 -1.57396690e+00]\n",
            " [-8.08673206e-01 -3.98121788e-01 -3.08028685e-01]\n",
            " [ 2.51763261e-01  1.18119283e+00 -1.41605244e+00]\n",
            " [ 1.92503754e-01  1.12757505e+00 -8.81434416e-01]\n",
            " [-2.30123841e-01  9.62545818e-01  5.16932626e-01]\n",
            " [ 1.09914664e-01  2.22023468e-01 -1.79363599e+00]\n",
            " [ 8.29719402e-01 -4.03032943e-01 -1.35243801e+00]\n",
            " [ 6.98702456e-01 -1.15717531e+00 -1.05680262e-01]\n",
            " [-3.26706842e-01 -1.40784028e-01 -8.01653568e-01]\n",
            " [-7.78440076e-01 -3.57232721e-01  2.84144691e-01]\n",
            " [ 7.21857293e-01 -6.07680249e-01  1.32489918e+00]\n",
            " [ 5.46822531e-01 -5.25998388e-01  3.14851964e+00]\n",
            " [-1.95329638e+00  2.39489655e-01 -1.19421386e-01]\n",
            " [-3.96977338e-01  8.89817909e-01  1.43702155e-01]\n",
            " [-1.43491002e+00 -7.67316160e-01  9.14224585e-01]\n",
            " [ 7.28169272e-01  1.20342164e+00  2.00213192e+00]\n",
            " [-7.12716172e-01 -5.29203854e-01 -2.04740025e-01]\n",
            " [-3.03442427e-02 -8.32000608e-01  2.14088839e-01]\n",
            " [ 1.26039826e+00  7.77100524e-01 -1.06233042e-01]\n",
            " [-2.15358898e-01 -5.38785030e-01  1.30102353e+00]\n",
            " [-7.78400918e-01 -2.22456422e-02 -1.54064526e+00]\n",
            " [-7.06992654e-01  1.13238885e+00 -1.01028571e+00]\n",
            " [-1.33956572e+00 -1.58482427e+00 -1.14712965e-01]\n",
            " [ 5.27688333e-01  3.24627698e-02  8.47978879e-01]\n",
            " [ 6.04764116e-01  3.35770953e-01 -9.68234764e-01]\n",
            " [-4.83035330e-01 -4.34541685e-01 -2.48935808e-02]\n",
            " [ 2.07899278e+00 -5.90722957e-02 -1.08290022e+00]\n",
            " [ 8.66766696e-01  6.64022815e-01 -7.44683785e-01]\n",
            " [-9.24206342e-01 -6.00769928e-01  4.08671954e-01]\n",
            " [-6.74712686e-02  3.12955709e-01  7.61620850e-01]\n",
            " [ 8.53713334e-01 -5.98616311e-01  6.22947505e-01]\n",
            " [-4.08790984e-01 -7.43810742e-01 -6.44048109e-02]\n",
            " [-6.02106063e-01 -1.97775108e-02  4.49275407e-01]\n",
            " [ 1.49422481e+00 -5.68070517e-01 -8.02480832e-03]\n",
            " [ 3.92890819e-01 -3.16796212e-01 -1.40576313e+00]\n",
            " [-3.81415783e-01 -3.63425614e-01  5.33355433e-01]\n",
            " [ 1.37949089e+00  5.49903309e-01 -3.75155717e-01]\n",
            " [-1.27388174e+00 -1.76468686e+00 -4.07843253e-01]\n",
            " [ 8.17412922e-01  5.87544749e-01  1.18405933e-02]\n",
            " [-1.24725839e+00 -6.95653170e-02 -5.19716647e-02]\n",
            " [-7.83153916e-01 -9.29895743e-01 -3.47007815e-01]\n",
            " [ 1.74924423e+00 -1.39641690e-01 -1.30547881e+00]\n",
            " [-5.56636392e-01  3.97747955e-01 -1.97468489e+00]\n",
            " [-4.08443993e-01  3.02273128e-01 -4.03809352e-01]\n",
            " [-2.02578122e-01  5.95059359e-01  4.11871587e-01]\n",
            " [ 7.18924729e-01  9.03264141e-01 -1.62011332e+00]\n",
            " [-8.55202212e-01 -1.71293696e+00 -1.60396607e+00]\n",
            " [-1.14356090e+00  1.83274753e+00 -5.62118883e-01]\n",
            " [-3.96283833e-01  1.10310091e+00 -1.52338966e+00]\n",
            " [-5.74934499e-01 -2.46741602e-02 -1.20903076e-01]\n",
            " [ 6.18484648e-01  9.74621111e-01 -9.80253491e-01]\n",
            " [ 5.21622009e-01  1.50500192e-01  9.68072783e-01]\n",
            " [ 3.54487019e-01 -1.10502169e-01  1.06855442e+00]\n",
            " [ 1.25880943e+00 -1.10921309e+00 -1.74063271e+00]\n",
            " [-8.09521272e-01  1.53932976e-01  1.43538201e+00]\n",
            " [-3.57468451e-01 -4.44455950e-01 -1.44362336e+00]\n",
            " [-5.34940307e-01  1.32254973e-01 -3.98698997e-01]\n",
            " [-1.69901954e-01  2.53176959e-01 -7.45173371e-01]\n",
            " [ 5.89607358e-01 -1.06460906e+00  9.21713127e-01]\n",
            " [-2.88499483e-01 -1.12654541e+00  3.53263296e-01]\n",
            " [ 1.40999377e+00  1.41818590e-01  1.18584704e+00]\n",
            " [ 1.29254911e-02 -7.25273095e-02 -4.78663042e-01]\n",
            " [ 5.92634012e-01 -4.18806793e-01  1.96223281e+00]\n",
            " [ 1.83411195e-01  2.51984190e-01 -2.08365824e+00]\n",
            " [ 4.27060384e-02  1.52259542e+00 -5.42734827e-01]\n",
            " [ 2.40775810e+00 -4.76882724e-01  1.27799070e+00]\n",
            " [ 1.64575231e+00 -6.37165051e-01  1.64809106e+00]\n",
            " [ 1.97228705e-01  3.52250397e-01 -2.37960265e+00]\n",
            " [ 5.70776581e-02 -3.98628773e-01 -1.08286551e+00]\n",
            " [-8.82208508e-01  5.24676837e-01  1.65062540e+00]\n",
            " [-1.01633263e-01 -4.12029837e-01 -4.96128500e-01]\n",
            " [-5.54618376e-01  8.51510592e-01 -7.15198903e-01]\n",
            " [ 4.20860219e-02  3.44320203e-01 -4.76057882e-01]\n",
            " [ 5.10629086e-01  1.17782815e+00 -5.32560016e-01]\n",
            " [-9.49450349e-01  1.58804855e+00 -1.55351373e+00]\n",
            " [ 1.20849065e+00  7.39496853e-02  3.47488478e-01]]\n",
            "Item Latent Q:\n",
            "[[ 0.00445749 -0.00463455  0.00353921 -0.00500057 -0.00827262 -0.00477732\n",
            "  -0.01393745  0.00496558  0.00061834 -0.01360354]\n",
            " [ 0.07239115  0.07730025  0.07174888  0.08118206  0.0786856   0.07755867\n",
            "   0.07381966  0.07312048  0.08056699  0.0957005 ]\n",
            " [-0.01996235 -0.0048106  -0.01706964 -0.01424396 -0.00652529 -0.01712615\n",
            "  -0.008078   -0.01094058 -0.01242969 -0.01985155]]\n",
            "P x Q:\n",
            "[[-0.05413944 -0.04857774 -0.05214537 ... -0.04957154 -0.05478888\n",
            "  -0.06778753]\n",
            " [-0.00223366 -0.00302563 -0.00283855 ... -0.00706252 -0.00382195\n",
            "   0.00907757]\n",
            " [ 0.04765313  0.0478616   0.04704672 ...  0.04913163  0.0518202\n",
            "   0.05437776]\n",
            " ...\n",
            " [ 0.09817161  0.0912418   0.09540568 ...  0.09448545  0.10182936\n",
            "   0.11634452]\n",
            " [ 0.14174029  0.13463016  0.13709832 ...  0.12840064  0.1466669\n",
            "   0.19573258]\n",
            " [ 0.00380345 -0.00155611  0.00365141 ...  0.00760637  0.00238598\n",
            "  -0.01626091]]\n",
            "bias:\n",
            "-0.15232627\n",
            "User Latent bias:\n",
            "[ 0.13418725  0.02676905 -0.01409596  0.07591307  0.00960527  0.\n",
            "  0.04122696 -0.06952611 -0.00159518  0.01640422 -0.01148723 -0.01696486\n",
            "  0.03250439 -0.01135356  0.03415526  0.02919905  0.11866374 -0.03300384\n",
            "  0.04463971 -0.17505909 -0.04817282  0.06545209 -0.06717136  0.17968143\n",
            "  0.08058972 -0.01047013  0.04892356  0.08039743  0.00299658  0.05030046\n",
            " -0.03313951  0.06527726 -0.08378808  0.04915619  0.02762689 -0.02780047\n",
            "  0.03647104  0.17036039  0.12072276  0.00696594  0.0651967  -0.13382216\n",
            "  0.01608683 -0.01591136  0.09949458 -0.03814016  0.06256135  0.02128373\n",
            "  0.00514012  0.0446377  -0.04221171 -0.06441737  0.06673104  0.10053176\n",
            " -0.04799172 -0.04324304 -0.06858011 -0.04977246  0.07725632  0.15042932\n",
            "  0.02829108  0.01846546  0.07532697  0.11550898 -0.014584    0.02563996\n",
            "  0.10961878 -0.04118749  0.0468773   0.05799885 -0.06220789  0.00905354\n",
            " -0.003523   -0.07185392  0.192533    0.03259114 -0.01928932  0.02865554\n",
            "  0.01541109 -0.03749659  0.08750265  0.0143101   0.15249471  0.13766408\n",
            "  0.0085463   0.06254687  0.02521293  0.07849588 -0.0114      0.17979433\n",
            " -0.05660237  0.00570707  0.10743342 -0.01560111 -0.04825719 -0.00210237\n",
            " -0.04223844 -0.01480672  0.17926443 -0.0816054  -0.02764283  0.02354437\n",
            " -0.07407916  0.01556119  0.0191643   0.1161031   0.09124449  0.04535335\n",
            "  0.05556076  0.          0.11289562  0.05813991  0.03293187  0.02885345\n",
            "  0.06123808 -0.01042741 -0.13075093  0.07892813  0.11604087 -0.00786011\n",
            "  0.04567482  0.00958136  0.05873544 -0.05326673 -0.01937476 -0.05137153\n",
            " -0.11595407  0.01582601]\n",
            "Item Latent bias:\n",
            "[0.19447581 0.21471642 0.20206416 0.19532901 0.18963867 0.20073814\n",
            " 0.19737177 0.19968865 0.18766349 0.18767026]\n",
            "Final R matrix:\n",
            "[[0.12219735 0.14799967 0.13177977 ... 0.13197809 0.1147356  0.10174371]\n",
            " [0.06668494 0.08613357 0.0736684  ... 0.06706892 0.05828433 0.07119061]\n",
            " [0.07570671 0.09615579 0.08268865 ... 0.08239805 0.07306147 0.07562579]\n",
            " ...\n",
            " [0.08894962 0.10226043 0.09377204 ... 0.0904763  0.08579506 0.10031698]\n",
            " [0.06793576 0.08106623 0.07088214 ... 0.05980895 0.06605005 0.1151225 ]\n",
            " [0.061779   0.07666005 0.06921531 ... 0.07079477 0.05354922 0.03490908]]\n",
            "Final RMSE:\n",
            "0.009842195089998963\n",
            "0:00:02\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ldzO90v6ZZV"
      },
      "source": [
        "matrix_50_R4 = matrix_2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "79u5BoWB6epc",
        "outputId": "f263c059-5ea7-43db-a45c-5f4699205067"
      },
      "source": [
        "matrix_50_R4"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.12219735, 0.14799967, 0.13177977, ..., 0.13197809, 0.1147356 ,\n",
              "        0.10174371],\n",
              "       [0.06668494, 0.08613357, 0.0736684 , ..., 0.06706892, 0.05828433,\n",
              "        0.07119061],\n",
              "       [0.07570671, 0.09615579, 0.08268865, ..., 0.08239805, 0.07306147,\n",
              "        0.07562579],\n",
              "       ...,\n",
              "       [0.08894962, 0.10226043, 0.09377204, ..., 0.0904763 , 0.08579506,\n",
              "        0.10031698],\n",
              "       [0.06793576, 0.08106623, 0.07088214, ..., 0.05980895, 0.06605005,\n",
              "        0.1151225 ],\n",
              "       [0.061779  , 0.07666005, 0.06921531, ..., 0.07079477, 0.05354922,\n",
              "        0.03490908]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_xuAutrX6ovC",
        "outputId": "a81a675f-b235-4997-b72b-e3e9fa25482d"
      },
      "source": [
        "weight_array_75 = model_dropout_75.get_weights()\n",
        "weight_array_75\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([[ 0.06255747, -0.02879985, -0.04570679, ...,  0.03082038,\n",
              "         -0.02286159,  0.04148098],\n",
              "        [ 0.0183855 , -0.03675165, -0.07218114, ...,  0.06255545,\n",
              "         -0.03942308, -0.04934542],\n",
              "        [-0.03470093,  0.0526543 ,  0.0329525 , ...,  0.019316  ,\n",
              "          0.04780298, -0.02344802],\n",
              "        ...,\n",
              "        [ 0.05285259, -0.06412537,  0.04240653, ...,  0.02117279,\n",
              "         -0.01577259, -0.06070466],\n",
              "        [ 0.05824352, -0.05672782, -0.070421  , ..., -0.03098848,\n",
              "         -0.02885967, -0.01920142],\n",
              "        [-0.07384575, -0.00434108,  0.07591277, ..., -0.00624391,\n",
              "          0.02009567, -0.07352012]], dtype=float32),\n",
              " array([ 0.18151325, -0.21440852, -0.5874271 , -1.0016598 , -0.10402112,\n",
              "        -0.43788296, -0.27318743, -0.1256076 ,  0.4760148 , -0.27789432,\n",
              "        -0.37296164,  0.36871687, -0.07575101, -0.73302585,  0.3205171 ,\n",
              "        -1.4970845 , -0.4630242 , -0.6202114 , -0.58658004, -1.3135527 ,\n",
              "         0.12419901, -0.31658146, -0.43741068, -0.26202315,  0.16651204,\n",
              "        -0.4765914 , -0.42133653, -0.6979836 , -0.4728605 , -0.5310334 ,\n",
              "        -0.3704084 ,  0.0163056 , -0.21803033, -0.13363308,  0.33826303,\n",
              "        -0.05214025, -0.36198232, -0.7207721 ,  0.1125317 , -0.5188484 ,\n",
              "         0.19128624,  0.02115939, -0.1694717 , -0.09857853, -0.3276083 ,\n",
              "         0.01459576, -0.71049833, -0.21863577, -0.48352945, -0.0958475 ,\n",
              "        -0.47276416, -0.03970684, -0.16369934, -0.14674883, -0.19240281,\n",
              "        -0.61922467, -0.57197946, -0.11062393, -0.3126792 , -0.24088626,\n",
              "        -0.7410101 , -0.20119756,  0.09594008, -0.26839292, -1.1731032 ,\n",
              "        -0.03224391,  0.01318834, -0.61733973, -0.8527223 , -0.37540153,\n",
              "        -0.32263452, -1.6939012 , -1.009343  , -0.13759562, -0.44300282,\n",
              "        -0.2674923 , -0.1422397 , -0.04554421, -0.04038421, -0.8570968 ,\n",
              "        -0.11087293,  0.07152198, -0.50367737,  0.13224265, -0.52534944,\n",
              "         0.07845794, -0.09979372, -1.2578522 , -0.36382297, -0.02606704,\n",
              "         0.11100028, -0.21790965,  0.22812212,  0.12006629, -0.48860115,\n",
              "        -0.16464935, -0.05568568, -0.42512885, -0.26160747,  0.03702662,\n",
              "        -0.09039948, -0.02991028, -0.28567895, -0.09915984, -0.37609512,\n",
              "        -0.09565779, -0.13644627,  0.04850561, -0.48816502, -0.53124565,\n",
              "        -0.6036201 ,  0.01740386, -0.10102823, -0.1379247 , -0.23018685,\n",
              "        -0.6208088 , -0.01923799,  0.24723707, -0.05119847, -0.98307985,\n",
              "         0.02635717, -0.05381076, -1.6984849 ,  0.05610888, -0.26199925,\n",
              "        -0.62391347, -0.2671719 , -0.03083567], dtype=float32),\n",
              " array([[-0.34951377, -0.34792224,  0.3281352 , ..., -0.55296636,\n",
              "          0.5887261 ,  0.4469281 ],\n",
              "        [ 0.23705427,  0.03230559, -0.04178045, ...,  0.09541211,\n",
              "         -0.58644044, -0.06480166],\n",
              "        [ 0.08430894,  0.099593  ,  0.42062706, ..., -0.05874408,\n",
              "         -0.00599038,  0.0593328 ],\n",
              "        ...,\n",
              "        [-0.4094884 , -0.4326936 , -0.12760703, ..., -0.4922596 ,\n",
              "          0.23256545,  0.2729653 ],\n",
              "        [ 0.03749668,  0.02315537,  0.31565207, ..., -0.392605  ,\n",
              "          0.06062418, -0.0726897 ],\n",
              "        [ 0.01366682, -0.07514962, -0.00846419, ..., -0.07984641,\n",
              "         -0.1575756 ,  0.126992  ]], dtype=float32),\n",
              " array([ 0.04194934, -0.3826861 ,  0.2186677 , -0.01674162,  0.22662696,\n",
              "         0.35393906, -0.04049107,  0.08582845, -0.04094363, -0.01603854,\n",
              "         0.00323889,  0.17778869, -0.0488628 ,  0.16790688,  0.16545436,\n",
              "         0.2503011 ,  0.19005197,  0.16351557, -0.01529088,  0.14594369,\n",
              "         0.00885987,  0.00971533,  0.04298687,  0.05867414,  0.02959206,\n",
              "         0.07255669,  0.05579247,  0.09248407, -0.00571618, -0.28022897,\n",
              "        -0.22369593,  0.15279377, -0.14333785,  0.27143046, -0.00501873,\n",
              "        -0.24739172, -0.09708623,  0.24047163, -0.14259951,  0.01092946,\n",
              "         0.13941626, -0.16438831,  0.20657276, -0.03276199, -0.05198326,\n",
              "         0.05441577,  0.06521503, -0.09609324, -0.14549977,  0.13955526,\n",
              "         0.13144292, -0.03461733,  0.18047692,  0.04771783,  0.21517344,\n",
              "        -0.01980747,  0.17389145, -0.03290542, -0.00129619,  0.09846175,\n",
              "         0.18782663, -0.05445778,  0.02300296,  0.1227624 ,  0.10822713,\n",
              "         0.1341858 ,  0.02608304, -0.08931176,  0.01658875, -0.00451647,\n",
              "        -0.01098008, -0.01259544, -0.05625412,  0.00347096,  0.04604128,\n",
              "         0.21843828,  0.03954653,  0.21719256,  0.03206712,  0.09125395,\n",
              "        -0.04905603,  0.03471919,  0.00141547,  0.1654964 , -0.02237206,\n",
              "         0.22004806,  0.03712796,  0.16553426, -0.0049592 , -0.03178545,\n",
              "         0.181879  ,  0.00935524, -0.2894469 , -0.0300518 , -0.11559466,\n",
              "         0.0674165 ,  0.09828497,  0.06098307, -0.32236964, -0.14061281,\n",
              "         0.19122359, -0.01336658, -0.21783382,  0.01006901,  0.03852912,\n",
              "        -0.09113389,  0.02529877, -0.01995048, -0.17246276, -0.03700563,\n",
              "        -0.06411073,  0.10252818,  0.05116688,  0.1774397 ,  0.158418  ,\n",
              "         0.1741501 ,  0.07575276, -0.04609824,  0.15421052,  0.05598302,\n",
              "         0.1668239 ,  0.00320032,  0.06306702, -0.00672678,  0.00205683,\n",
              "         0.10322815,  0.03285079, -0.00404888], dtype=float32),\n",
              " array([[-0.60866827, -0.30195126, -0.05845684, ..., -0.0203104 ,\n",
              "         -0.02207385, -0.03571115],\n",
              "        [-0.18507773, -0.03005413, -0.02075544, ..., -0.00941902,\n",
              "         -0.19047774, -0.34472138],\n",
              "        [-0.28985092, -0.34295744, -0.23073521, ..., -0.24325845,\n",
              "         -0.07760283, -0.04358992],\n",
              "        ...,\n",
              "        [-0.55775386, -0.20087694, -0.13631369, ...,  0.02077814,\n",
              "          0.05743261,  0.00660202],\n",
              "        [ 0.0274598 , -0.10393437,  0.00378403, ..., -0.25136596,\n",
              "         -0.23176992, -0.06776872],\n",
              "        [ 0.04074122, -0.2080985 , -0.07250974, ..., -0.00895612,\n",
              "         -0.16786024,  0.03415509]], dtype=float32),\n",
              " array([ 0.801155  , -0.43859228, -1.4350356 , -0.57360536,  0.38178477,\n",
              "        -0.54488474, -0.04316581, -1.1316563 ,  1.6524506 ,  0.9116332 ],\n",
              "       dtype=float32)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tPVpd5jG3j1_",
        "outputId": "56c1e9e4-7f61-4b7b-c95e-2b78a641d385"
      },
      "source": [
        "# run example\n",
        "if __name__ == \"__main__\":\n",
        "    # rating matrix - User X Item : (7 X 5)\n",
        "\n",
        "    R1_75 = weight_array_75[0]\n",
        "\n",
        "    start_8 = time.time()\n",
        "\n",
        "    # P, Q is (7 X k), (k X 5) matrix\n",
        "    factorizer1_75 = MatrixFactorization(R1_75, k=50, learning_rate=0.01, reg_param=0.01, epochs=100, verbose=True)\n",
        "    factorizer1_75.fit()\n",
        "    factorizer1_75.print_results()\n",
        "\n",
        "    sec_8 = time.time() - start_8\n",
        "    times_8 = str(datetime.timedelta(seconds=sec_8)).split(\".\")\n",
        "    times_8 = times_8[0]\n",
        "    print(times_8)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration: 10 ; cost = 0.0012\n",
            "Iteration: 20 ; cost = 0.0012\n",
            "Iteration: 30 ; cost = 0.0012\n",
            "Iteration: 40 ; cost = 0.0012\n",
            "Iteration: 50 ; cost = 0.0012\n",
            "Iteration: 60 ; cost = 0.0012\n",
            "Iteration: 70 ; cost = 0.0012\n",
            "Iteration: 80 ; cost = 0.0012\n",
            "Iteration: 90 ; cost = 0.0012\n",
            "Iteration: 100 ; cost = 0.0012\n",
            "User Latent P:\n",
            "[[ 0.28805167  0.69138708 -0.02730003 ... -0.64256425 -0.30082919\n",
            "  -0.14339755]\n",
            " [-0.16679948  0.41310788 -0.0624576  ...  0.15580892 -0.09453056\n",
            "  -0.15513445]\n",
            " [ 0.2582319   0.00952107 -0.5214661  ...  0.35184356  0.01647005\n",
            "  -0.25375277]\n",
            " ...\n",
            " [-0.0574298   0.00131589 -0.01167302 ... -0.24463951 -0.50630429\n",
            "   0.430993  ]\n",
            " [-0.49257575  0.2785439  -0.9733431  ... -0.30092943 -0.26657441\n",
            "  -0.35988142]\n",
            " [-0.54943379 -0.05084578 -0.27135646 ...  0.30167212  1.0488311\n",
            "  -0.80979245]]\n",
            "Item Latent Q:\n",
            "[[-7.32296323e-04 -2.02449621e-02  1.18375837e-02 ...  1.97970697e-02\n",
            "   2.62816821e-02 -1.54790151e-02]\n",
            " [-1.78106061e-02 -2.43555278e-02  6.19993343e-03 ... -8.09893492e-05\n",
            "   5.80212419e-02 -2.62586595e-03]\n",
            " [-8.69116940e-03  9.41745325e-03 -1.45127652e-02 ...  3.81695456e-03\n",
            "   1.34523950e-02  2.51060885e-03]\n",
            " ...\n",
            " [-3.21725403e-02  6.75661663e-03 -2.21110258e-02 ...  5.61454328e-03\n",
            "  -1.27404161e-02  9.46710936e-03]\n",
            " [ 2.69484593e-03  2.11096663e-02 -3.39449149e-02 ...  1.08904594e-02\n",
            "  -9.94868197e-03  3.88311156e-03]\n",
            " [ 9.54251187e-03 -1.21767991e-02 -1.94530380e-02 ... -6.26001375e-02\n",
            "  -1.87728906e-03  1.32549303e-04]]\n",
            "P x Q:\n",
            "[[ 0.04954742 -0.06046804  0.09481566 ... -0.01372942  0.19405937\n",
            "  -0.00541958]\n",
            " [-0.00354057 -0.02691667 -0.03801642 ... -0.0319536  -0.03819937\n",
            "  -0.01337305]\n",
            " [-0.06036742 -0.0319877   0.01516605 ...  0.0313911   0.04308783\n",
            "  -0.00738205]\n",
            " ...\n",
            " [ 0.0080675  -0.00293246  0.07285562 ...  0.05659221  0.06307272\n",
            "   0.07963577]\n",
            " [ 0.00460423 -0.01065363  0.10041362 ...  0.06467804  0.02066935\n",
            "   0.02800477]\n",
            " [ 0.02626435  0.03008002 -0.05492176 ...  0.03342908 -0.15751162\n",
            "   0.04408494]]\n",
            "bias:\n",
            "-0.028601458\n",
            "User Latent bias:\n",
            "[-6.79064145e-02 -4.32700562e-02 -4.40751253e-02 -6.11558478e-02\n",
            " -4.98270030e-02 -4.42480255e-02 -6.35253283e-02 -5.34090583e-02\n",
            " -5.76600028e-02 -6.51644292e-02 -6.08814912e-02 -3.06701281e-02\n",
            " -1.77359417e-02 -4.39451627e-03 -3.15378614e-02 -3.83817092e-02\n",
            " -5.00861487e-02 -3.07375965e-02 -6.26951233e-02 -5.79615394e-02\n",
            " -4.60635362e-02 -5.47585976e-02 -6.01978732e-02 -5.01798862e-02\n",
            " -5.58983265e-02 -3.33374437e-02 -4.19650403e-02 -5.27590795e-02\n",
            " -4.58968932e-02 -4.47346568e-02 -4.94447054e-02 -5.56243104e-02\n",
            " -4.00486451e-02 -8.16226811e-03  6.33156807e-02  8.16026795e-02\n",
            "  7.03968287e-02  1.12169251e-01  1.36744902e-01  2.20055964e-01\n",
            "  2.76054533e-01  1.83773073e-01  1.10293248e-01  9.81312045e-02\n",
            "  1.24308651e-01  2.51458210e-01  2.22146278e-01  1.55049349e-01\n",
            "  1.71548911e-01  1.15509814e-01  4.46959066e-02 -3.41466568e-02\n",
            " -5.35693617e-02 -2.91563698e-02 -3.90699464e-02 -5.54843270e-02\n",
            " -5.62362928e-02 -3.24931755e-02 -4.10383715e-02 -2.11385774e-03\n",
            "  6.43680943e-02  5.89821072e-02  1.20894412e-01  1.68186764e-01\n",
            "  1.63624272e-01  2.19953368e-01  2.25590066e-01  3.15161381e-01\n",
            "  2.38153171e-01  2.35912641e-01  2.24307674e-01  2.50443095e-01\n",
            "  1.92300408e-01  1.87315941e-01  2.33245118e-01  3.02352175e-01\n",
            "  1.70555117e-01  2.72217739e-01  1.57246038e-01  6.12478383e-02\n",
            "  9.15397411e-02  8.88611912e-03 -6.63615157e-02 -6.00221874e-02\n",
            " -4.84545621e-02 -3.73537050e-02 -1.18490591e-02  5.43676360e-02\n",
            "  8.89159239e-02  1.72710812e-01  2.30046047e-01  1.03017534e-01\n",
            "  2.00770769e-01  1.12908640e-01  1.22835295e-01  1.48143112e-01\n",
            "  2.14153335e-01  1.47386160e-01  1.96721644e-01  4.01502425e-02\n",
            "  6.50368825e-02  1.17631309e-01  8.92538548e-02  1.35826242e-01\n",
            "  1.04397992e-01  1.21211885e-01  1.21034489e-01  2.48192867e-02\n",
            "  1.06513731e-01  7.71349306e-02  1.23469527e-02 -5.27328055e-02\n",
            " -6.99558448e-02 -3.56071047e-02  5.39383060e-02  9.87701291e-02\n",
            "  1.28559992e-01  1.33271756e-01  1.20737613e-01  1.24489613e-01\n",
            "  8.60189094e-02  1.06431988e-01  1.07871498e-01  1.41118648e-01\n",
            "  1.58896383e-01  8.94388709e-02  8.23863587e-02  7.62567236e-02\n",
            "  4.83717635e-02  4.98566640e-02  2.43934367e-02  8.31852939e-02\n",
            "  3.53735709e-02  8.11661220e-02  1.09850572e-01  8.46786213e-02\n",
            "  9.34393661e-02  1.09622895e-01  1.03807085e-01 -2.67202691e-02\n",
            " -6.56308710e-02 -3.53053514e-02  8.21545091e-02  1.81657444e-01\n",
            "  1.45916243e-01  9.04295094e-02  1.19499789e-01  4.99012330e-02\n",
            "  5.14480110e-02  3.34559116e-02  5.28707587e-02  1.52302618e-02\n",
            "  2.52097137e-02  3.52013581e-02  2.19865444e-03  6.64675622e-02\n",
            "  2.74852032e-02  5.31965388e-04  4.55927655e-02  4.73058513e-02\n",
            "  5.49317852e-02  3.88937268e-02  3.24930142e-02  7.08900822e-02\n",
            "  7.48519518e-02  6.78361144e-02  1.24583145e-01 -3.44651454e-02\n",
            " -5.53783146e-02 -1.75330196e-04  1.48097214e-01  1.70186274e-01\n",
            "  1.94185816e-01  7.14145969e-02  8.16619736e-02  3.61936523e-02\n",
            "  6.94195686e-02  4.14457298e-02  5.56875748e-02  4.00279092e-02\n",
            "  5.35343500e-02  6.78763121e-02  1.99984332e-02  4.67365233e-02\n",
            "  4.71843034e-02  1.12591139e-01  6.84982803e-02  1.16889349e-02\n",
            "  2.50531848e-02  5.02015802e-02  6.79349370e-02  7.61174769e-02\n",
            "  6.71230096e-02  1.19478444e-01  9.75510613e-02  1.52908961e-02\n",
            " -5.17234687e-02  1.35179388e-01  1.37175466e-01  2.13927146e-01\n",
            "  8.92665760e-02  9.39958706e-02  5.00072855e-02  3.36293067e-02\n",
            "  1.75940386e-02  3.78235469e-02  6.66838780e-02  3.77266935e-02\n",
            "  4.79193185e-02  6.32930262e-02  1.22333823e-01  2.52843570e-02\n",
            "  5.35203056e-02  5.09771880e-02  7.84949800e-02  2.19638014e-02\n",
            "  6.15550044e-03  3.56698582e-02  5.10973821e-02  6.76664137e-02\n",
            "  9.23867473e-02  1.83226817e-01  1.89823864e-01  3.18986180e-02\n",
            " -2.91830540e-02  1.23087009e-01  1.69325152e-01  1.52753014e-01\n",
            "  8.86362774e-02  8.50263985e-02  3.53937176e-02  7.25620853e-02\n",
            "  5.94705875e-02  5.12227287e-02  7.17321898e-02  1.87722120e-02\n",
            "  4.50918566e-02  1.74194902e-02  1.29394587e-01  9.55137172e-02\n",
            "  5.16136707e-02  5.26907188e-02  1.08757306e-01  4.74127575e-03\n",
            "  5.06872585e-02  1.76262351e-02  3.71950331e-02  3.29098350e-02\n",
            "  1.18227185e-01  1.49775116e-01  1.39207441e-01  9.78540286e-02\n",
            " -3.94500266e-02  1.18798350e-01  1.47293851e-01  1.58746180e-01\n",
            "  4.62279717e-02  9.69170535e-02  7.70137552e-02  2.42730014e-02\n",
            "  1.71186120e-02  4.99396072e-02  5.33333100e-02  3.10645143e-02\n",
            "  3.21466117e-02  6.19985877e-02  8.11900391e-02  3.71777021e-02\n",
            "  9.26831451e-03  8.72105505e-02  6.76744302e-02  3.79302430e-02\n",
            " -3.87717878e-03  3.32401107e-02  3.01603511e-02  4.84982683e-02\n",
            "  1.77372058e-01  1.86495941e-01  1.24279439e-01  4.50346641e-02\n",
            " -5.25158714e-02  8.57116536e-02  1.29545435e-01  1.09995318e-01\n",
            "  1.58600169e-01  9.91195498e-02  6.82033483e-02  3.32788117e-02\n",
            "  4.97274095e-02  3.09654010e-02  6.24594849e-02  6.60260116e-02\n",
            "  4.87805904e-02  7.42396435e-02  8.06436402e-02  1.57245884e-01\n",
            "  7.74336495e-02  9.10479169e-02  4.91922583e-02  4.64409926e-02\n",
            "  3.78267135e-03  1.47676458e-02  4.49966698e-02  7.32711794e-02\n",
            "  1.99070556e-01  1.33422958e-01  1.91267047e-01 -5.29720034e-03\n",
            " -3.05786451e-02  1.27373597e-01  1.17678554e-01  1.41647657e-01\n",
            "  1.34874657e-01  6.42953478e-02  8.53858248e-02  5.04205187e-02\n",
            " -1.93104204e-02  5.90497642e-02  6.46416819e-02  8.95324973e-02\n",
            "  7.85734353e-02  3.66281240e-02  1.27875823e-01  1.78673237e-01\n",
            "  1.13310261e-01  8.21729883e-02  3.68596621e-02  7.94239059e-02\n",
            "  3.47758777e-02  3.58348759e-02 -3.52099082e-03  4.36953432e-02\n",
            "  1.68570868e-01  2.09184533e-01  1.81994922e-01  6.50554707e-02\n",
            " -6.71279583e-02  1.35325780e-01  1.35988908e-01  1.48639055e-01\n",
            "  1.24360534e-01  4.24141370e-02  1.80705282e-02  2.70209640e-02\n",
            "  6.06861034e-02  4.34333387e-02  9.73165552e-02  8.73819873e-02\n",
            "  8.36171429e-02  5.87334681e-02  2.10007412e-01  1.36657933e-01\n",
            "  8.57637565e-02  4.99461090e-02  9.55052551e-02 -2.65007955e-02\n",
            "  6.69322597e-03  4.71939369e-02  1.25313942e-02  1.61499782e-02\n",
            "  1.03800787e-01  1.55392510e-01  4.50258088e-02  2.52334492e-02\n",
            " -4.91904941e-02  8.10073645e-02  1.65250596e-01  1.30151018e-01\n",
            "  7.12044742e-02  2.06654141e-02  7.45428463e-02  5.62034705e-02\n",
            "  3.77563508e-02  3.42314073e-02  1.29618858e-01  8.34897789e-02\n",
            "  8.85854010e-02  1.20106756e-01  1.43555810e-01  9.44493995e-02\n",
            "  8.54906961e-02  2.44803923e-02  2.36432361e-02  3.68307109e-02\n",
            "  4.38145920e-02  6.08432847e-02  3.85771194e-02  1.05103474e-01\n",
            "  1.78848584e-01  1.01052046e-01  1.45467717e-01  5.63986153e-02\n",
            " -2.59247703e-02  5.24128153e-02  3.71481880e-02  1.77614479e-01\n",
            "  1.44442389e-01  8.45495021e-02  8.66366609e-02  1.19130741e-01\n",
            "  4.55727904e-02  8.09426772e-02  7.77299990e-02  7.33465839e-02\n",
            "  6.00185133e-02  2.79450763e-02  1.55233436e-01  8.96607656e-02\n",
            "  8.97354374e-02  3.58533959e-02  7.11704140e-02  1.00253182e-01\n",
            "  1.21333309e-02 -1.33877559e-02  8.63453002e-02  1.26314410e-01\n",
            "  9.91329267e-02  1.01275174e-01  1.85133459e-01  8.42123042e-02\n",
            "  3.42577209e-02 -4.82119103e-02  1.40064724e-01  1.39322677e-01\n",
            "  5.74641999e-02  8.98211514e-02  1.54367801e-01  4.54232315e-02\n",
            "  4.79102220e-02  7.78145753e-02  1.02808541e-01  1.16908294e-01\n",
            "  9.03650987e-02  1.89850434e-01  1.28375314e-01  5.85045392e-02\n",
            "  1.48872831e-01  1.64948891e-01  4.11086949e-02  2.44015243e-02\n",
            "  4.22062398e-02  5.15250992e-02  6.43757324e-02  5.00233193e-02\n",
            "  9.08101660e-02  1.15868221e-01  2.30909476e-01  8.84318934e-02\n",
            "  1.43160070e-02  4.63770555e-02  1.80527066e-01  1.78442660e-01\n",
            "  6.47455342e-02  4.42969406e-02  3.43098531e-02  1.89557978e-02\n",
            "  6.18671690e-02  9.55370088e-02  8.31308342e-02  1.44043739e-01\n",
            "  6.58097709e-02  9.21218277e-02  1.16786369e-01  7.77863734e-02\n",
            "  8.06012242e-02  7.26332550e-02  3.37316537e-02  4.20772950e-02\n",
            "  3.06374637e-02  6.48501172e-02  7.05007511e-02  7.06325720e-02\n",
            "  9.24610574e-02  1.56655541e-01  2.68948141e-01  1.67340945e-01\n",
            " -1.77034311e-02  7.23447171e-02  1.54231082e-01  1.13916754e-01\n",
            "  9.37636228e-02  6.79689433e-02  6.77533306e-02  7.85067878e-02\n",
            "  6.44503248e-02  6.01645103e-02  1.01488688e-01 -1.32760384e-02\n",
            "  1.30550846e-01  1.29650240e-01  1.79693032e-01  5.80578338e-02\n",
            "  6.42957577e-02  2.03845480e-02  1.61939953e-01  1.32724934e-02\n",
            "  3.49653495e-02  8.55386644e-02  8.18727334e-02  4.01098375e-02\n",
            "  1.34605124e-02  1.32103160e-01  1.67972583e-01  1.86537007e-01\n",
            "  4.01298412e-02  5.21573983e-02  1.69039493e-01  1.77008109e-01\n",
            "  8.27901337e-02  8.74305017e-02  4.84014617e-02  9.13484070e-02\n",
            "  8.45441588e-02  3.61933158e-02  2.10875561e-02  2.43216480e-02\n",
            "  6.66750636e-02  9.34574653e-02  4.21269763e-02  7.76033302e-03\n",
            "  6.78046796e-02  3.25491926e-02  3.25085982e-02  1.59119190e-02\n",
            "  4.81022461e-02  8.96982250e-02  1.44462915e-02  4.85302360e-02\n",
            "  1.52678995e-01  2.26224125e-01  1.51843184e-01  1.41919729e-01\n",
            " -3.28013672e-02  3.59438550e-02  1.18748341e-01  1.55987235e-01\n",
            "  6.42164137e-02  8.31189309e-03 -1.98451231e-05  3.93551361e-02\n",
            "  5.85818656e-02  6.15462641e-02  1.39272528e-01  1.87265995e-01\n",
            "  1.37768354e-01  9.35262376e-02  1.09103380e-02  6.36713929e-02\n",
            "  7.70585609e-03  2.62087956e-02  3.44027081e-02 -7.68125913e-03\n",
            "  2.62920411e-02  2.76407485e-02  1.10481710e-02  5.46495604e-02\n",
            "  5.39232514e-02  1.89117574e-01  1.59615572e-01  7.88239914e-02\n",
            " -4.87028167e-02  4.91975973e-02  6.02485170e-02  1.00560207e-01\n",
            "  8.36426044e-02  3.46347495e-02  2.42442885e-02 -2.42861994e-02\n",
            "  3.40424651e-02  3.45888717e-02  1.55973282e-01  1.60115507e-01\n",
            "  8.56340376e-02  4.72127888e-02  8.04690706e-02  8.92866533e-02\n",
            "  3.94006625e-02  2.32931336e-02  4.29586239e-02  8.90860283e-03\n",
            " -2.16165587e-02  3.36500950e-02  2.99248285e-02  6.51209584e-02\n",
            "  8.62144574e-02  1.06878027e-01  1.81202534e-01 -2.25988838e-02\n",
            " -1.00923765e-02  6.86876878e-02  1.22900692e-01  7.63065700e-02\n",
            "  7.55974396e-02  5.83164598e-02  2.49106537e-03 -1.97063858e-02\n",
            "  1.82072418e-03  2.35466665e-02  3.24011288e-02  1.35033556e-01\n",
            "  1.32046498e-01  6.07610760e-02  4.63454645e-02  7.02936792e-02\n",
            "  9.72929175e-03  2.59579847e-02  1.06045213e-02  5.65544880e-02\n",
            "  4.78539661e-02  5.49724080e-02  4.97992020e-02  1.12673335e-01\n",
            "  1.22360286e-01  1.34500399e-01  8.45996389e-02 -9.47417708e-03\n",
            " -2.35848052e-02 -3.83642943e-03  1.13267779e-01  9.13721403e-02\n",
            "  9.87281246e-02  6.90291543e-02  5.57568638e-02  1.84167992e-02\n",
            "  4.10046065e-02  5.19237932e-02  9.61514699e-02  1.43328757e-02\n",
            "  6.89377946e-02  3.84869336e-02  2.96879969e-02  3.92303676e-02\n",
            "  1.46913206e-02  3.18066490e-02  9.52945025e-02  6.46083255e-02\n",
            "  5.42930339e-02  6.40528511e-02  6.96674922e-02  1.61772545e-01\n",
            "  1.42208262e-01  1.72387096e-01  1.46872765e-01 -7.48072526e-03\n",
            " -5.56457334e-02 -2.20408595e-02  1.72963994e-01  1.77139719e-01\n",
            "  1.03815470e-01  9.40120286e-02  3.09272891e-02  2.37370672e-02\n",
            "  4.80549680e-02  8.01329619e-02  1.32086465e-01  6.12006576e-02\n",
            "  5.46716288e-02  4.97681712e-02  2.63493443e-02  6.09013064e-02\n",
            "  8.05038981e-02  6.31362154e-02  5.34244534e-02  1.11089571e-01\n",
            "  1.42025360e-02  1.20196866e-01  1.55681492e-01  1.82161219e-01\n",
            "  1.84869902e-01  1.91802986e-01  1.51404190e-01 -2.78196413e-02\n",
            " -5.90323057e-02 -5.45674191e-02  1.81333988e-02  7.65898967e-02\n",
            "  1.68218483e-01  8.72026512e-02  1.17161004e-01  5.31406177e-02\n",
            "  9.47302565e-02  6.93001003e-02  8.87748494e-02  4.45987863e-02\n",
            "  5.74787431e-02  5.53422096e-02  9.05251396e-02  7.77242087e-02\n",
            "  9.14123484e-02  1.08621146e-01  1.00774239e-01  1.00463857e-01\n",
            "  9.20370557e-02  6.84737658e-02  1.44132799e-01  1.78711618e-01\n",
            "  1.63329453e-01  1.29155632e-01  1.67727772e-02 -5.00323039e-02\n",
            " -4.88745936e-02 -5.02217226e-02  6.81707893e-02  9.31518160e-02\n",
            "  1.29061883e-01  1.30964329e-01  1.23585129e-01  6.54945258e-02\n",
            "  1.03080995e-01  1.81070044e-01  9.90396323e-02  1.30594852e-01\n",
            "  2.00559611e-01  1.16724992e-01  3.40908210e-02  1.06068019e-01\n",
            "  1.81268612e-01  1.49364691e-01  7.37748736e-02  7.31630803e-02\n",
            "  5.34078706e-02  8.34852627e-02  1.45544169e-01  1.58528646e-01\n",
            "  8.62600394e-02  2.50993833e-02  1.85051353e-02 -5.68185023e-02\n",
            " -5.15472216e-02 -7.47088524e-02 -5.09364201e-02 -1.13746244e-02\n",
            "  1.38380957e-01  1.31919822e-01  1.85737889e-01  1.56624840e-01\n",
            "  1.20376653e-01  2.45453027e-01  1.99784179e-01  1.49446511e-01\n",
            "  1.61985628e-01  2.49632474e-01  2.94815740e-01  2.04524557e-01\n",
            "  2.80552685e-01  2.34394901e-01  2.26081492e-01  2.23488646e-01\n",
            "  1.90767065e-01  2.46579718e-01  1.16691207e-01  8.94683585e-02\n",
            "  4.39845742e-02 -3.61522330e-02 -7.22869132e-02 -3.13868484e-02\n",
            " -4.87937960e-02 -5.97401577e-02 -2.10169483e-02 -6.19998905e-02\n",
            " -2.73822311e-02  4.24257162e-02  5.22596756e-02  1.05663176e-01\n",
            "  1.25203981e-01  1.10922437e-01  1.68052400e-01  1.92171943e-01\n",
            "  2.47980254e-01  3.48549300e-01  3.31561292e-01  1.54001733e-01\n",
            "  2.01702120e-01  2.52079256e-01  2.17582293e-01  1.43987949e-01\n",
            "  5.77768006e-02  5.97159435e-02  5.33003142e-02  1.10473661e-02\n",
            " -6.80855110e-02 -6.85447386e-02 -5.38936800e-02 -4.44259098e-02]\n",
            "Item Latent bias:\n",
            "[ 0.11064097  0.09384062  0.14332982  0.12567707  0.13447587  0.10430004\n",
            "  0.13917289  0.14481896  0.11065403  0.14504349  0.11968275  0.12129909\n",
            "  0.13867982  0.09110525  0.11902165  0.11018357  0.12222422  0.1118527\n",
            "  0.10190918  0.12939815  0.13711401  0.11393234  0.15435259  0.13846388\n",
            "  0.14310949  0.13896274  0.10430144  0.09598621  0.11235089  0.11980902\n",
            "  0.14073215  0.11727527  0.13101566  0.1190669   0.11428908 -0.01263636\n",
            "  0.11390319  0.10093685  0.14078552  0.12181726  0.10078668  0.13223858\n",
            "  0.18222597  0.1117891   0.0818191   0.13626004  0.17017054  0.17722313\n",
            "  0.11750351  0.13387823  0.12162743 -0.00806606  0.12836437  0.19084898\n",
            "  0.11570272  0.16725915  0.11717293  0.13239417  0.08838866  0.19572177\n",
            "  0.10426831  0.12147112  0.14021213  0.09600968  0.1023125  -0.01504002\n",
            "  0.13871033  0.11282917  0.14139412  0.10607673  0.11801354  0.21236582\n",
            "  0.11416476  0.20174592  0.13266482  0.09099213  0.22380898 -0.02149925\n",
            "  0.19659015  0.08316885  0.14068882  0.08697441  0.12272227  0.12417442\n",
            "  0.13417403  0.11277057  0.20284323  0.10310562  0.1512865  -0.01136504\n",
            "  0.14349432  0.18828318  0.12454152  0.09160939  0.1111376   0.08761442\n",
            "  0.10888899  0.15035783  0.12281322  0.15033996  0.11544578 -0.01791542\n",
            "  0.10817361  0.10390973  0.12142574  0.1293638   0.17247756  0.16935805\n",
            "  0.103807    0.10160895  0.10624521  0.17517049  0.18879025  0.15666311\n",
            "  0.08639937  0.11858144  0.10902495  0.16144487 -0.03440628  0.12985224\n",
            "  0.12065738  0.14248249  0.11205836  0.09330309  0.17296554  0.11081961\n",
            "  0.12964038 -0.01411518]\n",
            "Final R matrix:\n",
            "[[ 0.06368052 -0.06313529  0.14163761 ...  0.00058232  0.22719188\n",
            "  -0.11604264]\n",
            " [ 0.03522889 -0.00494757  0.03344189 ...  0.00699449  0.0195695\n",
            "  -0.09935974]\n",
            " [-0.02240303 -0.01082367  0.08581929 ...  0.06953412  0.10005163\n",
            "  -0.09417382]\n",
            " ...\n",
            " [ 0.02156228 -0.00623804  0.11903924 ...  0.07026562  0.0955669\n",
            "  -0.03162561]\n",
            " [ 0.03275006  0.00069185  0.16124831 ...  0.0930025   0.06781459\n",
            "  -0.06860555]\n",
            " [ 0.06387796  0.05089327  0.0153807  ...  0.07122132 -0.1008986\n",
            "  -0.04305762]]\n",
            "Final RMSE:\n",
            "0.0011704384895213288\n",
            "0:02:59\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vnMMiPB46yI4"
      },
      "source": [
        "matrix_75_R1 = matrix_2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yb9TraFs-aQO",
        "outputId": "f36677f0-92dc-42dd-bf98-e61d86d87253"
      },
      "source": [
        "matrix_75_R1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.06368052, -0.06313529,  0.14163761, ...,  0.00058232,\n",
              "         0.22719188, -0.11604264],\n",
              "       [ 0.03522889, -0.00494757,  0.03344189, ...,  0.00699449,\n",
              "         0.0195695 , -0.09935974],\n",
              "       [-0.02240303, -0.01082367,  0.08581929, ...,  0.06953412,\n",
              "         0.10005163, -0.09417382],\n",
              "       ...,\n",
              "       [ 0.02156228, -0.00623804,  0.11903924, ...,  0.07026562,\n",
              "         0.0955669 , -0.03162561],\n",
              "       [ 0.03275006,  0.00069185,  0.16124831, ...,  0.0930025 ,\n",
              "         0.06781459, -0.06860555],\n",
              "       [ 0.06387796,  0.05089327,  0.0153807 , ...,  0.07122132,\n",
              "        -0.1008986 , -0.04305762]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nApWG9kV-aET"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JUK14JZu6vxI",
        "outputId": "8d433ca6-f229-414c-c44e-3df704679386"
      },
      "source": [
        "# run example\n",
        "if __name__ == \"__main__\":\n",
        "    # rating matrix - User X Item : (7 X 5)\n",
        "\n",
        "    R4_75 = weight_array_75[4]\n",
        "\n",
        "    start_9 = time.time()\n",
        "\n",
        "    # P, Q is (7 X k), (k X 5) matrix\n",
        "    factorizer1_75 = MatrixFactorization(R4_75, k=3, learning_rate=0.01, reg_param=0.01, epochs=100, verbose=True)\n",
        "    factorizer1_75.fit()\n",
        "    factorizer1_75.print_results()\n",
        "\n",
        "    sec_9 = time.time() - start_9\n",
        "    times_9 = str(datetime.timedelta(seconds=sec_9)).split(\".\")\n",
        "    times_9= times_9[0]\n",
        "    print(times_9)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration: 10 ; cost = 0.0079\n",
            "Iteration: 20 ; cost = 0.0064\n",
            "Iteration: 30 ; cost = 0.0061\n",
            "Iteration: 40 ; cost = 0.0059\n",
            "Iteration: 50 ; cost = 0.0059\n",
            "Iteration: 60 ; cost = 0.0058\n",
            "Iteration: 70 ; cost = 0.0058\n",
            "Iteration: 80 ; cost = 0.0058\n",
            "Iteration: 90 ; cost = 0.0058\n",
            "Iteration: 100 ; cost = 0.0058\n",
            "User Latent P:\n",
            "[[-0.11847239 -0.92860901 -0.07490496]\n",
            " [ 0.7938724   0.03458332  0.47541159]\n",
            " [ 0.51551262  0.03823475 -0.44661683]\n",
            " [ 0.27805625 -0.21440305 -0.70289236]\n",
            " [ 0.32676618  0.92499943 -0.06092022]\n",
            " [-0.17150868  1.32537859  0.14461121]\n",
            " [-1.1172191  -0.38815897 -0.53186262]\n",
            " [-1.42014735 -0.35516059 -0.5290341 ]\n",
            " [-0.15067278 -0.39031577  1.54110913]\n",
            " [ 0.38852257  1.14261074  0.16742403]\n",
            " [ 0.99941658  0.15209789 -0.16720433]\n",
            " [ 0.37063035  1.15174119  0.30479264]\n",
            " [-0.08081398 -0.34996543  1.70203333]\n",
            " [ 0.27635116 -1.54181211  0.27820305]\n",
            " [-0.19828461  0.24505008  1.21880983]\n",
            " [ 0.34547984 -0.78612456 -0.52306627]\n",
            " [-0.50015594  1.10517213  0.05991187]\n",
            " [ 1.67762645 -0.65857705 -0.38136406]\n",
            " [ 1.11656686 -0.01751784  2.34520629]\n",
            " [ 0.41669362  1.6304025  -0.11683455]\n",
            " [-0.14434731  0.41137134 -0.87216873]\n",
            " [-0.57650809 -0.61968695  0.72427371]\n",
            " [ 0.91044282 -0.69635033  1.62761093]\n",
            " [ 1.0961336   0.69900352 -0.03167242]\n",
            " [-0.83442044  0.37433425 -1.13530634]\n",
            " [ 1.01236329 -1.98898719 -0.98933096]\n",
            " [ 0.07980199 -0.24112596  0.18849689]\n",
            " [ 0.76696978  1.5887801  -0.03990864]\n",
            " [-1.39444796  0.54217856  0.78745282]\n",
            " [ 0.12181491 -0.08027957 -1.06217   ]\n",
            " [ 0.00796001 -0.14113198 -0.89637412]\n",
            " [ 1.11195369 -0.10271305  0.53107714]\n",
            " [ 0.70029594  0.12493616 -0.24565617]\n",
            " [-0.30653174 -0.08383826 -0.36110736]\n",
            " [ 0.02122083  1.66017547  0.02500762]\n",
            " [-0.58379273  0.12777034  0.09486628]\n",
            " [ 0.95764191  0.1184447  -0.65829388]\n",
            " [ 0.22096236  1.54708942 -0.04873183]\n",
            " [ 0.25885712 -0.8678795   0.56925955]\n",
            " [-0.2554379  -0.45375144  0.65148397]\n",
            " [ 1.93871916  0.00860617 -0.04534681]\n",
            " [-0.62621321 -0.18557102 -0.75084936]\n",
            " [ 0.60537747 -0.95729807 -0.40118607]\n",
            " [ 0.54733108 -0.82125794 -0.94775087]\n",
            " [ 0.27945447 -2.03053366  0.03639696]\n",
            " [-0.82809927 -0.48995443  1.62819398]\n",
            " [ 0.4498927  -0.40682875  1.57085746]\n",
            " [ 0.62715495  0.07421463  2.5158649 ]\n",
            " [-0.33090064  0.05015237  1.39449683]\n",
            " [ 0.39324746  0.48155705 -0.77143186]\n",
            " [ 1.16589759 -1.0777402   1.21976287]\n",
            " [-0.4670185  -0.18274284 -2.07046275]\n",
            " [-1.90921817  2.35021077 -0.26911364]\n",
            " [-1.40355691 -1.81299517  0.31384044]\n",
            " [-0.14860735 -0.48827334  0.62346693]\n",
            " [-0.42201918  0.04824471 -1.12062616]\n",
            " [-0.6270588  -1.60919508 -0.25087227]\n",
            " [ 1.15476256  1.37342141  0.53868373]\n",
            " [ 0.93088955  0.42744883 -0.59074302]\n",
            " [-0.42452591  0.17689292  1.20618488]\n",
            " [ 2.1439411   1.38862432  1.86002933]\n",
            " [ 1.03581164 -0.68103819 -0.84432753]\n",
            " [-0.78187029 -0.65411385  0.23443957]\n",
            " [-0.46603467 -1.09122016  0.51458973]\n",
            " [-0.44645734  0.92682018  2.33802765]\n",
            " [-0.79850204  0.14724037  0.14579976]\n",
            " [ 0.57865267 -1.52793828 -0.200583  ]\n",
            " [ 0.46083068  1.06407212  0.19367468]\n",
            " [-0.13658074 -0.75033842 -1.33784338]\n",
            " [-0.30932068 -0.03126436 -0.88621351]\n",
            " [-0.84135989 -0.36154188  0.1381725 ]\n",
            " [ 0.01018095 -0.26655248 -1.46802349]\n",
            " [ 0.5552337  -0.81709567 -0.97054327]\n",
            " [ 1.16872305 -0.07939671  0.94393118]\n",
            " [-1.40721964 -0.04410635 -1.01747256]\n",
            " [-1.08598622 -0.32904447 -1.10872926]\n",
            " [-2.1687126   0.28250667  0.43592234]\n",
            " [ 0.06066077 -0.41677227  0.13162899]\n",
            " [-1.79276516  0.29859164 -1.40916929]\n",
            " [-0.41261727  0.12962587  1.22838724]\n",
            " [-0.94519627  1.05171181  1.61814552]\n",
            " [-0.57500228  0.97839269 -0.31101902]\n",
            " [-0.25652944 -1.2752309  -0.1955605 ]\n",
            " [ 0.468907   -0.81566294 -0.43841374]\n",
            " [-0.65927137  1.33274968 -0.6690726 ]\n",
            " [ 0.68454185 -0.43564668 -0.88427023]\n",
            " [-1.31603531  0.75422802 -1.20598166]\n",
            " [ 0.10736667 -0.42596183  0.18572495]\n",
            " [ 0.38522275  0.10745312 -0.69474719]\n",
            " [-1.24350661  0.07484015 -0.4612743 ]\n",
            " [-0.88443711  0.66272407  0.15155759]\n",
            " [-0.84631719 -0.07752135 -0.58081388]\n",
            " [ 0.01780209 -1.03535864  0.21103939]\n",
            " [-0.29079997  0.59375436 -1.01754219]\n",
            " [ 0.48755673  0.0084852  -0.13560461]\n",
            " [-0.37164169  1.92302949 -0.21334445]\n",
            " [-1.01668934  1.06535667  0.98656802]\n",
            " [ 0.54232028  0.73021794 -0.01231269]\n",
            " [ 0.18252366 -0.30467808 -0.83262706]\n",
            " [ 0.49250092 -1.68116926  0.37899674]\n",
            " [ 1.97744881 -1.97436319  1.18516698]\n",
            " [-0.37582834  0.16924085 -0.08085927]\n",
            " [-2.05034865 -1.09933935  0.03286966]\n",
            " [ 0.7307365   0.9804329  -1.40916411]\n",
            " [-0.49671065  0.50559747 -0.40480406]\n",
            " [ 0.855368    1.09985857  2.04918292]\n",
            " [ 1.40672843  0.66317072 -0.81728483]\n",
            " [-1.31199906  1.06387019  0.12169646]\n",
            " [ 0.83199981 -2.41207817 -0.93269952]\n",
            " [ 0.18846479 -0.21939346 -0.09763649]\n",
            " [ 0.58971936 -0.12112067 -1.10835879]\n",
            " [-1.29396018 -1.58363334 -0.34971284]\n",
            " [ 0.94999057  1.12572092 -0.08688493]\n",
            " [ 1.48176675  0.54759275 -0.58157413]\n",
            " [ 0.77035583  0.9003057  -0.58681452]\n",
            " [-1.14161674  1.03187698 -0.08632125]\n",
            " [-0.76109868  0.19062137  0.92180264]\n",
            " [ 1.422556    0.33468844  1.43497549]\n",
            " [ 1.25198573 -1.14721482  0.69639779]\n",
            " [-0.39846728 -0.06742739 -1.02803912]\n",
            " [-2.67491451 -0.21769965  0.81415559]\n",
            " [-0.16061131  0.4340235  -1.32501697]\n",
            " [-0.05231983 -1.08466136 -1.11896081]\n",
            " [-0.93381924 -0.92451188 -1.45364551]\n",
            " [ 0.44620803  0.70059771 -0.17485061]\n",
            " [-1.29252766 -0.2167805  -1.20457197]\n",
            " [-0.47836116 -0.39910022 -0.26341703]\n",
            " [ 0.00649151 -0.00643041  0.35072836]]\n",
            "Item Latent Q:\n",
            "[[-0.01608744  0.00053522  0.00634676  0.0067082   0.00562267 -0.00121917\n",
            "  -0.00690599  0.00878819  0.00622792 -0.00138802]\n",
            " [-0.01261497  0.00644092 -0.00296852 -0.00531934 -0.00559386 -0.0067193\n",
            "   0.00107056 -0.00049594 -0.00103136 -0.00585736]\n",
            " [-0.06571777 -0.06717888 -0.06283018 -0.05668035 -0.05963371 -0.06171611\n",
            "  -0.06189121 -0.06091539 -0.06023835 -0.05601449]]\n",
            "P x Q:\n",
            "[[ 0.01854288 -0.00101248  0.00671097 ...  0.00398224  0.00473204\n",
            "   0.0097994 ]\n",
            " [-0.04445064 -0.03128997 -0.02493435 ... -0.02200033 -0.0237295\n",
            "  -0.02793441]\n",
            " [ 0.02057505  0.0305254   0.03121935 ...  0.0317173   0.0300746\n",
            "   0.02407752]\n",
            " ...\n",
            " [ 0.10268993  0.07883374  0.06812364 ...  0.0621255   0.06473525\n",
            "   0.0705373 ]\n",
            " [ 0.03004143  0.01486946  0.01469924 ...  0.01204015  0.01330023\n",
            "   0.01775682]\n",
            " [-0.0230724  -0.02359948 -0.02197604 ... -0.02130452 -0.02108024\n",
            "  -0.01961722]]\n",
            "bias:\n",
            "-0.10460117\n",
            "User Latent bias:\n",
            "[ 0.         -0.01349396  0.          0.0210622   0.01915782 -0.01041316\n",
            "  0.         -0.0255111   0.10146717  0.04678229  0.          0.\n",
            "  0.          0.02508698  0.10806187 -0.02113922  0.00632036 -0.03873992\n",
            "  0.         -0.02164146 -0.05030546  0.03632381  0.12084186 -0.01467626\n",
            " -0.04905386 -0.04458551  0.          0.          0.07610339 -0.03567706\n",
            "  0.00678266  0.         -0.00403701  0.          0.0260463   0.03521406\n",
            " -0.01348264  0.01717533  0.03173727  0.03164638  0.01878624  0.06726115\n",
            " -0.00588484 -0.07220605  0.01865201  0.          0.12673616  0.15720758\n",
            "  0.1042861   0.          0.09714116  0.         -0.06188532  0.0877347\n",
            "  0.         -0.04318141  0.          0.11984749  0.          0.09163212\n",
            "  0.10459492  0.00724542  0.06595638  0.          0.          0.01297453\n",
            "  0.00456579  0.03679042  0.00491047 -0.03520646  0.03779935 -0.04303588\n",
            " -0.06705244  0.08088568  0.         -0.06208374  0.10347767 -0.00518153\n",
            " -0.09613191  0.11491053  0.         -0.02669912 -0.00189864 -0.02763349\n",
            " -0.00553557 -0.03465434  0.02080897  0.         -0.03578893  0.00949694\n",
            "  0.00763114  0.          0.00080502 -0.0247831  -0.00444962  0.00099518\n",
            "  0.10921539  0.05329198 -0.0017492   0.00962456  0.          0.0632771\n",
            "  0.02558674  0.         -0.0186566   0.11813282  0.          0.\n",
            " -0.03159207  0.          0.          0.01515901  0.00385255 -0.03324946\n",
            " -0.03949079  0.01281515  0.09428619  0.07827633  0.          0.\n",
            "  0.03336658  0.          0.0471445  -0.07886432  0.03895659 -0.05390156\n",
            " -0.03108773  0.02782096]\n",
            "Item Latent bias:\n",
            "[0.11786136 0.12619429 0.12472672 0.12906991 0.11949845 0.12795999\n",
            " 0.1277309  0.12608414 0.11499151 0.1187518 ]\n",
            "Final R matrix:\n",
            "[[ 0.03180307  0.02058065  0.02683653 ...  0.02546522  0.01512238\n",
            "   0.02395004]\n",
            " [-0.0446844  -0.0231908  -0.01830275 ... -0.01401131 -0.02683312\n",
            "  -0.02727774]\n",
            " [ 0.03383525  0.05211852  0.0513449  ...  0.05320028  0.04046494\n",
            "   0.03822815]\n",
            " ...\n",
            " [ 0.06204856  0.0465253   0.03434763 ...  0.02970691  0.02122403\n",
            "   0.03078637]\n",
            " [ 0.01221389  0.00537485  0.00373706 ...  0.00243539 -0.00739716\n",
            "   0.00081972]\n",
            " [ 0.01800875  0.0258146   0.02597047 ...  0.02799942  0.01713106\n",
            "   0.02235438]]\n",
            "Final RMSE:\n",
            "0.00576701956655041\n",
            "0:00:01\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EJrwG2Y1663W"
      },
      "source": [
        "matrix_75_R4 = matrix_2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "If-AP3-r-lLN",
        "outputId": "de1820ce-bbb7-433e-f235-50b12fcedfed"
      },
      "source": [
        "matrix_75_R4"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.03180307,  0.02058065,  0.02683653, ...,  0.02546522,\n",
              "         0.01512238,  0.02395004],\n",
              "       [-0.0446844 , -0.0231908 , -0.01830275, ..., -0.01401131,\n",
              "        -0.02683312, -0.02727774],\n",
              "       [ 0.03383525,  0.05211852,  0.0513449 , ...,  0.05320028,\n",
              "         0.04046494,  0.03822815],\n",
              "       ...,\n",
              "       [ 0.06204856,  0.0465253 ,  0.03434763, ...,  0.02970691,\n",
              "         0.02122403,  0.03078637],\n",
              "       [ 0.01221389,  0.00537485,  0.00373706, ...,  0.00243539,\n",
              "        -0.00739716,  0.00081972],\n",
              "       [ 0.01800875,  0.0258146 ,  0.02597047, ...,  0.02799942,\n",
              "         0.01713106,  0.02235438]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_8GTM_S0Hwly",
        "outputId": "fcfc1086-2f9e-43c9-e0b0-a583bcd181a1"
      },
      "source": [
        "weight_array_50_R1 = np.delete(weight_array_50, 0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return array(a, dtype, copy=False, order=order)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tE8sSXHpD4sv",
        "outputId": "6403b9a2-f9f2-4ef0-bc98-2f4d840d6cbc"
      },
      "source": [
        "np.shape(weight_array_50)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return array(a, dtype, copy=False, order=order)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BoAJunm_xX_k"
      },
      "source": [
        "#50% + MF1\n",
        "weight_array_50_final_MF1 = []\n",
        "\n",
        "weight_array_50_final_MF1.append(matrix_50_R1)\n",
        "weight_array_50_final_MF1.append(weight_array_50_R1[0])\n",
        "weight_array_50_final_MF1.append(weight_array_50_R1[1])\n",
        "weight_array_50_final_MF1.append(weight_array_50_R1[2])\n",
        "weight_array_50_final_MF1.append(weight_array_50_R1[3])\n",
        "weight_array_50_final_MF1.append(weight_array_50_R1[4])\n",
        "\n",
        "\n",
        "#for i in [matrix_2, weight_2]:\n",
        "#  weight_3.append(i)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sDHiOxnsEGj0",
        "outputId": "1ec2194f-0e5c-4454-aa00-3464b63fd198"
      },
      "source": [
        "np.shape(weight_array_50_final_MF1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return array(a, dtype, copy=False, order=order)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N2IqFZqFdvDh"
      },
      "source": [
        "#드롭아웃 한 신경망에 MF한거 다시 넣기 MF1만\n",
        "model_dropout_50.set_weights(weight_array_50_final_MF1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TYwqFcAivcS9",
        "outputId": "7f80dc2d-ce7c-48e4-9b56-6273b4089442"
      },
      "source": [
        "#\n",
        "start_10 = time.time()\n",
        "\n",
        "final_50_R1 = model_dropout_50.fit(\n",
        "    x_train,\n",
        "    y_train,\n",
        "    epochs=50,\n",
        "    batch_size=32,\n",
        "    validation_split=0.1,\n",
        "    verbose = 1,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "sec_10 = time.time() - start_10\n",
        "times_10 = str(datetime.timedelta(seconds=sec_10)).split(\".\")\n",
        "times_10 = times_10[0]\n",
        "print(times_10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 3.7394 - accuracy: 0.1050 - val_loss: 2.3024 - val_accuracy: 0.1050\n",
            "Epoch 2/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 2.3062 - accuracy: 0.1137 - val_loss: 2.3023 - val_accuracy: 0.1050\n",
            "Epoch 3/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 2.3035 - accuracy: 0.1138 - val_loss: 2.3022 - val_accuracy: 0.1050\n",
            "Epoch 4/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 2.3042 - accuracy: 0.1142 - val_loss: 2.3019 - val_accuracy: 0.1050\n",
            "Epoch 5/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 2.0190 - accuracy: 0.2563 - val_loss: 1.0948 - val_accuracy: 0.6590\n",
            "Epoch 6/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 1.0401 - accuracy: 0.6720 - val_loss: 0.4713 - val_accuracy: 0.8713\n",
            "Epoch 7/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.6081 - accuracy: 0.8190 - val_loss: 0.2598 - val_accuracy: 0.9275\n",
            "Epoch 8/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.4407 - accuracy: 0.8726 - val_loss: 0.1942 - val_accuracy: 0.9432\n",
            "Epoch 9/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.3519 - accuracy: 0.8994 - val_loss: 0.1644 - val_accuracy: 0.9505\n",
            "Epoch 10/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.3040 - accuracy: 0.9146 - val_loss: 0.1391 - val_accuracy: 0.9602\n",
            "Epoch 11/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.2712 - accuracy: 0.9225 - val_loss: 0.1233 - val_accuracy: 0.9628\n",
            "Epoch 12/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.2445 - accuracy: 0.9291 - val_loss: 0.1143 - val_accuracy: 0.9645\n",
            "Epoch 13/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.2253 - accuracy: 0.9348 - val_loss: 0.1088 - val_accuracy: 0.9675\n",
            "Epoch 14/50\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 0.2115 - accuracy: 0.9404 - val_loss: 0.1012 - val_accuracy: 0.9693\n",
            "Epoch 15/50\n",
            "1688/1688 [==============================] - 4s 3ms/step - loss: 0.1996 - accuracy: 0.9427 - val_loss: 0.0985 - val_accuracy: 0.9682\n",
            "Epoch 16/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.1893 - accuracy: 0.9444 - val_loss: 0.0950 - val_accuracy: 0.9710\n",
            "Epoch 17/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.1798 - accuracy: 0.9478 - val_loss: 0.0903 - val_accuracy: 0.9738\n",
            "Epoch 18/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.1718 - accuracy: 0.9491 - val_loss: 0.0867 - val_accuracy: 0.9733\n",
            "Epoch 19/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.1667 - accuracy: 0.9516 - val_loss: 0.0870 - val_accuracy: 0.9732\n",
            "Epoch 20/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.1636 - accuracy: 0.9527 - val_loss: 0.0913 - val_accuracy: 0.9720\n",
            "Epoch 21/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.1555 - accuracy: 0.9544 - val_loss: 0.0860 - val_accuracy: 0.9745\n",
            "Epoch 22/50\n",
            "1688/1688 [==============================] - 4s 3ms/step - loss: 0.1528 - accuracy: 0.9547 - val_loss: 0.0831 - val_accuracy: 0.9757\n",
            "Epoch 23/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.1470 - accuracy: 0.9569 - val_loss: 0.0797 - val_accuracy: 0.9763\n",
            "Epoch 24/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.1438 - accuracy: 0.9578 - val_loss: 0.0792 - val_accuracy: 0.9767\n",
            "Epoch 25/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.1385 - accuracy: 0.9593 - val_loss: 0.0799 - val_accuracy: 0.9765\n",
            "Epoch 26/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.1362 - accuracy: 0.9601 - val_loss: 0.0750 - val_accuracy: 0.9783\n",
            "Epoch 27/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.1306 - accuracy: 0.9615 - val_loss: 0.0815 - val_accuracy: 0.9773\n",
            "Epoch 28/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.1301 - accuracy: 0.9617 - val_loss: 0.0792 - val_accuracy: 0.9768\n",
            "Epoch 29/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.1277 - accuracy: 0.9626 - val_loss: 0.0778 - val_accuracy: 0.9765\n",
            "Epoch 30/50\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 0.1240 - accuracy: 0.9634 - val_loss: 0.0763 - val_accuracy: 0.9790\n",
            "Epoch 31/50\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 0.1254 - accuracy: 0.9635 - val_loss: 0.0841 - val_accuracy: 0.9767\n",
            "Epoch 32/50\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 0.1240 - accuracy: 0.9639 - val_loss: 0.0795 - val_accuracy: 0.9780\n",
            "Epoch 33/50\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 0.1177 - accuracy: 0.9656 - val_loss: 0.0803 - val_accuracy: 0.9775\n",
            "Epoch 34/50\n",
            "1688/1688 [==============================] - 4s 3ms/step - loss: 0.1226 - accuracy: 0.9639 - val_loss: 0.0828 - val_accuracy: 0.9782\n",
            "Epoch 35/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.1162 - accuracy: 0.9653 - val_loss: 0.0742 - val_accuracy: 0.9790\n",
            "Epoch 36/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.1161 - accuracy: 0.9651 - val_loss: 0.0758 - val_accuracy: 0.9787\n",
            "Epoch 37/50\n",
            "1688/1688 [==============================] - 4s 3ms/step - loss: 0.1095 - accuracy: 0.9670 - val_loss: 0.0816 - val_accuracy: 0.9797\n",
            "Epoch 38/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.1145 - accuracy: 0.9667 - val_loss: 0.0735 - val_accuracy: 0.9808\n",
            "Epoch 39/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.1097 - accuracy: 0.9669 - val_loss: 0.0753 - val_accuracy: 0.9778\n",
            "Epoch 40/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.1129 - accuracy: 0.9671 - val_loss: 0.0741 - val_accuracy: 0.9798\n",
            "Epoch 41/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.1082 - accuracy: 0.9675 - val_loss: 0.0742 - val_accuracy: 0.9798\n",
            "Epoch 42/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.1096 - accuracy: 0.9681 - val_loss: 0.0725 - val_accuracy: 0.9797\n",
            "Epoch 43/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.1053 - accuracy: 0.9688 - val_loss: 0.0749 - val_accuracy: 0.9802\n",
            "Epoch 44/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.1032 - accuracy: 0.9682 - val_loss: 0.0718 - val_accuracy: 0.9797\n",
            "Epoch 45/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.1024 - accuracy: 0.9696 - val_loss: 0.0818 - val_accuracy: 0.9787\n",
            "Epoch 46/50\n",
            "1688/1688 [==============================] - 4s 3ms/step - loss: 0.1032 - accuracy: 0.9697 - val_loss: 0.0783 - val_accuracy: 0.9798\n",
            "Epoch 47/50\n",
            "1688/1688 [==============================] - 4s 3ms/step - loss: 0.1004 - accuracy: 0.9704 - val_loss: 0.0753 - val_accuracy: 0.9808\n",
            "Epoch 48/50\n",
            "1688/1688 [==============================] - 4s 3ms/step - loss: 0.0984 - accuracy: 0.9707 - val_loss: 0.0730 - val_accuracy: 0.9825\n",
            "Epoch 49/50\n",
            "1688/1688 [==============================] - 4s 3ms/step - loss: 0.0986 - accuracy: 0.9711 - val_loss: 0.0748 - val_accuracy: 0.9817\n",
            "Epoch 50/50\n",
            "1688/1688 [==============================] - 4s 3ms/step - loss: 0.0974 - accuracy: 0.9707 - val_loss: 0.0750 - val_accuracy: 0.9813\n",
            "0:03:29\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0SgzxuhMF5kV",
        "outputId": "98f8f3b1-695d-440b-fa44-42e8aba8f56f"
      },
      "source": [
        "weight_array_50_R1_R4 = np.delete(weight_array_50_final_MF1, 4)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return array(a, dtype, copy=False, order=order)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KyJdamGcFKmD"
      },
      "source": [
        "#50% + MF1 + MF2\n",
        "weight_array_50_final_MF1_MF2 = []\n",
        "\n",
        "weight_array_50_final_MF1_MF2.append(weight_array_50_final_MF1[0])\n",
        "weight_array_50_final_MF1_MF2.append(weight_array_50_final_MF1[1])\n",
        "weight_array_50_final_MF1_MF2.append(weight_array_50_final_MF1[2])\n",
        "weight_array_50_final_MF1_MF2.append(weight_array_50_final_MF1[3])\n",
        "weight_array_50_final_MF1_MF2.append(matrix_50_R4)\n",
        "weight_array_50_final_MF1_MF2.append(weight_array_50_final_MF1[5])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yeC7NZN5GkCZ"
      },
      "source": [
        "model_dropout_50.set_weights(weight_array_50_final_MF1_MF2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ya4b7fyOGmst",
        "outputId": "c472e1fa-ce8c-4189-fccd-519019ecbf0c"
      },
      "source": [
        "start_11 = time.time(\n",
        "    \n",
        ")\n",
        "final_50_R1_R4 = model_dropout_50.fit(\n",
        "    x_train,\n",
        "    y_train,\n",
        "    epochs=50,\n",
        "    batch_size=32,\n",
        "    validation_split=0.1,\n",
        "    verbose = 1,\n",
        "    shuffle=True\n",
        ")\n",
        "sec_11 = time.time() - start_11\n",
        "times_11 = str(datetime.timedelta(seconds=sec_11)).split(\".\")\n",
        "times_11 = times_11[0]\n",
        "print(times_10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "1688/1688 [==============================] - 4s 3ms/step - loss: 2.3522 - accuracy: 0.1419 - val_loss: 2.0438 - val_accuracy: 0.2458\n",
            "Epoch 2/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 1.6486 - accuracy: 0.3925 - val_loss: 0.7458 - val_accuracy: 0.7828\n",
            "Epoch 3/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.7207 - accuracy: 0.7713 - val_loss: 0.2785 - val_accuracy: 0.9210\n",
            "Epoch 4/50\n",
            "1688/1688 [==============================] - 4s 3ms/step - loss: 0.4487 - accuracy: 0.8685 - val_loss: 0.2070 - val_accuracy: 0.9417\n",
            "Epoch 5/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.3593 - accuracy: 0.8967 - val_loss: 0.1685 - val_accuracy: 0.9527\n",
            "Epoch 6/50\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 0.3126 - accuracy: 0.9113 - val_loss: 0.1452 - val_accuracy: 0.9588\n",
            "Epoch 7/50\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 0.2714 - accuracy: 0.9228 - val_loss: 0.1294 - val_accuracy: 0.9653\n",
            "Epoch 8/50\n",
            "1688/1688 [==============================] - 4s 3ms/step - loss: 0.2511 - accuracy: 0.9281 - val_loss: 0.1232 - val_accuracy: 0.9663\n",
            "Epoch 9/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.2336 - accuracy: 0.9338 - val_loss: 0.1154 - val_accuracy: 0.9683\n",
            "Epoch 10/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.2155 - accuracy: 0.9380 - val_loss: 0.1068 - val_accuracy: 0.9685\n",
            "Epoch 11/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.1983 - accuracy: 0.9428 - val_loss: 0.1023 - val_accuracy: 0.9717\n",
            "Epoch 12/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.1950 - accuracy: 0.9434 - val_loss: 0.0972 - val_accuracy: 0.9718\n",
            "Epoch 13/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.1861 - accuracy: 0.9466 - val_loss: 0.1007 - val_accuracy: 0.9707\n",
            "Epoch 14/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.1721 - accuracy: 0.9511 - val_loss: 0.0924 - val_accuracy: 0.9748\n",
            "Epoch 15/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.1680 - accuracy: 0.9517 - val_loss: 0.0924 - val_accuracy: 0.9750\n",
            "Epoch 16/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.1613 - accuracy: 0.9545 - val_loss: 0.0952 - val_accuracy: 0.9743\n",
            "Epoch 17/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.1572 - accuracy: 0.9542 - val_loss: 0.0903 - val_accuracy: 0.9748\n",
            "Epoch 18/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.1535 - accuracy: 0.9556 - val_loss: 0.0870 - val_accuracy: 0.9762\n",
            "Epoch 19/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.1457 - accuracy: 0.9576 - val_loss: 0.0872 - val_accuracy: 0.9767\n",
            "Epoch 20/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.1425 - accuracy: 0.9591 - val_loss: 0.0858 - val_accuracy: 0.9760\n",
            "Epoch 21/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.1388 - accuracy: 0.9596 - val_loss: 0.0845 - val_accuracy: 0.9763\n",
            "Epoch 22/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.1373 - accuracy: 0.9603 - val_loss: 0.0804 - val_accuracy: 0.9775\n",
            "Epoch 23/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.1350 - accuracy: 0.9609 - val_loss: 0.0828 - val_accuracy: 0.9753\n",
            "Epoch 24/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.1338 - accuracy: 0.9608 - val_loss: 0.0849 - val_accuracy: 0.9765\n",
            "Epoch 25/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.1302 - accuracy: 0.9631 - val_loss: 0.0854 - val_accuracy: 0.9773\n",
            "Epoch 26/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.1301 - accuracy: 0.9622 - val_loss: 0.0796 - val_accuracy: 0.9770\n",
            "Epoch 27/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.1221 - accuracy: 0.9644 - val_loss: 0.0810 - val_accuracy: 0.9793\n",
            "Epoch 28/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.1271 - accuracy: 0.9630 - val_loss: 0.0798 - val_accuracy: 0.9787\n",
            "Epoch 29/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.1201 - accuracy: 0.9640 - val_loss: 0.0819 - val_accuracy: 0.9768\n",
            "Epoch 30/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.1172 - accuracy: 0.9658 - val_loss: 0.0862 - val_accuracy: 0.9782\n",
            "Epoch 31/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.1191 - accuracy: 0.9654 - val_loss: 0.0879 - val_accuracy: 0.9767\n",
            "Epoch 32/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.1169 - accuracy: 0.9657 - val_loss: 0.0833 - val_accuracy: 0.9773\n",
            "Epoch 33/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.1168 - accuracy: 0.9662 - val_loss: 0.0829 - val_accuracy: 0.9768\n",
            "Epoch 34/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.1130 - accuracy: 0.9662 - val_loss: 0.0829 - val_accuracy: 0.9797\n",
            "Epoch 35/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.1141 - accuracy: 0.9667 - val_loss: 0.0832 - val_accuracy: 0.9778\n",
            "Epoch 36/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.1068 - accuracy: 0.9681 - val_loss: 0.0826 - val_accuracy: 0.9775\n",
            "Epoch 37/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.1072 - accuracy: 0.9686 - val_loss: 0.0792 - val_accuracy: 0.9787\n",
            "Epoch 38/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.1077 - accuracy: 0.9682 - val_loss: 0.0826 - val_accuracy: 0.9798\n",
            "Epoch 39/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.1038 - accuracy: 0.9693 - val_loss: 0.0794 - val_accuracy: 0.9803\n",
            "Epoch 40/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.1056 - accuracy: 0.9688 - val_loss: 0.0809 - val_accuracy: 0.9808\n",
            "Epoch 41/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.1077 - accuracy: 0.9684 - val_loss: 0.0820 - val_accuracy: 0.9795\n",
            "Epoch 42/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.1067 - accuracy: 0.9692 - val_loss: 0.0832 - val_accuracy: 0.9783\n",
            "Epoch 43/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.1007 - accuracy: 0.9694 - val_loss: 0.0833 - val_accuracy: 0.9775\n",
            "Epoch 44/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.1004 - accuracy: 0.9702 - val_loss: 0.0861 - val_accuracy: 0.9795\n",
            "Epoch 45/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.1029 - accuracy: 0.9693 - val_loss: 0.0818 - val_accuracy: 0.9803\n",
            "Epoch 46/50\n",
            "1688/1688 [==============================] - 4s 3ms/step - loss: 0.0996 - accuracy: 0.9701 - val_loss: 0.0868 - val_accuracy: 0.9778\n",
            "Epoch 47/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.1020 - accuracy: 0.9696 - val_loss: 0.0809 - val_accuracy: 0.9777\n",
            "Epoch 48/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.1011 - accuracy: 0.9695 - val_loss: 0.0818 - val_accuracy: 0.9777\n",
            "Epoch 49/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.0990 - accuracy: 0.9710 - val_loss: 0.0820 - val_accuracy: 0.9790\n",
            "Epoch 50/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.0949 - accuracy: 0.9722 - val_loss: 0.0840 - val_accuracy: 0.9772\n",
            "0:03:29\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sR6MwWXhIlOq",
        "outputId": "ea526a96-e57f-4ca2-900b-f648787fdbef"
      },
      "source": [
        "weight_array_75_R1 = np.delete(weight_array_75, 0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return array(a, dtype, copy=False, order=order)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dsl86PjgIrd-"
      },
      "source": [
        "#75% + MF1\n",
        "weight_array_75_final_MF1 = []\n",
        "\n",
        "weight_array_75_final_MF1.append(matrix_75_R1)\n",
        "weight_array_75_final_MF1.append(weight_array_75_R1[0])\n",
        "weight_array_75_final_MF1.append(weight_array_75_R1[1])\n",
        "weight_array_75_final_MF1.append(weight_array_75_R1[2])\n",
        "weight_array_75_final_MF1.append(weight_array_75_R1[3])\n",
        "weight_array_75_final_MF1.append(weight_array_75_R1[4])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Ql-ZTWjI5Np"
      },
      "source": [
        "model_dropout_75.set_weights(weight_array_75_final_MF1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oFvEPEr5I6_O",
        "outputId": "ecbb720c-a2f1-49a0-a856-c85862ec9504"
      },
      "source": [
        "start_12 = time.time()\n",
        "\n",
        "final_75_R1 = model_dropout_75.fit(\n",
        "    x_train,\n",
        "    y_train,\n",
        "    epochs=50,\n",
        "    batch_size=32,\n",
        "    validation_split=0.1,\n",
        "    verbose = 1,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "sec_12 = time.time() - start_12\n",
        "times_12 = str(datetime.timedelta(seconds=sec_12)).split(\".\")\n",
        "times_12 = times_12[0]\n",
        "print(times_12)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.3415 - accuracy: 0.9052 - val_loss: 0.1365 - val_accuracy: 0.9667\n",
            "Epoch 2/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.3412 - accuracy: 0.9061 - val_loss: 0.1403 - val_accuracy: 0.9665\n",
            "Epoch 3/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.3400 - accuracy: 0.9071 - val_loss: 0.1402 - val_accuracy: 0.9672\n",
            "Epoch 4/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.3379 - accuracy: 0.9064 - val_loss: 0.1365 - val_accuracy: 0.9663\n",
            "Epoch 5/50\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 0.3400 - accuracy: 0.9059 - val_loss: 0.1455 - val_accuracy: 0.9643\n",
            "Epoch 6/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.3339 - accuracy: 0.9071 - val_loss: 0.1405 - val_accuracy: 0.9677\n",
            "Epoch 7/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.3320 - accuracy: 0.9069 - val_loss: 0.1362 - val_accuracy: 0.9695\n",
            "Epoch 8/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.3327 - accuracy: 0.9062 - val_loss: 0.1411 - val_accuracy: 0.9680\n",
            "Epoch 9/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.3345 - accuracy: 0.9080 - val_loss: 0.1363 - val_accuracy: 0.9693\n",
            "Epoch 10/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.3381 - accuracy: 0.9058 - val_loss: 0.1407 - val_accuracy: 0.9688\n",
            "Epoch 11/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.3361 - accuracy: 0.9076 - val_loss: 0.1466 - val_accuracy: 0.9672\n",
            "Epoch 12/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.3277 - accuracy: 0.9098 - val_loss: 0.1470 - val_accuracy: 0.9678\n",
            "Epoch 13/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.3268 - accuracy: 0.9087 - val_loss: 0.1417 - val_accuracy: 0.9668\n",
            "Epoch 14/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.3299 - accuracy: 0.9087 - val_loss: 0.1438 - val_accuracy: 0.9678\n",
            "Epoch 15/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.3279 - accuracy: 0.9074 - val_loss: 0.1416 - val_accuracy: 0.9677\n",
            "Epoch 16/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.3321 - accuracy: 0.9073 - val_loss: 0.1395 - val_accuracy: 0.9663\n",
            "Epoch 17/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.3249 - accuracy: 0.9091 - val_loss: 0.1483 - val_accuracy: 0.9653\n",
            "Epoch 18/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.3262 - accuracy: 0.9091 - val_loss: 0.1427 - val_accuracy: 0.9670\n",
            "Epoch 19/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.3251 - accuracy: 0.9071 - val_loss: 0.1466 - val_accuracy: 0.9665\n",
            "Epoch 20/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.3203 - accuracy: 0.9104 - val_loss: 0.1474 - val_accuracy: 0.9652\n",
            "Epoch 21/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.3163 - accuracy: 0.9102 - val_loss: 0.1455 - val_accuracy: 0.9663\n",
            "Epoch 22/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.3230 - accuracy: 0.9088 - val_loss: 0.1504 - val_accuracy: 0.9678\n",
            "Epoch 23/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.3268 - accuracy: 0.9092 - val_loss: 0.1475 - val_accuracy: 0.9685\n",
            "Epoch 24/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.3284 - accuracy: 0.9093 - val_loss: 0.1364 - val_accuracy: 0.9703\n",
            "Epoch 25/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.3255 - accuracy: 0.9087 - val_loss: 0.1507 - val_accuracy: 0.9668\n",
            "Epoch 26/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.3186 - accuracy: 0.9094 - val_loss: 0.1521 - val_accuracy: 0.9678\n",
            "Epoch 27/50\n",
            "1688/1688 [==============================] - 4s 3ms/step - loss: 0.3226 - accuracy: 0.9109 - val_loss: 0.1448 - val_accuracy: 0.9675\n",
            "Epoch 28/50\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 0.3270 - accuracy: 0.9105 - val_loss: 0.1475 - val_accuracy: 0.9685\n",
            "Epoch 29/50\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 0.3217 - accuracy: 0.9095 - val_loss: 0.1484 - val_accuracy: 0.9682\n",
            "Epoch 30/50\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 0.3228 - accuracy: 0.9087 - val_loss: 0.1451 - val_accuracy: 0.9678\n",
            "Epoch 31/50\n",
            "1688/1688 [==============================] - 4s 3ms/step - loss: 0.3219 - accuracy: 0.9101 - val_loss: 0.1513 - val_accuracy: 0.9680\n",
            "Epoch 32/50\n",
            "1688/1688 [==============================] - 4s 3ms/step - loss: 0.3201 - accuracy: 0.9101 - val_loss: 0.1502 - val_accuracy: 0.9683\n",
            "Epoch 33/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.3167 - accuracy: 0.9105 - val_loss: 0.1502 - val_accuracy: 0.9665\n",
            "Epoch 34/50\n",
            "1688/1688 [==============================] - 4s 3ms/step - loss: 0.3214 - accuracy: 0.9089 - val_loss: 0.1538 - val_accuracy: 0.9678\n",
            "Epoch 35/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.3195 - accuracy: 0.9117 - val_loss: 0.1485 - val_accuracy: 0.9680\n",
            "Epoch 36/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.3185 - accuracy: 0.9108 - val_loss: 0.1491 - val_accuracy: 0.9678\n",
            "Epoch 37/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.3182 - accuracy: 0.9095 - val_loss: 0.1478 - val_accuracy: 0.9670\n",
            "Epoch 38/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.3099 - accuracy: 0.9114 - val_loss: 0.1486 - val_accuracy: 0.9687\n",
            "Epoch 39/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.3224 - accuracy: 0.9089 - val_loss: 0.1478 - val_accuracy: 0.9692\n",
            "Epoch 40/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.3151 - accuracy: 0.9104 - val_loss: 0.1508 - val_accuracy: 0.9685\n",
            "Epoch 41/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.3102 - accuracy: 0.9124 - val_loss: 0.1519 - val_accuracy: 0.9687\n",
            "Epoch 42/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.3138 - accuracy: 0.9118 - val_loss: 0.1482 - val_accuracy: 0.9693\n",
            "Epoch 43/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.3195 - accuracy: 0.9114 - val_loss: 0.1515 - val_accuracy: 0.9668\n",
            "Epoch 44/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.3123 - accuracy: 0.9129 - val_loss: 0.1529 - val_accuracy: 0.9692\n",
            "Epoch 45/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.3137 - accuracy: 0.9131 - val_loss: 0.1494 - val_accuracy: 0.9688\n",
            "Epoch 46/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.3095 - accuracy: 0.9128 - val_loss: 0.1478 - val_accuracy: 0.9682\n",
            "Epoch 47/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.3145 - accuracy: 0.9126 - val_loss: 0.1512 - val_accuracy: 0.9687\n",
            "Epoch 48/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.3132 - accuracy: 0.9117 - val_loss: 0.1550 - val_accuracy: 0.9675\n",
            "Epoch 49/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.3165 - accuracy: 0.9117 - val_loss: 0.1501 - val_accuracy: 0.9678\n",
            "Epoch 50/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.3077 - accuracy: 0.9143 - val_loss: 0.1525 - val_accuracy: 0.9677\n",
            "0:03:28\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dN8T79w5J4VX",
        "outputId": "f0c13cd6-757c-4091-89dd-be4f0fa6737f"
      },
      "source": [
        "weight_array_75_R1_R4 = np.delete(weight_array_75_final_MF1, 4)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return array(a, dtype, copy=False, order=order)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G-_JIX1bJ-zK"
      },
      "source": [
        "#75% + MF1 + MF2\n",
        "weight_array_75_final_MF1_MF2 = []\n",
        "\n",
        "weight_array_75_final_MF1_MF2.append(weight_array_75_final_MF1[0])\n",
        "weight_array_75_final_MF1_MF2.append(weight_array_75_final_MF1[1])\n",
        "weight_array_75_final_MF1_MF2.append(weight_array_75_final_MF1[2])\n",
        "weight_array_75_final_MF1_MF2.append(weight_array_75_final_MF1[3])\n",
        "weight_array_75_final_MF1_MF2.append(matrix_75_R4)\n",
        "weight_array_75_final_MF1_MF2.append(weight_array_75_final_MF1[5])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nfvrsHCOKK1d"
      },
      "source": [
        "model_dropout_75.set_weights(weight_array_75_final_MF1_MF2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CqxMw2tJKRS-",
        "outputId": "1de705f2-aaba-4ecb-e6a3-65e52986c0e0"
      },
      "source": [
        "start_13 = time.time()\n",
        "\n",
        "final_75_R1_R4 = model_dropout_75.fit(\n",
        "    x_train,\n",
        "    y_train,\n",
        "    epochs=50,\n",
        "    batch_size=32,\n",
        "    validation_split=0.1,\n",
        "    verbose = 1,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "sec_13 = time.time() - start_13\n",
        "times_13 = str(datetime.timedelta(seconds=sec_13)).split(\".\")\n",
        "times_13 = times_13[0]\n",
        "print(times_13)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "1688/1688 [==============================] - 4s 3ms/step - loss: 0.3139 - accuracy: 0.9116 - val_loss: 0.1498 - val_accuracy: 0.9687\n",
            "Epoch 2/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.3161 - accuracy: 0.9113 - val_loss: 0.1496 - val_accuracy: 0.9698\n",
            "Epoch 3/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.3185 - accuracy: 0.9109 - val_loss: 0.1540 - val_accuracy: 0.9685\n",
            "Epoch 4/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.3123 - accuracy: 0.9114 - val_loss: 0.1550 - val_accuracy: 0.9682\n",
            "Epoch 5/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.3095 - accuracy: 0.9120 - val_loss: 0.1599 - val_accuracy: 0.9680\n",
            "Epoch 6/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.3116 - accuracy: 0.9126 - val_loss: 0.1552 - val_accuracy: 0.9682\n",
            "Epoch 7/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.3085 - accuracy: 0.9134 - val_loss: 0.1555 - val_accuracy: 0.9697\n",
            "Epoch 8/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.3082 - accuracy: 0.9135 - val_loss: 0.1605 - val_accuracy: 0.9687\n",
            "Epoch 9/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.3103 - accuracy: 0.9123 - val_loss: 0.1569 - val_accuracy: 0.9688\n",
            "Epoch 10/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.3072 - accuracy: 0.9143 - val_loss: 0.1516 - val_accuracy: 0.9685\n",
            "Epoch 11/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.3088 - accuracy: 0.9138 - val_loss: 0.1615 - val_accuracy: 0.9677\n",
            "Epoch 12/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.3140 - accuracy: 0.9121 - val_loss: 0.1556 - val_accuracy: 0.9697\n",
            "Epoch 13/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.3118 - accuracy: 0.9113 - val_loss: 0.1575 - val_accuracy: 0.9677\n",
            "Epoch 14/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.3054 - accuracy: 0.9134 - val_loss: 0.1541 - val_accuracy: 0.9687\n",
            "Epoch 15/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.3111 - accuracy: 0.9119 - val_loss: 0.1604 - val_accuracy: 0.9687\n",
            "Epoch 16/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.3087 - accuracy: 0.9131 - val_loss: 0.1663 - val_accuracy: 0.9685\n",
            "Epoch 17/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.3077 - accuracy: 0.9132 - val_loss: 0.1569 - val_accuracy: 0.9683\n",
            "Epoch 18/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.3060 - accuracy: 0.9134 - val_loss: 0.1623 - val_accuracy: 0.9675\n",
            "Epoch 19/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.3082 - accuracy: 0.9129 - val_loss: 0.1585 - val_accuracy: 0.9665\n",
            "Epoch 20/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.3054 - accuracy: 0.9136 - val_loss: 0.1637 - val_accuracy: 0.9668\n",
            "Epoch 21/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.3080 - accuracy: 0.9142 - val_loss: 0.1569 - val_accuracy: 0.9697\n",
            "Epoch 22/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.3066 - accuracy: 0.9127 - val_loss: 0.1647 - val_accuracy: 0.9688\n",
            "Epoch 23/50\n",
            "1688/1688 [==============================] - 4s 3ms/step - loss: 0.3050 - accuracy: 0.9141 - val_loss: 0.1551 - val_accuracy: 0.9690\n",
            "Epoch 24/50\n",
            "1688/1688 [==============================] - 4s 3ms/step - loss: 0.3059 - accuracy: 0.9133 - val_loss: 0.1598 - val_accuracy: 0.9680\n",
            "Epoch 25/50\n",
            "1688/1688 [==============================] - 4s 3ms/step - loss: 0.3033 - accuracy: 0.9132 - val_loss: 0.1572 - val_accuracy: 0.9677\n",
            "Epoch 26/50\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 0.3072 - accuracy: 0.9145 - val_loss: 0.1573 - val_accuracy: 0.9690\n",
            "Epoch 27/50\n",
            "1688/1688 [==============================] - 4s 3ms/step - loss: 0.3054 - accuracy: 0.9128 - val_loss: 0.1616 - val_accuracy: 0.9683\n",
            "Epoch 28/50\n",
            "1688/1688 [==============================] - 4s 3ms/step - loss: 0.2971 - accuracy: 0.9167 - val_loss: 0.1695 - val_accuracy: 0.9697\n",
            "Epoch 29/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.3067 - accuracy: 0.9138 - val_loss: 0.1507 - val_accuracy: 0.9693\n",
            "Epoch 30/50\n",
            "1688/1688 [==============================] - 4s 3ms/step - loss: 0.3083 - accuracy: 0.9117 - val_loss: 0.1615 - val_accuracy: 0.9675\n",
            "Epoch 31/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.3051 - accuracy: 0.9147 - val_loss: 0.1484 - val_accuracy: 0.9707\n",
            "Epoch 32/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.3038 - accuracy: 0.9137 - val_loss: 0.1548 - val_accuracy: 0.9702\n",
            "Epoch 33/50\n",
            "1688/1688 [==============================] - 4s 3ms/step - loss: 0.3077 - accuracy: 0.9132 - val_loss: 0.1611 - val_accuracy: 0.9693\n",
            "Epoch 34/50\n",
            "1688/1688 [==============================] - 4s 3ms/step - loss: 0.3036 - accuracy: 0.9139 - val_loss: 0.1591 - val_accuracy: 0.9698\n",
            "Epoch 35/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.3048 - accuracy: 0.9128 - val_loss: 0.1595 - val_accuracy: 0.9685\n",
            "Epoch 36/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.3056 - accuracy: 0.9132 - val_loss: 0.1706 - val_accuracy: 0.9662\n",
            "Epoch 37/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.2952 - accuracy: 0.9163 - val_loss: 0.1626 - val_accuracy: 0.9690\n",
            "Epoch 38/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.3014 - accuracy: 0.9153 - val_loss: 0.1774 - val_accuracy: 0.9680\n",
            "Epoch 39/50\n",
            "1688/1688 [==============================] - 4s 3ms/step - loss: 0.3064 - accuracy: 0.9122 - val_loss: 0.1595 - val_accuracy: 0.9685\n",
            "Epoch 40/50\n",
            "1688/1688 [==============================] - 4s 3ms/step - loss: 0.2989 - accuracy: 0.9130 - val_loss: 0.1662 - val_accuracy: 0.9672\n",
            "Epoch 41/50\n",
            "1688/1688 [==============================] - 4s 3ms/step - loss: 0.3124 - accuracy: 0.9127 - val_loss: 0.1688 - val_accuracy: 0.9675\n",
            "Epoch 42/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.3039 - accuracy: 0.9129 - val_loss: 0.1630 - val_accuracy: 0.9683\n",
            "Epoch 43/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.3006 - accuracy: 0.9146 - val_loss: 0.1677 - val_accuracy: 0.9678\n",
            "Epoch 44/50\n",
            "1688/1688 [==============================] - 4s 3ms/step - loss: 0.3072 - accuracy: 0.9139 - val_loss: 0.1637 - val_accuracy: 0.9675\n",
            "Epoch 45/50\n",
            "1688/1688 [==============================] - 4s 3ms/step - loss: 0.3038 - accuracy: 0.9140 - val_loss: 0.1584 - val_accuracy: 0.9695\n",
            "Epoch 46/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.3084 - accuracy: 0.9121 - val_loss: 0.1636 - val_accuracy: 0.9705\n",
            "Epoch 47/50\n",
            "1688/1688 [==============================] - 4s 3ms/step - loss: 0.2997 - accuracy: 0.9134 - val_loss: 0.1644 - val_accuracy: 0.9707\n",
            "Epoch 48/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.2949 - accuracy: 0.9159 - val_loss: 0.1616 - val_accuracy: 0.9692\n",
            "Epoch 49/50\n",
            "1688/1688 [==============================] - 4s 3ms/step - loss: 0.3040 - accuracy: 0.9145 - val_loss: 0.1687 - val_accuracy: 0.9688\n",
            "Epoch 50/50\n",
            "1688/1688 [==============================] - 4s 2ms/step - loss: 0.2941 - accuracy: 0.9157 - val_loss: 0.1707 - val_accuracy: 0.9675\n",
            "0:03:29\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}